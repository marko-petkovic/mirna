{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merkelmauer/mirna/blob/main/StampDIVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4D7JeCpd2Nep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218a8c73-52cf-4a6f-a4f4-b9b5628a40d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.6.3\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchvision\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = '/content/drive/MyDrive/master'"
      ],
      "metadata": {
        "id": "UuXEtFCubCjx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "MgMR4QspjvRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VgKU5wNzDK4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2dca6c-4d40-40ec-cef6-91cf25d153b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
        "sys.path.insert(0, link)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.distributions as dist\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torchinfo import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "#writer = SummaryWriter()\n",
        "writer = None \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HuLsYxyh6_ZM"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Classes"
      ],
      "metadata": {
        "id": "axFkNf0cjx2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ae7NZhZGj7Zi"
      },
      "outputs": [],
      "source": [
        "class diva_args:\n",
        "\n",
        "    def __init__(self, zd_dim=32, zx_dim=32, zy_dim=64, d_dim=45, x_dim=7500, \n",
        "                 y_dim=2, aux_loss_multiplier_y=20, aux_loss_multiplier_d=2,\n",
        "                 beta_d=10, beta_x=10, beta_y=40, \n",
        "                 rec_alpha = 1, rec_beta = 1, rec_gamma = 1):\n",
        "\n",
        "        self.zd_dim = zd_dim\n",
        "        self.zx_dim = zx_dim\n",
        "        self.zy_dim = zy_dim\n",
        "        self.d_dim = d_dim\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.aux_loss_multiplier_y = aux_loss_multiplier_y\n",
        "        self.aux_loss_multiplier_d = aux_loss_multiplier_d\n",
        "        self.beta_d = beta_d\n",
        "        self.beta_x = beta_x\n",
        "        self.beta_y = beta_y\n",
        "        self.rec_alpha = rec_alpha\n",
        "        self.rec_beta = rec_beta\n",
        "        self.rec_gamma = rec_gamma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class"
      ],
      "metadata": {
        "id": "tb1vH-a1j7Rf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D6ouvuZX3WPs"
      },
      "outputs": [],
      "source": [
        "class MicroRNADataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds='train'):\n",
        "        \n",
        "        # loading images\n",
        "        self.images = np.load(f'{link}/modmirbase_{ds}_images.npz')['arr_0']/255\n",
        "        \n",
        "        \n",
        "        # loading labels\n",
        "        print('Loading Labels! (~10s)')     \n",
        "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
        "        labels = np.load(f'{link}/modmirbase_{ds}_labels.npz')['arr_0']\n",
        "        self.labels = ohe.fit_transform(labels)\n",
        "        \n",
        "        \n",
        "        # loading names\n",
        "        print('Loading Names! (~5s)')\n",
        "        names =  np.load(f'{link}/modmirbase_{ds}_names.npz')['arr_0']\n",
        "        names = [i.decode('utf-8') for i in names]\n",
        "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
        "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
        "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
        "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
        "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
        "                        'ppt', 'tca', 'dme', 'sbi']\n",
        "        # assigning a species label to each observation from species\n",
        "        # with more than 200 observations from past research\n",
        "        self.names = []\n",
        "        for i in names:\n",
        "            append = False\n",
        "            for j in self.species:\n",
        "                if j in i.lower():\n",
        "                    self.names.append(j)\n",
        "                    append = True\n",
        "                    break\n",
        "            if not append:\n",
        "                if 'random' in i.lower() or i.isdigit():\n",
        "                    self.names.append('hsa')\n",
        "                else:\n",
        "                    self.names.append('notfound')\n",
        "        \n",
        "        # performing one hot encoding\n",
        "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
        "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
        "      \n",
        "    def __len__(self):\n",
        "        return(self.images.shape[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        d = self.names_ohe[idx]\n",
        "        y = self.labels[idx]\n",
        "        x = self.images[idx]\n",
        "        x = np.transpose(x, (2,0,1))\n",
        "        return (x, y, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder classes"
      ],
      "metadata": {
        "id": "Xxj-WGXMj-Ne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RKizJuchX9uG"
      },
      "outputs": [],
      "source": [
        "# Decoders\n",
        "class px(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(px, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Sequential(nn.Linear(zd_dim + zx_dim + zy_dim, 200, bias=False),  \n",
        "                                 nn.ReLU())\n",
        "        \n",
        "        # Predicting length and color of each bar\n",
        "        self.up1 = nn.Upsample(scale_factor=5)\n",
        "        self.de1 = nn.Sequential(nn.ConvTranspose1d(5,25,kernel_size = 5,\n",
        "                                                    stride = 1, padding = 2,\n",
        "                                                    bias=False),\n",
        "                                 nn.ReLU()\n",
        "                                 )\n",
        "        # Predicting color of each bar\n",
        "        self.color_bar = nn.Sequential(nn.Conv1d(25,5, kernel_size = 3, padding = 'same'),\n",
        "                                      nn.Softmax(dim=1))\n",
        "        \n",
        "        # Predicting the length of each bar\n",
        "        self.length_bar = nn.Sequential(nn.Conv1d(25, 13, kernel_size = 3, padding = 'same'),\n",
        "                                        nn.Softmax(dim=1))\n",
        "\n",
        "        # Predicting length of the RNA strand\n",
        "        self.length_RNA = nn.Sequential(nn.Linear(200,100), nn.Softmax())\n",
        "        \n",
        "    def forward(self, zd, zx, zy):\n",
        "        if zx is None:\n",
        "            zdzxzy = torch.cat((zd, zy), dim=-1)\n",
        "        else:\n",
        "            zdzxzy = torch.cat((zd, zx, zy), dim=-1)\n",
        "        h = self.fc1(zdzxzy)\n",
        "        len_RNA = self.length_RNA(h)\n",
        "        \n",
        "        h = h.view(-1, 5, 40)\n",
        "        h = self.up1(h)\n",
        "        h = self.de1(h)\n",
        "        \n",
        "        len_bar = self.length_bar(h)\n",
        "        col_bar = self.color_bar(h)\n",
        "        \n",
        "        return len_RNA, len_bar, col_bar\n",
        "\n",
        "    def reconstruct_image(self, len_RNA, len_bar, col_bar, sample=False):\n",
        "        \"\"\"\n",
        "        reconstructs RNA image given output from decoder\n",
        "        even indexes of len_bar and col_bar   -> top\n",
        "        uneven indexes of len_bar and col_bar -> bottom\n",
        "        function does not support sampling yet\n",
        "        color reconstructions: 0: black\n",
        "                               1: red\n",
        "                               2: blue\n",
        "                               3: green\n",
        "                               4: yellow\n",
        "        \"\"\"\n",
        "        color_dict = {\n",
        "                  0: np.array([0,0,0]), # black\n",
        "                  1: np.array([1,0,0]), # red\n",
        "                  3: np.array([0,1,0]), # green\n",
        "                  2: np.array([0,0,1]), # blue\n",
        "                  4: np.array([1,1,0])  # yellow\n",
        "                  }\n",
        "    \n",
        "        \n",
        "        len_RNA = len_RNA.cpu().numpy()#.reshape((100,))\n",
        "        len_bar = len_bar.cpu().numpy()\n",
        "        col_bar = col_bar.cpu().numpy()\n",
        "        n = len_RNA.shape[0]\n",
        "        output = np.ones((n,25,100,3))\n",
        "\n",
        "        for i in range(n):\n",
        "            if sample:\n",
        "                limit = np.random.choice(np.arange(100), p = len_RNA[i])\n",
        "            else:\n",
        "                limit = np.argmax(len_RNA[i])\n",
        "\n",
        "            for j in range(limit+1):\n",
        "                if sample:\n",
        "                    _len_bar_1 = np.random.choice(np.arange(1,14), p = len_bar[i, :,2*j]) \n",
        "                    _len_bar_2 = np.random.choice(np.arange(1,14), p = len_bar[i, :, 2*j+1])\n",
        "                    _col_bar_1 = np.random.choice(np.arange(5), p = col_bar[i, :, 2*j])\n",
        "                    _col_bar_2 = np.random.choice(np.arange(5), p = col_bar[i,:, 2*j+1])\n",
        "                else:\n",
        "                    _len_bar_1 = np.argmax(len_bar[i,:, 2*j]) + 1 \n",
        "                    _len_bar_2 = np.argmax(len_bar[i,:, 2*j + 1]) + 1\n",
        "                    _col_bar_1 = np.argmax(col_bar[i,:, 2*j])\n",
        "                    _col_bar_2 = np.argmax(col_bar[i,:, 2*j+1])\n",
        "                \n",
        "                h1 = 13-_len_bar_1\n",
        "                # paint upper bar\n",
        "                output[i, h1:13, j] = color_dict[_col_bar_1]\n",
        "        \n",
        "                # paint lower bar\n",
        "                output[i, 13:13+_len_bar_2, j] = color_dict[_col_bar_2]\n",
        "        \n",
        "        \n",
        "        return output\n",
        "\n",
        "class pzd(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(pzd, self).__init__()\n",
        "        self.fc1 = nn.Sequential(nn.Linear(d_dim, zd_dim, bias=False), \n",
        "                                 nn.BatchNorm1d(zd_dim), \n",
        "                                 nn.ReLU())\n",
        "        self.fc21 = nn.Sequential(nn.Linear(zd_dim, zd_dim))\n",
        "        self.fc22 = nn.Sequential(nn.Linear(zd_dim, zd_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc21[0].weight)\n",
        "        self.fc21[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc22[0].weight)\n",
        "        self.fc22[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, d):\n",
        "        hidden = self.fc1(d)\n",
        "        zd_loc = self.fc21(hidden)\n",
        "        zd_scale = self.fc22(hidden) + 1e-7\n",
        "\n",
        "        return zd_loc, zd_scale\n",
        "\n",
        "\n",
        "class pzy(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(pzy, self).__init__()\n",
        "        self.fc1 = nn.Sequential(nn.Linear(y_dim, zy_dim, bias=False),\n",
        "                                 nn.BatchNorm1d(zy_dim), \n",
        "                                 nn.ReLU())\n",
        "        self.fc21 = nn.Sequential(nn.Linear(zy_dim, zy_dim))\n",
        "        self.fc22 = nn.Sequential(nn.Linear(zy_dim, zy_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc21[0].weight)\n",
        "        self.fc21[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc22[0].weight)\n",
        "        self.fc22[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, y):\n",
        "        hidden = self.fc1(y)\n",
        "        zy_loc = self.fc21(hidden)\n",
        "        zy_scale = self.fc22(hidden) + 1e-7\n",
        "\n",
        "        return zy_loc, zy_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1y8G2S1zxzTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8b4324-c715-4592-ce6a-da4255a03f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "px                                       --                        --\n",
              "├─Sequential: 1-1                        [1, 200]                  --\n",
              "│    └─Linear: 2-1                       [1, 200]                  19,200\n",
              "│    └─ReLU: 2-2                         [1, 200]                  --\n",
              "├─Sequential: 1-2                        [1, 100]                  --\n",
              "│    └─Linear: 2-3                       [1, 100]                  20,100\n",
              "│    └─Softmax: 2-4                      [1, 100]                  --\n",
              "├─Upsample: 1-3                          [1, 5, 200]               --\n",
              "├─Sequential: 1-4                        [1, 25, 200]              --\n",
              "│    └─ConvTranspose1d: 2-5              [1, 25, 200]              625\n",
              "│    └─ReLU: 2-6                         [1, 25, 200]              --\n",
              "├─Sequential: 1-5                        [1, 13, 200]              --\n",
              "│    └─Conv1d: 2-7                       [1, 13, 200]              988\n",
              "│    └─Softmax: 2-8                      [1, 13, 200]              --\n",
              "├─Sequential: 1-6                        [1, 5, 200]               --\n",
              "│    └─Conv1d: 2-9                       [1, 5, 200]               380\n",
              "│    └─Softmax: 2-10                     [1, 5, 200]               --\n",
              "==========================================================================================\n",
              "Total params: 41,293\n",
              "Trainable params: 41,293\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.44\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.07\n",
              "Params size (MB): 0.17\n",
              "Estimated Total Size (MB): 0.24\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
        "# summary(pzy_, (1,2))\n",
        "pzy_ = px(45, 7500, 2, 32,32,32)\n",
        "summary(pzy_, [(1,32),(1,32),(1,32)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Endcoder Classes"
      ],
      "metadata": {
        "id": "YmNnZWXvkCDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pzy_.reconstruct_image(torch.zeros((1,100)), torch.zeros((1,13,200)), torch.zeros(1,5,200)).shape"
      ],
      "metadata": {
        "id": "tt82wvITwg4j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "78ZFH8gYl_-z"
      },
      "outputs": [],
      "source": [
        "class qzd(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(qzd, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc11 = nn.Sequential(nn.Linear(4224, zd_dim))\n",
        "        self.fc12 = nn.Sequential(nn.Linear(4224, zd_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
        "        self.fc11[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
        "        self.fc12[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(-1, 4224)\n",
        "        zd_loc = self.fc11(h)\n",
        "        zd_scale = self.fc12(h) + 1e-7\n",
        "\n",
        "        return zd_loc, zd_scale\n",
        "\n",
        "\n",
        "class qzx(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(qzx, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc11 = nn.Sequential(nn.Linear(4224, zx_dim))\n",
        "        self.fc12 = nn.Sequential(nn.Linear(4224, zx_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
        "        self.fc11[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
        "        self.fc12[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(-1, 4224)\n",
        "        zd_loc = self.fc11(h)\n",
        "        zd_scale = self.fc12(h) + 1e-7\n",
        "\n",
        "        return zd_loc, zd_scale\n",
        "\n",
        "\n",
        "class qzy(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(qzy, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc11 = nn.Sequential(nn.Linear(4224, zy_dim))\n",
        "        self.fc12 = nn.Sequential(nn.Linear(4224, zy_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
        "        self.fc11[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
        "        self.fc12[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(-1, 4224)\n",
        "        zd_loc = self.fc11(h)\n",
        "        zd_scale = self.fc12(h) + 1e-7\n",
        "\n",
        "        return zd_loc, zd_scale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary predictors classes"
      ],
      "metadata": {
        "id": "601pquQEkE6-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XhIOunSHcc9b"
      },
      "outputs": [],
      "source": [
        "# Auxiliary tasks\n",
        "class qd(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(qd, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(zd_dim, d_dim)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc1.bias.data.zero_()\n",
        "\n",
        "    def forward(self, zd):\n",
        "        h = F.relu(zd)\n",
        "        loc_d = self.fc1(h)\n",
        "\n",
        "        return loc_d\n",
        "\n",
        "\n",
        "class qy(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, zd_dim, zx_dim, zy_dim):\n",
        "        super(qy, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(zy_dim, y_dim)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc1.bias.data.zero_()\n",
        "\n",
        "    def forward(self, zy):\n",
        "        h = F.relu(zy)\n",
        "        loc_y = self.fc1(h)\n",
        "\n",
        "        return loc_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full model class"
      ],
      "metadata": {
        "id": "vn_gJdNSkH_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BgR5BnQN1WWG"
      },
      "outputs": [],
      "source": [
        "class StampDIVA(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(StampDIVA, self).__init__()\n",
        "        self.zd_dim = args.zd_dim\n",
        "        self.zx_dim = args.zx_dim\n",
        "        self.zy_dim = args.zy_dim\n",
        "        self.d_dim = args.d_dim\n",
        "        self.x_dim = args.x_dim\n",
        "        self.y_dim = args.y_dim\n",
        "\n",
        "        self.start_zx = self.zd_dim\n",
        "        self.start_zy = self.zd_dim + self.zx_dim\n",
        "\n",
        "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "        self.pzd = pzd(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "        self.pzy = pzy(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "\n",
        "        self.qzd = qzd(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "        if self.zx_dim != 0:\n",
        "            self.qzx = qzx(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "        self.qzy = qzy(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "\n",
        "        self.qd = qd(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "        self.qy = qy(self.d_dim, self.x_dim, self.y_dim, self.zd_dim, self.zx_dim, self.zy_dim)\n",
        "\n",
        "        self.aux_loss_multiplier_y = args.aux_loss_multiplier_y\n",
        "        self.aux_loss_multiplier_d = args.aux_loss_multiplier_d\n",
        "\n",
        "        self.beta_d = args.beta_d\n",
        "        self.beta_x = args.beta_x\n",
        "        self.beta_y = args.beta_y\n",
        "\n",
        "        self.rec_alpha = args.rec_alpha\n",
        "        self.rec_beta = args.rec_beta\n",
        "        self.rec_gamma = args.rec_gamma\n",
        "\n",
        "        self.cuda()\n",
        "\n",
        "    def forward(self, d, x, y):\n",
        "        # Encode\n",
        "        zd_q_loc, zd_q_scale = self.qzd(x)\n",
        "        if self.zx_dim != 0:\n",
        "            zx_q_loc, zx_q_scale = self.qzx(x)\n",
        "        zy_q_loc, zy_q_scale = self.qzy(x)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        qzd = dist.Normal(zd_q_loc, zd_q_scale)\n",
        "        zd_q = qzd.rsample()\n",
        "        if self.zx_dim != 0:\n",
        "            qzx = dist.Normal(zx_q_loc, zx_q_scale)\n",
        "            zx_q = qzx.rsample()\n",
        "        else:\n",
        "            qzx = None\n",
        "            zx_q = None\n",
        "\n",
        "        qzy = dist.Normal(zy_q_loc, zy_q_scale)\n",
        "        zy_q = qzy.rsample()\n",
        "\n",
        "        # Decode\n",
        "        x_len, x_bar, x_col = self.px(zd_q, zx_q, zy_q)\n",
        "\n",
        "        zd_p_loc, zd_p_scale = self.pzd(d)\n",
        "\n",
        "        if self.zx_dim != 0:\n",
        "            zx_p_loc, zx_p_scale = torch.zeros(zd_p_loc.size()[0], self.zx_dim).cuda(),\\\n",
        "                                   torch.ones(zd_p_loc.size()[0], self.zx_dim).cuda()\n",
        "        zy_p_loc, zy_p_scale = self.pzy(y)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        pzd = dist.Normal(zd_p_loc, zd_p_scale)\n",
        "        if self.zx_dim != 0:\n",
        "            pzx = dist.Normal(zx_p_loc, zx_p_scale)\n",
        "        else:\n",
        "            pzx = None\n",
        "        pzy = dist.Normal(zy_p_loc, zy_p_scale)\n",
        "\n",
        "        # Auxiliary losses\n",
        "        d_hat = self.qd(zd_q)\n",
        "        y_hat = self.qy(zy_q)\n",
        "\n",
        "        return x_len, x_bar, x_col, d_hat, y_hat, qzd, pzd, zd_q, qzx, pzx, zx_q, qzy, pzy, zy_q\n",
        "\n",
        "    def loss_function(self, d, x, y):\n",
        "          x_len, x_bar, x_col, d_hat, y_hat, qzd, pzd, zd_q, qzx, pzx, zx_q, qzy, pzy, zy_q = self.forward(d, x, y)\n",
        "          \n",
        "          out_len, out_bar, out_col = self.get_encoded_values(x)\n",
        "          \n",
        "          CE_len = F.cross_entropy(x_len, out_len, reduction='sum')\n",
        "          CE_bar = F.cross_entropy(x_bar, out_bar, reduction='sum')\n",
        "          CE_col = F.cross_entropy(x_col, out_col, reduction='sum')\n",
        "\n",
        "          zd_p_minus_zd_q = torch.sum(pzd.log_prob(zd_q) - qzd.log_prob(zd_q))\n",
        "          if self.zx_dim != 0:\n",
        "              KL_zx = torch.sum(pzx.log_prob(zx_q) - qzx.log_prob(zx_q))\n",
        "          else:\n",
        "              KL_zx = 0\n",
        "\n",
        "          zy_p_minus_zy_q = torch.sum(pzy.log_prob(zy_q) - qzy.log_prob(zy_q))\n",
        "\n",
        "          _, d_target = d.max(dim=1)\n",
        "          CE_d = F.cross_entropy(d_hat, d_target, reduction='sum')\n",
        "\n",
        "          _, y_target = y.max(dim=1)\n",
        "          CE_y = F.cross_entropy(y_hat, y_target, reduction='sum')\n",
        "\n",
        "          return self.rec_alpha * CE_len \\\n",
        "                  + self.rec_beta * CE_bar \\\n",
        "                  + self.rec_gamma * CE_col \\\n",
        "                  - self.beta_d * zd_p_minus_zd_q \\\n",
        "                  - self.beta_x * KL_zx \\\n",
        "                  - self.beta_y * zy_p_minus_zy_q \\\n",
        "                  + self.aux_loss_multiplier_d * CE_d \\\n",
        "                  + self.aux_loss_multiplier_y * CE_y,\\\n",
        "                  CE_y\n",
        "\n",
        "    def get_encoded_values(self, x):\n",
        "        \"\"\"\n",
        "        given an image or batch of images\n",
        "        returns length of strand, length of bars and colors of bars\n",
        "        \"\"\"\n",
        "        n = x.shape[0]\n",
        "        out_len = torch.zeros((n,100)).to(DEVICE)\n",
        "        out_col = torch.zeros((n,5,200)).to(DEVICE)\n",
        "        out_bar = torch.zeros((n,13,200)).to(DEVICE)\n",
        "\n",
        "        for i in range(n):\n",
        "            rna_len = 0\n",
        "            for j in range(100):\n",
        "                if (x[i,:,12,j] == torch.tensor([1,1,1]).to(DEVICE)).all():\n",
        "                   out_len[i,rna_len-1] = 1\n",
        "                   break\n",
        "                else:\n",
        "                    rna_len += 1\n",
        "                    # check color of bars\n",
        "                    out_col[i, self.get_color(x[i,:,12,j]) ,2*j] = 1 \n",
        "                    out_col[i, self.get_color(x[i,:,13,j]), 2*j+1] = 1\n",
        "                    # check length of bars\n",
        "                    len1 = 0\n",
        "                    # loop until white pixel\n",
        "                    while not (x[i,:,12-len1,j] == torch.tensor([1.,1.,1.]).to(DEVICE)).all():\n",
        "                        len1 += 1\n",
        "                        if 13-len1 == 0:\n",
        "                           break\n",
        "                    out_bar[i, len1-1, 2*j] = 1\n",
        "\n",
        "                    len2 = 0\n",
        "                    while not (x[i,:,13+len2,j] == torch.tensor([1.,1.,1.]).to(DEVICE)).all():\n",
        "                        len2 += 1\n",
        "                        if 13+len2 == 25:\n",
        "                            break\n",
        "                    out_bar[i, len2-1, 2*j+1] = 1\n",
        "        return out_len, out_bar, out_col\n",
        "\n",
        "    def get_color(self, pixel):\n",
        "        \"\"\"\n",
        "        returns the encoded value for a pixel\n",
        "        \"\"\"\n",
        "        if (pixel == torch.tensor([0,0,0]).to(DEVICE)).all():  \n",
        "            return 0 # black\n",
        "        elif (pixel == torch.tensor([1,0,0]).to(DEVICE)).all():  \n",
        "            return 1 # red\n",
        "        elif (pixel == torch.tensor([0,0,1]).to(DEVICE)).all():  \n",
        "            return 2 # blue\n",
        "        elif (pixel == torch.tensor([0,1,0]).to(DEVICE)).all():  \n",
        "            return 3 # green\n",
        "        elif (pixel == torch.tensor([1,1,0]).to(DEVICE)).all():  \n",
        "            return 4 # yellow\n",
        "        else:\n",
        "            print(\"Something wrong!\")\n",
        "        \n",
        "                  \n",
        "\n",
        "    def classifier(self, x):\n",
        "        \"\"\"\n",
        "        classify an image (or a batch of images)\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :return: a batch of the corresponding class labels (as one-hots)\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            zd_q_loc, zd_q_scale = self.qzd(x)\n",
        "            zd = zd_q_loc\n",
        "            alpha = F.softmax(self.qd(zd), dim=1)\n",
        "\n",
        "            # get the index (digit) that corresponds to\n",
        "            # the maximum predicted class probability\n",
        "            res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "            # convert the digit(s) to one-hot tensor(s)\n",
        "            d = x.new_zeros(alpha.size())\n",
        "            d = d.scatter_(1, ind, 1.0)\n",
        "\n",
        "            zy_q_loc, zy_q_scale = self.qzy.forward(x)\n",
        "            zy = zy_q_loc\n",
        "            alpha = F.softmax(self.qy(zy), dim=1)\n",
        "\n",
        "            # get the index (digit) that corresponds to\n",
        "            # the maximum predicted class probability\n",
        "            res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "            # convert the digit(s) to one-hot tensor(s)\n",
        "            y = x.new_zeros(alpha.size())\n",
        "            y = y.scatter_(1, ind, 1.0)\n",
        "\n",
        "        return d, y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "LdOsLfYJjBBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing model"
      ],
      "metadata": {
        "id": "R_H_mVMUszt2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sJE0HTJE1ayP"
      },
      "outputs": [],
      "source": [
        "default_args = diva_args(zd_dim=32, zx_dim=64, zy_dim=32,\n",
        "                         aux_loss_multiplier_y=100, aux_loss_multiplier_d=2,\n",
        "                         rec_alpha = 50, rec_beta = 100, rec_gamma = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kxIMSeUD1949"
      },
      "outputs": [],
      "source": [
        "diva = StampDIVA(default_args).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(diva, [(1,45),(1,3,25,100),(1,2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ZiBzfeZwro",
        "outputId": "677a7e34-d047-42f3-8a80-e3eb53c0c718"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "StampDIVA                                --                        --\n",
              "├─qzd: 1-1                               [1, 32]                   --\n",
              "│    └─Sequential: 2-1                   [1, 64, 3, 22]            --\n",
              "│    │    └─Conv2d: 3-1                  [1, 32, 21, 96]           2,400\n",
              "│    │    └─ReLU: 3-2                    [1, 32, 21, 96]           --\n",
              "│    │    └─MaxPool2d: 3-3               [1, 32, 10, 48]           --\n",
              "│    │    └─Conv2d: 3-4                  [1, 64, 6, 44]            51,200\n",
              "│    │    └─ReLU: 3-5                    [1, 64, 6, 44]            --\n",
              "│    │    └─MaxPool2d: 3-6               [1, 64, 3, 22]            --\n",
              "│    └─Sequential: 2-2                   [1, 32]                   --\n",
              "│    │    └─Linear: 3-7                  [1, 32]                   135,200\n",
              "│    └─Sequential: 2-3                   [1, 32]                   --\n",
              "│    │    └─Linear: 3-8                  [1, 32]                   135,200\n",
              "│    │    └─Softplus: 3-9                [1, 32]                   --\n",
              "├─qzx: 1-2                               [1, 64]                   --\n",
              "│    └─Sequential: 2-4                   [1, 64, 3, 22]            --\n",
              "│    │    └─Conv2d: 3-10                 [1, 32, 21, 96]           2,400\n",
              "│    │    └─ReLU: 3-11                   [1, 32, 21, 96]           --\n",
              "│    │    └─MaxPool2d: 3-12              [1, 32, 10, 48]           --\n",
              "│    │    └─Conv2d: 3-13                 [1, 64, 6, 44]            51,200\n",
              "│    │    └─ReLU: 3-14                   [1, 64, 6, 44]            --\n",
              "│    │    └─MaxPool2d: 3-15              [1, 64, 3, 22]            --\n",
              "│    └─Sequential: 2-5                   [1, 64]                   --\n",
              "│    │    └─Linear: 3-16                 [1, 64]                   270,400\n",
              "│    └─Sequential: 2-6                   [1, 64]                   --\n",
              "│    │    └─Linear: 3-17                 [1, 64]                   270,400\n",
              "│    │    └─Softplus: 3-18               [1, 64]                   --\n",
              "├─qzy: 1-3                               [1, 32]                   --\n",
              "│    └─Sequential: 2-7                   [1, 64, 3, 22]            --\n",
              "│    │    └─Conv2d: 3-19                 [1, 32, 21, 96]           2,400\n",
              "│    │    └─ReLU: 3-20                   [1, 32, 21, 96]           --\n",
              "│    │    └─MaxPool2d: 3-21              [1, 32, 10, 48]           --\n",
              "│    │    └─Conv2d: 3-22                 [1, 64, 6, 44]            51,200\n",
              "│    │    └─ReLU: 3-23                   [1, 64, 6, 44]            --\n",
              "│    │    └─MaxPool2d: 3-24              [1, 64, 3, 22]            --\n",
              "│    └─Sequential: 2-8                   [1, 32]                   --\n",
              "│    │    └─Linear: 3-25                 [1, 32]                   135,200\n",
              "│    └─Sequential: 2-9                   [1, 32]                   --\n",
              "│    │    └─Linear: 3-26                 [1, 32]                   135,200\n",
              "│    │    └─Softplus: 3-27               [1, 32]                   --\n",
              "├─px: 1-4                                [1, 100]                  --\n",
              "│    └─Sequential: 2-10                  [1, 200]                  --\n",
              "│    │    └─Linear: 3-28                 [1, 200]                  25,600\n",
              "│    │    └─ReLU: 3-29                   [1, 200]                  --\n",
              "│    └─Sequential: 2-11                  [1, 100]                  --\n",
              "│    │    └─Linear: 3-30                 [1, 100]                  20,100\n",
              "│    │    └─Softmax: 3-31                [1, 100]                  --\n",
              "│    └─Upsample: 2-12                    [1, 5, 200]               --\n",
              "│    └─Sequential: 2-13                  [1, 25, 200]              --\n",
              "│    │    └─ConvTranspose1d: 3-32        [1, 25, 200]              625\n",
              "│    │    └─ReLU: 3-33                   [1, 25, 200]              --\n",
              "│    └─Sequential: 2-14                  [1, 13, 200]              --\n",
              "│    │    └─Conv1d: 3-34                 [1, 13, 200]              988\n",
              "│    │    └─Softmax: 3-35                [1, 13, 200]              --\n",
              "│    └─Sequential: 2-15                  [1, 5, 200]               --\n",
              "│    │    └─Conv1d: 3-36                 [1, 5, 200]               380\n",
              "│    │    └─Softmax: 3-37                [1, 5, 200]               --\n",
              "├─pzd: 1-5                               [1, 32]                   --\n",
              "│    └─Sequential: 2-16                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-38                 [1, 32]                   1,440\n",
              "│    │    └─BatchNorm1d: 3-39            [1, 32]                   64\n",
              "│    │    └─ReLU: 3-40                   [1, 32]                   --\n",
              "│    └─Sequential: 2-17                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-41                 [1, 32]                   1,056\n",
              "│    └─Sequential: 2-18                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-42                 [1, 32]                   1,056\n",
              "│    │    └─Softplus: 3-43               [1, 32]                   --\n",
              "├─pzy: 1-6                               [1, 32]                   --\n",
              "│    └─Sequential: 2-19                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-44                 [1, 32]                   64\n",
              "│    │    └─BatchNorm1d: 3-45            [1, 32]                   64\n",
              "│    │    └─ReLU: 3-46                   [1, 32]                   --\n",
              "│    └─Sequential: 2-20                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-47                 [1, 32]                   1,056\n",
              "│    └─Sequential: 2-21                  [1, 32]                   --\n",
              "│    │    └─Linear: 3-48                 [1, 32]                   1,056\n",
              "│    │    └─Softplus: 3-49               [1, 32]                   --\n",
              "├─qd: 1-7                                [1, 45]                   --\n",
              "│    └─Linear: 2-22                      [1, 45]                   1,485\n",
              "├─qy: 1-8                                [1, 2]                    --\n",
              "│    └─Linear: 2-23                      [1, 2]                    66\n",
              "==========================================================================================\n",
              "Total params: 1,297,500\n",
              "Trainable params: 1,297,500\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 56.60\n",
              "==========================================================================================\n",
              "Input size (MB): 0.03\n",
              "Forward/backward pass size (MB): 2.03\n",
              "Params size (MB): 5.19\n",
              "Estimated Total Size (MB): 7.25\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diva.load_state_dict(torch.load(f'{link}/stampdiva_v3.0.2.pth'))"
      ],
      "metadata": {
        "id": "s5C6mSJTDLtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176c0feb-6878-4a87-dacd-fb1de1dfc053"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "rH1E5J-ps3GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_dataset = MicroRNADataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myflmDPxjV40",
        "outputId": "7a3e10be-c848-4c02-e392-d93d10a0fc82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Labels! (~10s)\n",
            "Loading Names! (~5s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_dataset_test = MicroRNADataset('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut2P5RSaMoDR",
        "outputId": "b3da7204-f34f-40ee-a647-b47f114f98b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Labels! (~10s)\n",
            "Loading Names! (~5s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training functions"
      ],
      "metadata": {
        "id": "YdYaqWvbjN26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eVGq463Y2m20"
      },
      "outputs": [],
      "source": [
        "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    epoch_class_y_loss = 0\n",
        "\n",
        "    no_batches = 0\n",
        "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
        "                                     desc=f'Epoch {epoch}')\n",
        "    for batch_idx, (x, y, d) in pbar:\n",
        "        # To device\n",
        "        # print(x)\n",
        "        # print(y)\n",
        "        # print(d)\n",
        "        x, y, d = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
        "\n",
        "        # if (epoch % 50 == 0) and (batch_idx == 1):\n",
        "        #     save_reconstructions(model, d, x, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, class_y_loss = model.loss_function(d.float(), x.float(), y.float())\n",
        "        _, y_pred = model.classifier(x.float())\n",
        "        acc = ((y == y_pred).all(axis=1)*1.0).mean().item()\n",
        "        if writer is not None:\n",
        "          writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "          writer.add_scalar(\"y_loss/train\", class_y_loss, epoch)\n",
        "          writer.add_scalar(\"y_acc/train\", acc, epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_postfix(loss=loss.item()/x.shape[0], \n",
        "                         y_loss = class_y_loss.item()/x.shape[0])\n",
        "        train_loss += loss\n",
        "        epoch_class_y_loss += class_y_loss\n",
        "        no_batches += 1\n",
        "        # print(f'finished batch {no_batches}!')\n",
        "        # if no_batches == 25:\n",
        "        #     break\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    epoch_class_y_loss /= len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, epoch_class_y_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_single_epoch(test_loader, model, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    epoch_class_y_loss = 0\n",
        "    test_corr = 0\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x,y,d) in enumerate(test_loader):\n",
        "            x, y, d = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
        "            loss, class_y_loss = model.loss_function(d.float(), x.float(), y.float())\n",
        "            _, y_pred = model.classifier(x.float())\n",
        "            test_corr += (y == y_pred).all(axis=1).sum().item()\n",
        "            acc = ((y == y_pred).all(axis=1)*1.).mean().item()\n",
        "            if writer is not None:\n",
        "              writer.add_scalar(\"Loss/test\", loss, epoch)\n",
        "              writer.add_scalar(\"y_loss/test\", class_y_loss, epoch)\n",
        "              writer.add_scalar(\"y_acc/test\", acc, epoch)\n",
        "            test_loss += loss\n",
        "            epoch_class_y_loss += class_y_loss\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    epoch_class_y_loss /= len(test_loader.dataset)\n",
        "    acc = test_corr/len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, epoch_class_y_loss, acc\n",
        "  "
      ],
      "metadata": {
        "id": "dT7E0C3nM3qh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, diva, optimizer, end_epoch, start_epoch=0):\n",
        "    epoch_loss_sup = []\n",
        "    epoch_loss_y = []\n",
        "\n",
        "    y_loss_test = []\n",
        "    test_loss = []\n",
        "    test_acc_lst = []\n",
        "\n",
        "    for epoch in range(start_epoch+1, end_epoch+1):\n",
        "        avg_epoch_losses_sup, avg_epoch_class_y_loss = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
        "        str_loss_sup = avg_epoch_losses_sup\n",
        "        epoch_loss_sup.append(avg_epoch_losses_sup)\n",
        "        epoch_loss_y.append(avg_epoch_class_y_loss)\n",
        "        str_print = \"epoch {}: avg train loss {}\".format(epoch, str_loss_sup)\n",
        "        str_print += \", class y train loss {}\".format(avg_epoch_class_y_loss)\n",
        "        print(str_print)\n",
        "\n",
        "        test_lss, epoch_class_y_loss_test, test_acc = test_single_epoch(test_loader, diva, epoch)\n",
        "        test_loss.append(test_lss)\n",
        "        y_loss_test.append(epoch_class_y_loss_test)\n",
        "        test_acc_lst.append(test_acc)\n",
        "        str_print = \"epoch {}: avg test loss {}\".format(epoch, test_lss)\n",
        "        str_print += \", class y test loss {}\".format(epoch_class_y_loss_test)\n",
        "        str_print += \", test accuracy {}\".format(test_acc)\n",
        "        print(str_print)\n",
        "    if writer is not None:    \n",
        "      writer.flush()\n",
        "    return epoch_loss_sup, epoch_loss_y"
      ],
      "metadata": {
        "id": "npLjVGs0jHYn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "nI4-NzHxjmci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "48B39rFl79Yh"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(RNA_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(RNA_dataset_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J6y2Ek2677z1"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(diva.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0m47XoL87oLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f5cd28-01f7-418f-8701-4a9741ee0ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6: 0batch [00:00, ?batch/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "Epoch 6: 272batch [45:39, 10.07s/batch, loss=4.45e+4, y_loss=0.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6: avg train loss 41661.75390625, class y train loss 0.45483437180519104\n",
            "epoch 6: avg test loss 41588.2265625, class y test loss 0.4445858597755432, test accuracy 0.8555876621194812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 272batch [45:27, 10.03s/batch, loss=3.99e+4, y_loss=0.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7: avg train loss 41470.96484375, class y train loss 0.41649219393730164\n",
            "epoch 7: avg test loss 41282.8828125, class y test loss 0.40967127680778503, test accuracy 0.9122370808413413\n"
          ]
        }
      ],
      "source": [
        "lss, eplss = train(train_loader, diva, optimizer, 7, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "14_0zzMCtR7Y"
      },
      "outputs": [],
      "source": [
        "torch.save(diva.state_dict(), f'{link}/stampdiva_v3.0.2.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5JUqEE7bHGjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710ed728-b0f3-4be3-e028-6593f958dc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8: 0batch [00:00, ?batch/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "Epoch 8: 272batch [45:21, 10.01s/batch, loss=4.2e+4, y_loss=0.519]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8: avg train loss 41169.57421875, class y train loss 0.390360563993454\n",
            "epoch 8: avg test loss 41081.05078125, class y test loss 0.4185554087162018, test accuracy 0.9246690410590687\n"
          ]
        }
      ],
      "source": [
        "lss, eplss = train(train_loader, diva, optimizer, 8, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uqYgruvcHGjP"
      },
      "outputs": [],
      "source": [
        "torch.save(diva.state_dict(), f'{link}/stampdiva_v3.0.3.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gl6VY6zFHDg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "whsgNltzXDhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling from trained model"
      ],
      "metadata": {
        "id": "VfcwhSNIjqIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "blYW4SMZG4fv"
      },
      "outputs": [],
      "source": [
        "a = next(enumerate(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "deiEYKxlmphu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e935cf69-8fe9-433d-a3f4-cc678c2df729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    diva.eval()\n",
        "    d = a[1][2][:9].to(DEVICE).float()\n",
        "    x = a[1][0][:9].to(DEVICE).float()\n",
        "    y = a[1][1][:9].to(DEVICE).float()\n",
        "    x_1, x_2, x_3, _, _, _, _, _, _, _, _, _, _, _ = diva(d,x,y)\n",
        "    out = diva.px.reconstruct_image(x_1, x_2, x_3)\n",
        "    #sample_x = sample(x_recon.cpu().numpy(), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4NWGV4Xd7bn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c153a9c7-aef2-45af-a212-cad4a63a1ed9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x3600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(50,50))\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
        "for i in range(9):\n",
        "  ax[i//3, i%3].imshow(out[i])\n",
        "plt.savefig('divastamprecon.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OE3qVVFFLaPm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "08b76ed8-5e60-42e8-da58-65c2dbad6681"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
        "for i in range(9):\n",
        "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
        "  \n",
        "plt.savefig('divastamporg.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RRQU05xQEx28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "StampDIVA",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merkelmauer/mirna/blob/main/SimpleVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D7JeCpd2Nep",
        "outputId": "7cb36c58-4188-418b-8d0a-8ca545cbec7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchvision\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = '/content/drive/MyDrive/master'"
      ],
      "metadata": {
        "id": "4dy2BXayokxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "MgMR4QspjvRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgKU5wNzDK4F",
        "outputId": "fbc6cf07-4dbf-4cfd-8869-790f7dbefdbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
        "sys.path.insert(0, link)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.distributions as dist\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torchinfo import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuLsYxyh6_ZM"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Classes"
      ],
      "metadata": {
        "id": "axFkNf0cjx2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae7NZhZGj7Zi"
      },
      "outputs": [],
      "source": [
        "class diva_args:\n",
        "\n",
        "    def __init__(self, z_dim=128, d_dim=45, x_dim=15000, y_dim=2,\n",
        "                 aux_loss_multiplier_y=10, aux_loss_multiplier_d=0,\n",
        "                 beta=1\n",
        "                 ):\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.d_dim = d_dim\n",
        "        self.x_dim = x_dim\n",
        "        self.y_dim = y_dim\n",
        "        self.aux_loss_multiplier_y = aux_loss_multiplier_y\n",
        "        self.aux_loss_multiplier_d = aux_loss_multiplier_d\n",
        "        self.beta = beta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class"
      ],
      "metadata": {
        "id": "tb1vH-a1j7Rf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6ouvuZX3WPs"
      },
      "outputs": [],
      "source": [
        "class MicroRNADataset(Dataset):\n",
        "\n",
        "    def __init__(self, cat_data=True, ds='train'):\n",
        "        \n",
        "        # loading images\n",
        "        \n",
        "        if not cat_data:\n",
        "            print('Loading and Converting Images! (~90min)')\n",
        "            images = np.load(f'/{link}/modmirbase_{ds}_images.npz')['arr_0']/255\n",
        "            self.images = self.im2col(images, ds)\n",
        "        else:\n",
        "            print('Loading Converted Images (~1min)')\n",
        "            self.images = np.load(f'/{link}/modmirbase_{ds}_images_wbrgby.npz')#['arr_0']\n",
        "        \n",
        "        \n",
        "        # loading labels\n",
        "        print('Loading Labels! (~10s)')     \n",
        "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
        "        labels = np.load(f'/{link}/modmirbase_{ds}_labels.npz')['arr_0']\n",
        "        self.labels = ohe.fit_transform(labels)\n",
        "        \n",
        "        \n",
        "        # loading names\n",
        "        print('Loading Names! (~5s)')\n",
        "        names =  np.load(f'/{link}/modmirbase_{ds}_names.npz')['arr_0']\n",
        "        names = [i.decode('utf-8') for i in names]\n",
        "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
        "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
        "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
        "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
        "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
        "                        'ppt', 'tca', 'dme', 'sbi']\n",
        "        # assigning a species label to each observation from species\n",
        "        # with more than 200 observations from past research\n",
        "        self.names = []\n",
        "        for i in names:\n",
        "            append = False\n",
        "            for j in self.species:\n",
        "                if j in i.lower():\n",
        "                    self.names.append(j)\n",
        "                    append = True\n",
        "                    break\n",
        "            if not append:\n",
        "                if 'random' in i.lower() or i.isdigit():\n",
        "                    self.names.append('hsa')\n",
        "                else:\n",
        "                    self.names.append('notfound')\n",
        "        \n",
        "        # performing one hot encoding\n",
        "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
        "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
        "      \n",
        "    def __len__(self):\n",
        "        return(self.images.shape[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        d = self.names_ohe[idx]\n",
        "        y = self.labels[idx]\n",
        "        x = self.images[idx]\n",
        "        x = np.transpose(x, (2,0,1))\n",
        "        return (x, y, d)\n",
        "\n",
        "    def im2col(self, images, ds):\n",
        "        \"\"\"\n",
        "        One hot encodes images\n",
        "        0: black\n",
        "        1: white\n",
        "        2: red\n",
        "        3: green\n",
        "        4: blue\n",
        "        5: yellow\n",
        "        \"\"\"\n",
        "        out_shape = (images.shape[0],images.shape[1],images.shape[2],6)\n",
        "        out_array = np.zeros(out_shape)\n",
        "        for i in range(out_array.shape[0]):\n",
        "            print(f'at image {i} out of {out_array.shape[0]}!')\n",
        "            for j in range(out_array.shape[1]):\n",
        "                for k in range(out_array.shape[2]):\n",
        "                    #print(images[i,j,k].shape, images[i,j,k])\n",
        "                    curr = images[i,j,k]\n",
        "                    if (curr==np.array([0,0,0])).all():\n",
        "                        out_array[i,j,k,0] = 1\n",
        "                    elif (curr==np.array([1,1,1])).all():\n",
        "                        out_array[i,j,k,1] = 1\n",
        "                    elif (curr==np.array([1,0,0])).all():\n",
        "                        out_array[i,j,k,2] = 1\n",
        "                    elif (curr==np.array([0,1,0])).all():\n",
        "                        out_array[i,j,k,3] = 1\n",
        "                    elif (curr==np.array([0,0,1])).all():\n",
        "                        out_array[i,j,k,4] = 1\n",
        "                    elif (curr==np.array([1,1,0])).all():\n",
        "                        out_array[i,j,k,5] = 1\n",
        "                    else:\n",
        "                        print(\"big error!!!\")\n",
        "        print('saving new file!')\n",
        "        with open(f'/{link}/modmirbase_{ds}_images_wbrgby.npz', 'wb') as f:\n",
        "            np.save(f, out_array)\n",
        "        return out_array\n",
        "                    \n",
        "                    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder classes"
      ],
      "metadata": {
        "id": "Xxj-WGXMj-Ne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKizJuchX9uG"
      },
      "outputs": [],
      "source": [
        "# Decoders\n",
        "class px(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
        "        super(px, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Sequential(nn.Linear(z_dim, 128, bias=False),\n",
        "                                 nn.ReLU())\n",
        "        self.up1 = nn.Upsample(scale_factor=5)\n",
        "        self.de1 = nn.Sequential(nn.ConvTranspose2d(32, 64, kernel_size=5, stride=1, padding=2, bias=False),\n",
        "                                 nn.ReLU())\n",
        "        self.up2 = nn.Upsample(scale_factor=5)\n",
        "        self.de2 = nn.Sequential(nn.ConvTranspose2d(64, 128, kernel_size=5, stride=1, padding=2, bias=False),\n",
        "                                 nn.ReLU())\n",
        "        self.de3 = nn.Sequential(nn.Conv2d(128, 6, kernel_size=1, stride=1),\n",
        "                                 nn.Softmax(dim=1))\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.de1[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.de2[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.de3[0].weight)\n",
        "        self.de3[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.fc1(z)\n",
        "        h = h.view(-1, 32, 1, 4)\n",
        "        h = self.up1(h)\n",
        "        h = self.de1(h)\n",
        "        h = self.up2(h)\n",
        "        h = self.de2(h)\n",
        "        loc_img = self.de3(h)\n",
        "\n",
        "        return loc_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y8G2S1zxzTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3779af50-5db2-4620-bb94-d58c1553dedb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "px                                       --                        --\n",
              "├─Sequential: 1-1                        [1, 128]                  --\n",
              "│    └─Linear: 2-1                       [1, 128]                  16,384\n",
              "│    └─ReLU: 2-2                         [1, 128]                  --\n",
              "├─Upsample: 1-2                          [1, 32, 5, 20]            --\n",
              "├─Sequential: 1-3                        [1, 64, 5, 20]            --\n",
              "│    └─ConvTranspose2d: 2-3              [1, 64, 5, 20]            51,200\n",
              "│    └─ReLU: 2-4                         [1, 64, 5, 20]            --\n",
              "├─Upsample: 1-4                          [1, 64, 25, 100]          --\n",
              "├─Sequential: 1-5                        [1, 128, 25, 100]         --\n",
              "│    └─ConvTranspose2d: 2-5              [1, 128, 25, 100]         204,800\n",
              "│    └─ReLU: 2-6                         [1, 128, 25, 100]         --\n",
              "├─Sequential: 1-6                        [1, 6, 25, 100]           --\n",
              "│    └─Conv2d: 2-7                       [1, 6, 25, 100]           774\n",
              "│    └─Softmax: 2-8                      [1, 6, 25, 100]           --\n",
              "==========================================================================================\n",
              "Total params: 273,158\n",
              "Trainable params: 273,158\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 519.07\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 2.73\n",
              "Params size (MB): 1.09\n",
              "Estimated Total Size (MB): 3.83\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
        "# summary(pzy_, (1,2))\n",
        "pzy_ = px(0, 75000, 0, 128)\n",
        "summary(pzy_, (1,128))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Endcoder Classes"
      ],
      "metadata": {
        "id": "YmNnZWXvkCDP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ZFH8gYl_-z"
      },
      "outputs": [],
      "source": [
        "# Encoders\n",
        "class qz(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
        "        super(qz, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, bias=False),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc11 = nn.Sequential(nn.Linear(2112, z_dim))\n",
        "        self.fc12 = nn.Sequential(nn.Linear(2112, z_dim), nn.Softplus())\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
        "        self.fc11[0].bias.data.zero_()\n",
        "        torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
        "        self.fc12[0].bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(-1, 2112)\n",
        "        zd_loc = self.fc11(h)\n",
        "        zd_scale = self.fc12(h) + 1e-7\n",
        "\n",
        "        return zd_loc, zd_scale\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_qz = qz(0, 75000, 0, 128)\n",
        "summary(_qz, (1,6,25,100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_1MOlRzGaPR",
        "outputId": "439407a6-5093-4fc1-ecdb-1158c7b39bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "qz                                       --                        --\n",
              "├─Sequential: 1-1                        [1, 32, 3, 22]            --\n",
              "│    └─Conv2d: 2-1                       [1, 16, 21, 96]           2,400\n",
              "│    └─ReLU: 2-2                         [1, 16, 21, 96]           --\n",
              "│    └─MaxPool2d: 2-3                    [1, 16, 10, 48]           --\n",
              "│    └─Conv2d: 2-4                       [1, 32, 6, 44]            12,800\n",
              "│    └─ReLU: 2-5                         [1, 32, 6, 44]            --\n",
              "│    └─MaxPool2d: 2-6                    [1, 32, 3, 22]            --\n",
              "├─Sequential: 1-2                        [1, 128]                  --\n",
              "│    └─Linear: 2-7                       [1, 128]                  270,464\n",
              "├─Sequential: 1-3                        [1, 128]                  --\n",
              "│    └─Linear: 2-8                       [1, 128]                  270,464\n",
              "│    └─Softplus: 2-9                     [1, 128]                  --\n",
              "==========================================================================================\n",
              "Total params: 556,128\n",
              "Trainable params: 556,128\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 8.76\n",
              "==========================================================================================\n",
              "Input size (MB): 0.06\n",
              "Forward/backward pass size (MB): 0.33\n",
              "Params size (MB): 2.22\n",
              "Estimated Total Size (MB): 2.61\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary predictors classes"
      ],
      "metadata": {
        "id": "601pquQEkE6-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhIOunSHcc9b"
      },
      "outputs": [],
      "source": [
        "# Auxiliary tasks\n",
        "class qd(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
        "        super(qd, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(z_dim, d_dim)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc1.bias.data.zero_()\n",
        "\n",
        "    def forward(self, zd):\n",
        "        h = F.relu(zd)\n",
        "        loc_d = self.fc1(h)\n",
        "\n",
        "        return loc_d\n",
        "\n",
        "\n",
        "class qy(nn.Module):\n",
        "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
        "        super(qy, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(z_dim, y_dim)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc1.bias.data.zero_()\n",
        "\n",
        "    def forward(self, zy):\n",
        "        h = F.relu(zy)\n",
        "        loc_y = self.fc1(h)\n",
        "\n",
        "        return loc_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full model class"
      ],
      "metadata": {
        "id": "vn_gJdNSkH_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgR5BnQN1WWG"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(VAE, self).__init__()\n",
        "        self.z_dim = args.z_dim\n",
        "        self.d_dim = args.d_dim\n",
        "        self.x_dim = args.x_dim\n",
        "        self.y_dim = args.y_dim\n",
        "\n",
        "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
        "\n",
        "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
        "\n",
        "        self.qd = qd(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
        "        self.qy = qy(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
        "\n",
        "        self.aux_loss_multiplier_y = args.aux_loss_multiplier_y\n",
        "        self.aux_loss_multiplier_d = args.aux_loss_multiplier_d\n",
        "\n",
        "        self.beta = args.beta\n",
        "\n",
        "        self.cuda()\n",
        "\n",
        "    def forward(self, d, x, y):\n",
        "        # Encode\n",
        "        z_q_loc, z_q_scale = self.qz(x)\n",
        "\n",
        "        # Reparameterization trick\n",
        "        qz = dist.Normal(z_q_loc, z_q_scale)\n",
        "        z_q = qz.rsample()\n",
        "\n",
        "        # Decode\n",
        "        x_recon = self.px(z_q)\n",
        "\n",
        "        # Priors\n",
        "        z_p_loc, z_p_scale = torch.zeros(z_q.size()[0], self.z_dim).cuda(),\\\n",
        "                               torch.ones(z_q.size()[0], self.z_dim).cuda()\n",
        "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
        "\n",
        "        # Auxiliary losses\n",
        "        d_hat = self.qd(z_q)\n",
        "        y_hat = self.qy(z_q)\n",
        "\n",
        "        return x_recon, d_hat, y_hat, qz, pz, z_q\n",
        "\n",
        "    def loss_function(self, d, x, y):\n",
        "        x_recon, d_hat, y_hat, qz, pz, z_q = self.forward(d, x, y)\n",
        "\n",
        "        x_recon = x_recon.view(-1, 6)\n",
        "        x_target = x.view(-1, 6)\n",
        "        CE_x = F.cross_entropy(x_recon, x_target, reduction='sum')\n",
        "\n",
        "        KL_z = torch.sum(pz.log_prob(z_q) - qz.log_prob(z_q))\n",
        "\n",
        "        _, d_target = d.max(dim=1)\n",
        "        CE_d = F.cross_entropy(d_hat, d_target, reduction='sum')\n",
        "\n",
        "        _, y_target = y.max(dim=1)\n",
        "        CE_y = F.cross_entropy(y_hat, y_target, reduction='sum')\n",
        "\n",
        "        return CE_x - self.beta * KL_z + self.aux_loss_multiplier_d * CE_d + self.aux_loss_multiplier_y * CE_y, CE_y\n",
        "\n",
        "    def classifier(self, x):\n",
        "        \"\"\"\n",
        "        classify an image (or a batch of images)\n",
        "        :param xs: a batch of scaled vectors of pixels from an image\n",
        "        :return: a batch of the corresponding class labels (as one-hots)\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            z_q_loc, z_q_scale = self.qz(x)\n",
        "            z = z_q_loc\n",
        "            alpha = F.softmax(self.qd(z), dim=1)\n",
        "\n",
        "            # get the index (digit) that corresponds to\n",
        "            # the maximum predicted class probability\n",
        "            res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "            # convert the digit(s) to one-hot tensor(s)\n",
        "            d = x.new_zeros(alpha.size())\n",
        "            d = d.scatter_(1, ind, 1.0)\n",
        "\n",
        "            alpha = F.softmax(self.qy(z), dim=1)\n",
        "\n",
        "            # get the index (digit) that corresponds to\n",
        "            # the maximum predicted class probability\n",
        "            res, ind = torch.topk(alpha, 1)\n",
        "\n",
        "            # convert the digit(s) to one-hot tensor(s)\n",
        "            y = x.new_zeros(alpha.size())\n",
        "            y = y.scatter_(1, ind, 1.0)\n",
        "\n",
        "        return d, y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "LdOsLfYJjBBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing model"
      ],
      "metadata": {
        "id": "R_H_mVMUszt2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJE0HTJE1ayP"
      },
      "outputs": [],
      "source": [
        "default_args = diva_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxIMSeUD1949"
      },
      "outputs": [],
      "source": [
        "vae = VAE(default_args).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#diva.load_state_dict(torch.load(f'{link}/diva_v2.5.pth'))"
      ],
      "metadata": {
        "id": "s5C6mSJTDLtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset"
      ],
      "metadata": {
        "id": "rH1E5J-ps3GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_dataset = MicroRNADataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myflmDPxjV40",
        "outputId": "a4c7717e-089e-48ec-c1b8-b4a09e6b556c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Converted Images (~1min)\n",
            "Loading Labels! (~10s)\n",
            "Loading Names! (~5s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_dataset_test = MicroRNADataset('test')"
      ],
      "metadata": {
        "id": "ut2P5RSaMoDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d31a3fc-6645-4576-e967-82c014160c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Converted Images (~1min)\n",
            "Loading Labels! (~10s)\n",
            "Loading Names! (~5s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ3JG664vsnE"
      },
      "outputs": [],
      "source": [
        "#summary(diva, [(1,45),(1,6,25,100),(1,2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training functions"
      ],
      "metadata": {
        "id": "YdYaqWvbjN26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVGq463Y2m20"
      },
      "outputs": [],
      "source": [
        "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    epoch_class_y_loss = 0\n",
        "\n",
        "    no_batches = 0\n",
        "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
        "                                     desc=f'Epoch {epoch}')\n",
        "    for batch_idx, (x, y, d) in pbar:\n",
        "        # To device\n",
        "        # print(x)\n",
        "        # print(y)\n",
        "        # print(d)\n",
        "        x, y, d = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
        "\n",
        "        # if (epoch % 50 == 0) and (batch_idx == 1):\n",
        "        #     save_reconstructions(model, d, x, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, class_y_loss = model.loss_function(d.float(), x.float(), y.float())\n",
        "        _, y_pred = model.classifier(x.float())\n",
        "        acc = ((y == y_pred).all(axis=1)*1.0).mean().item()\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        writer.add_scalar(\"y_loss/train\", class_y_loss, epoch)\n",
        "        writer.add_scalar(\"y_acc/train\", acc, epoch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_postfix(loss=loss.item()/x.shape[0], \n",
        "                         y_loss = class_y_loss.item()/x.shape[0])\n",
        "        train_loss += loss\n",
        "        epoch_class_y_loss += class_y_loss\n",
        "        no_batches += 1\n",
        "        # print(f'finished batch {no_batches}!')\n",
        "        # if no_batches == 25:\n",
        "        #     break\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    epoch_class_y_loss /= len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, epoch_class_y_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_single_epoch(test_loader, model, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    epoch_class_y_loss = 0\n",
        "    test_corr = 0\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x,y,d) in enumerate(test_loader):\n",
        "            x, y, d = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
        "            loss, class_y_loss = model.loss_function(d.float(), x.float(), y.float())\n",
        "            _, y_pred = model.classifier(x.float())\n",
        "            test_corr += (y == y_pred).all(axis=1).sum().item()\n",
        "            acc = ((y == y_pred).all(axis=1)*1.).mean().item()\n",
        "            \n",
        "            writer.add_scalar(\"Loss/test\", loss, epoch)\n",
        "            writer.add_scalar(\"y_loss/test\", class_y_loss, epoch)\n",
        "            writer.add_scalar(\"y_acc/test\", acc, epoch)\n",
        "            test_loss += loss\n",
        "            epoch_class_y_loss += class_y_loss\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    epoch_class_y_loss /= len(test_loader.dataset)\n",
        "    acc = test_corr/len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, epoch_class_y_loss, acc\n",
        "  "
      ],
      "metadata": {
        "id": "dT7E0C3nM3qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, diva, optimizer, end_epoch, start_epoch=0):\n",
        "    epoch_loss_sup = []\n",
        "    epoch_loss_y = []\n",
        "\n",
        "    y_loss_test = []\n",
        "    test_loss = []\n",
        "    test_acc_lst = []\n",
        "\n",
        "    for epoch in range(start_epoch+1, end_epoch+1):\n",
        "        avg_epoch_losses_sup, avg_epoch_class_y_loss = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
        "        str_loss_sup = avg_epoch_losses_sup\n",
        "        epoch_loss_sup.append(avg_epoch_losses_sup)\n",
        "        epoch_loss_y.append(avg_epoch_class_y_loss)\n",
        "        str_print = \"epoch {}: avg train loss {}\".format(epoch, str_loss_sup)\n",
        "        str_print += \", class y train loss {}\".format(avg_epoch_class_y_loss)\n",
        "        print(str_print)\n",
        "\n",
        "        test_lss, epoch_class_y_loss_test, test_acc = test_single_epoch(test_loader, diva, epoch)\n",
        "        test_loss.append(test_lss)\n",
        "        y_loss_test.append(epoch_class_y_loss_test)\n",
        "        test_acc_lst.append(test_acc)\n",
        "        str_print = \"epoch {}: avg test loss {}\".format(epoch, test_lss)\n",
        "        str_print += \", class y test loss {}\".format(epoch_class_y_loss_test)\n",
        "        str_print += \", test accuracy {}\".format(test_acc)\n",
        "        print(str_print)\n",
        "        \n",
        "    writer.flush()\n",
        "    return epoch_loss_sup, epoch_loss_y"
      ],
      "metadata": {
        "id": "npLjVGs0jHYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "nI4-NzHxjmci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48B39rFl79Yh"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(RNA_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(RNA_dataset_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# diva.eval()\n",
        "# x,y,d = next(enumerate(train_loader))[1]\n",
        "# x = x.to(DEVICE)\n",
        "# d_pred, y_pred = diva.classifier(x.float())"
      ],
      "metadata": {
        "id": "wYUc05O-WJIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (y_pred == y.to(DEVICE)).all(axis=1).sum().item()"
      ],
      "metadata": {
        "id": "Xu00DTXnYY-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6y2Ek2677z1"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(vae.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "25t-KQho0_Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m47XoL87oLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4bbe6b-8ba0-4887-ff03-2298cc6fe186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 101: 272batch [01:01,  4.44batch/s, loss=4.43e+3, y_loss=0.0906]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 101: avg train loss 4426.2548828125, class y train loss 0.12601345777511597\n",
            "epoch 101: avg test loss 4426.0830078125, class y test loss 0.11172561347484589, test accuracy 0.9718902105354108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 102: 272batch [01:01,  4.41batch/s, loss=4.42e+3, y_loss=0.108]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 102: avg train loss 4426.07568359375, class y train loss 0.11901376396417618\n",
            "epoch 102: avg test loss 4425.7841796875, class y test loss 0.12876425683498383, test accuracy 0.94979983295412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 103: 272batch [01:01,  4.39batch/s, loss=4.43e+3, y_loss=0.318]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 103: avg train loss 4425.94677734375, class y train loss 0.121357262134552\n",
            "epoch 103: avg test loss 4425.85302734375, class y test loss 0.1182638555765152, test accuracy 0.9616370496241468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 104: 272batch [01:01,  4.39batch/s, loss=4.43e+3, y_loss=0.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 104: avg train loss 4425.94970703125, class y train loss 0.11878436803817749\n",
            "epoch 104: avg test loss 4425.7333984375, class y test loss 0.12917672097682953, test accuracy 0.9741942916390657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 105: 272batch [01:01,  4.40batch/s, loss=4.43e+3, y_loss=0.148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 105: avg train loss 4425.8095703125, class y train loss 0.11919622868299484\n",
            "epoch 105: avg test loss 4426.09228515625, class y test loss 0.11068164557218552, test accuracy 0.9642003398519627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 106: 272batch [01:01,  4.40batch/s, loss=4.43e+3, y_loss=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 106: avg train loss 4425.828125, class y train loss 0.11820089817047119\n",
            "epoch 106: avg test loss 4425.69677734375, class y test loss 0.12283945828676224, test accuracy 0.9551568215201175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 107: 272batch [01:01,  4.39batch/s, loss=4.43e+3, y_loss=0.0988]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 107: avg train loss 4425.81005859375, class y train loss 0.11867193877696991\n",
            "epoch 107: avg test loss 4425.3935546875, class y test loss 0.10917624086141586, test accuracy 0.9726678379078944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 108: 272batch [01:01,  4.40batch/s, loss=4.43e+3, y_loss=0.248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 108: avg train loss 4425.6591796875, class y train loss 0.11851505935192108\n",
            "epoch 108: avg test loss 4425.3701171875, class y test loss 0.11738640069961548, test accuracy 0.9673396503556925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 109: 272batch [01:01,  4.39batch/s, loss=4.42e+3, y_loss=0.0316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 109: avg train loss 4425.5146484375, class y train loss 0.11892436444759369\n",
            "epoch 109: avg test loss 4425.388671875, class y test loss 0.10728367418050766, test accuracy 0.9716598024250453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 110: 272batch [01:01,  4.41batch/s, loss=4.42e+3, y_loss=0.0256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 110: avg train loss 4425.47119140625, class y train loss 0.11580397188663483\n",
            "epoch 110: avg test loss 4425.27490234375, class y test loss 0.10953828692436218, test accuracy 0.9631635033553181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 111: 272batch [01:01,  4.41batch/s, loss=4.43e+3, y_loss=0.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 111: avg train loss 4425.47802734375, class y train loss 0.11586325615644455\n",
            "epoch 111: avg test loss 4424.9765625, class y test loss 0.11575073003768921, test accuracy 0.9675988594798537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 112: 272batch [01:01,  4.40batch/s, loss=4.43e+3, y_loss=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 112: avg train loss 4425.3671875, class y train loss 0.11685682088136673\n",
            "epoch 112: avg test loss 4425.33740234375, class y test loss 0.11339357495307922, test accuracy 0.9594481725756747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 113: 272batch [01:01,  4.40batch/s, loss=4.43e+3, y_loss=0.0424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 113: avg train loss 4425.2998046875, class y train loss 0.11858968436717987\n",
            "epoch 113: avg test loss 4425.1015625, class y test loss 0.11065749824047089, test accuracy 0.9660724057486824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 114: 272batch [01:01,  4.41batch/s, loss=4.43e+3, y_loss=0.374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 114: avg train loss 4425.1943359375, class y train loss 0.11775655299425125\n",
            "epoch 114: avg test loss 4424.931640625, class y test loss 0.10444515198469162, test accuracy 0.9659860027072953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 115: 272batch [01:01,  4.40batch/s, loss=4.42e+3, y_loss=0.0431]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 115: avg train loss 4425.1259765625, class y train loss 0.11550169438123703\n",
            "epoch 115: avg test loss 4424.69287109375, class y test loss 0.10795298963785172, test accuracy 0.9728118429768727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 116: 272batch [01:01,  4.39batch/s, loss=4.42e+3, y_loss=0.0177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 116: avg train loss 4425.15087890625, class y train loss 0.11712789535522461\n",
            "epoch 116: avg test loss 4425.97802734375, class y test loss 0.10626400262117386, test accuracy 0.969672532473143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 117: 272batch [01:01,  4.40batch/s, loss=4.44e+3, y_loss=0.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 117: avg train loss 4424.91796875, class y train loss 0.11442460119724274\n",
            "epoch 117: avg test loss 4425.07568359375, class y test loss 0.10752453655004501, test accuracy 0.9699317415973042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 118: 272batch [01:01,  4.40batch/s, loss=4.41e+3, y_loss=0.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 118: avg train loss 4424.8935546875, class y train loss 0.11469559371471405\n",
            "epoch 118: avg test loss 4424.853515625, class y test loss 0.11707602441310883, test accuracy 0.9552720255753002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 119: 272batch [01:01,  4.40batch/s, loss=4.42e+3, y_loss=0.0848]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 119: avg train loss 4424.9599609375, class y train loss 0.11540640145540237\n",
            "epoch 119: avg test loss 4424.88134765625, class y test loss 0.11634693294763565, test accuracy 0.9593329685204919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 120: 272batch [01:01,  4.40batch/s, loss=4.42e+3, y_loss=0.0335]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 120: avg train loss 4424.791015625, class y train loss 0.11367254704236984\n",
            "epoch 120: avg test loss 4424.40478515625, class y test loss 0.10415253043174744, test accuracy 0.9737334754183348\n"
          ]
        }
      ],
      "source": [
        "lss, eplss = train(train_loader, vae, optimizer, 120, 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "S6KKD9fmL3n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14_0zzMCtR7Y"
      },
      "outputs": [],
      "source": [
        "torch.save(vae.state_dict(), f'{link}/vae_v1.2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "whsgNltzXDhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling from trained model"
      ],
      "metadata": {
        "id": "VfcwhSNIjqIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaSz6PSlII26"
      },
      "outputs": [],
      "source": [
        "def sample(x, mean=False):\n",
        "    \"\"\"\n",
        "    takes sample for each pixel given probabilities\n",
        "    input: reconstructed x (shape: -1,6,25,100)\n",
        "    output: sample from x (shape: -1,25,100,3)\n",
        "    \"\"\"\n",
        "    color_dict = {1: np.array([1,1,1]), # white\n",
        "                  0: np.array([0,0,0]), # black\n",
        "                  2: np.array([1,0,0]), # red\n",
        "                  3: np.array([0,1,0]), # green\n",
        "                  4: np.array([0,0,1]), # blue\n",
        "                  5: np.array([1,1,0])  # yellow\n",
        "                  }\n",
        "    out = np.zeros((x.shape[0],x.shape[2],x.shape[3], 3))\n",
        "    for i in range(x.shape[0]):\n",
        "      for j in range(x.shape[2]):\n",
        "        for k in range(x.shape[3]):\n",
        "          p = x[i,:,j,k]\n",
        "          p = p.astype(np.float64)\n",
        "          p += 1e-7\n",
        "          #print(p)\n",
        "          p /= p.sum()\n",
        "          #print(p, sum(p))\n",
        "          if not mean:\n",
        "            pix = np.random.choice(np.arange(6), p=p)\n",
        "          else:\n",
        "            pix = np.argmax(p)\n",
        "          out[i,j,k] = color_dict[pix]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DMiSSjWMSzh"
      },
      "outputs": [],
      "source": [
        "def decode(x):\n",
        "    \"\"\"\n",
        "    gives image in pixels given x\n",
        "    input: training x (shape: -1,6,25,100)\n",
        "    output:  x (shape: -1,25,100,3)\n",
        "    \"\"\"\n",
        "    color_dict = {1: np.array([1,1,1]), # white\n",
        "              0: np.array([0,0,0]), # black\n",
        "              2: np.array([1,0,0]), # red\n",
        "              3: np.array([0,1,0]), # green\n",
        "              4: np.array([0,0,1]), # blue\n",
        "              5: np.array([1,1,0])  # yellow\n",
        "              }\n",
        "    out = np.zeros((x.shape[0],x.shape[2],x.shape[3], 3))\n",
        "    for i in range(x.shape[0]):\n",
        "      for j in range(x.shape[2]):\n",
        "        for k in range(x.shape[3]):\n",
        "          for l in range(6):\n",
        "            if x[i,l,j,k] == 1:\n",
        "              out[i,j,k] = color_dict[l]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blYW4SMZG4fv"
      },
      "outputs": [],
      "source": [
        "a = next(enumerate(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahb9oyxiHHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe46a616-6dad-4c78-bb6c-5fa35702cac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([128, 6, 25, 100]), torch.Size([128, 2]), torch.Size([128, 45])]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "[h.shape for h in a[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deiEYKxlmphu"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    vae.eval()\n",
        "    d = a[1][2][:9].to(DEVICE).float()\n",
        "    x = a[1][0][:9].to(DEVICE).float()\n",
        "    y = a[1][1][:9].to(DEVICE).float()\n",
        "    x_recon, _, _, _, _, _ = vae(d,x,y)\n",
        "    sample_x = sample(x_recon.cpu().numpy(), True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NWGV4Xd7bn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "b47a6953-ff2e-47cb-ff88-b41561cb2928"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x3600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(50,50))\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
        "for i in range(9):\n",
        "  ax[i//3, i%3].imshow(sample_x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE3qVVFFLaPm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "b7e4ef66-2209-4c0a-fbff-bf933e5b8333"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADVCAYAAABOv6vWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZAV9bnw8e/TAzNssojIoqCiCKJodBCxXK+KwOsCVXEhxmtc6kUNccu9aq6iFlFSkVRpSa5EfEtusIIlShaVREBJJFAlOjPcyCojKCojICMOywCzPu8f3XPmzMzZ5pw+Z073PJ+pU3N6+/Wv+zn9nO5fL0dUFWOMMcHjdHQFjDHGpMcSuDHGBJQlcGOMCShL4MYYE1CWwI0xJqAsgRtjTEBllMBFZJKIbBWRbSLyC78qZTqWxTW8LLbhIuleBy4iBUA5MAHYCZQAP1LVzf5Vz+SaxTW8LLbhk8ke+Dhgm6p+rqq1wOvAFH+qZTqQxTW8LLYhk0kCPwH4Oqp7p9fPBJvFNbwstiHTJdszEJHpwHSAnj17Fo8aNSqj8urqYPP6OkazhS1dRzFq1Fa2bh3DmDF+1LZz2LFjB5WVlZJJGYniWkYZxQq6DtYVAyrI/57HeedlVG2TRLbjmgvV1fD1p4cY1asCRo7M6bzzWVlZWaWqDmgzQFXTegEXAsujuv8L+K9E0xQXF2tjoyo0qihaX+9oQYG2y+7dqoP4RncyRIcO/VK/+OIkHT68fWXkxE03qb75ZkfXIqbi4mJVn+Oq2qiNiqKoo6jWobVd3G6OFmpR0RHValR79Mj58nYWieKqacS2Ka5up8SZ6xFV7e7bMnz4oepFrFa99NKE4zU2+jbLQABKNUaMMmlCKQFGiMgpIlIITAPeTqegVM+jVlbCoEHpzCHXYi1QYB4allZc27N0mjfrom098qduWeHbNtukI56Ft3gx3Hpr7uebj9JO4KpaD/wMWA5sAd5Q1U1JZ9hqjg0NUFiY8lzbV8l286v8W4E3WvWbDLzvU/nZk3ZcU/woVXOY3vTOqI7+eB54tE3fR3mU53k+99XJgXRjG09NDXTv7lftmoT6C9R3GV0Hrqp/U9XTVfVUVZ2dUVle4OJ/o+8D2jYBta1T25KTjwOwCLg9afnxp48/v/ZN37QuOu6D7Gdc486jvcvXtNJS2OVLZa8w1jgh3/sG/IhtNtdRCW4rT3xLlsC0aclL6gyxhBzfiVlWFrt/PXUUUZTwGz2VcGzZQquTmW0/ECtWwOTJaZQftcXPnAlz5sQb8XbgtYRFXXoprFkTf/hIRrIdB9iRrFZ5oYw4gY3jEIfoS9/UJ2gK7Pr1UFyccNSlS2Hq1MTFzZ0LP/952/4zmclv+E3q9Qq5srJWX3TaAHQFoLYWunXzeYYp5dzkI81hDjOZmXF1giAQt9JXUUV/+met/MUs5lYSNKrNmeNmbWM6mUiTZ6NClyxetLZuHYwbl2Skt4Abs1eHAApEAs+GFodYib7UfTlLE7+Mjm4uyTfehSxJx2lfoT6XZ5KKXqfxPuPtXe/xwtiZ45fXCVxR9rOffvRLc/pYXcpylnEd16Fo3DY1Rb1jbYfok13t/7AocB3ueaPo6d3/4xjHOhxgPaSQvMKneX3sYhcODidxkte/7bpYx/8yjnGtpm3qap4msh4XLYLbb498MbRev7OZzVM85dvSdA6JP6PRR8x72MMQHOBEb0r3r5xyRjPam2I9EKtprDmWS5dqzKaxBSzgHu6JjNe2hHBvT3mWwJtPVFVrtXu1Qorr3/12bj4Ruk7XRTZ01TXA5azUlUxkIgB/5a9MJcYnQpX5Op8ZzGg7a1We0qf4FbOb56kKqt6/WJWdCvw1Mv4VXMEaVgOXgK5tVf8xjMbhMz5LbaGDTquA/qhWAoOiYv017kfzNNByiGzoUZPqWuCSSAxW6AocHK7jOt7mLW7kRtDFwK0s5FUc728GM2jxofJyfuzYmbYagLaXjTV9/vdr8w5XpVYyiObrfr/SryJxGMnIyHSxt/F/Ale1iGuseTZNO0/n8QAPeBVpHv6UPsVsnZ3o2vhAy58EXlvnnhWpOcphpye9egEHD0Hf5Ce7Pv8cRjrlMHo0mza57XZN57rWroVLLoFVq+Cqq1pO9/ZbcGN0k9rCV1ng3MU998Dv5sEDD0QN+9Wv3IKffhqARx91O+c6D4DjcI8zH8e5i4ULX22e5sYb4a3my2wnTIAP/hFV5oUXQkkpAOecAxs3Jl9NobH/APTrx759MGAA7NkDQ4a0Gmf75813423a5K4koLTEXXVr1sDlzio3EBMntpx2yR9jHlr9bt7veKApsHN+AzNn8vTT8LTzFMz+lc8LGU51dVBU1Nx9+DA4TjWO0zuyuX7vxbVJRQWcdFLLcj7dAmOcjZG4trZyZduwNnntNTfsd90FL8+HGTOAub91ez76KL+a3by5zpw5E8dxYr4WLlyY/orIA1m/ld4XGrcjRr9Ud9lbvdHkJccbEm+c6FlIjBucW1ehxYCMbojuIE311tjLFmsxY5YBaKvll3jjp9E/1eGmpaiDXNq19pJeNptWTVIY0gkiHO/QIhsvit2DVWjUBkWpdzTSBoFqYeFRPXKkSLtTrdoDPXCgl0JV04FS3Ndw0K2M0FGjNqtu8Ao7F/3447F6AR/q6ovQSz9A9QqvKu+ieg2qf0HfbFHWbXoHr6hOR/VF9IX7UJ5rGvaYguqsWU+4ZTzszuc+XlBQfYnp7nx/783jJvSHvKn85XrlGvTdd1G9EtW/oxdf/E9l9UXKBR/qx4zVc0E/AT1zA7pZ0REjtirbhusX+oUPN+G2leyW67Ti2uiuj4YGUZx6RdEutah2RY96DZ/dFT3U1Aha1Vvp8732+w7d2x89fjf6DegQ0C+HeuNsG66M2KqjNqMbOFPH8Enkw/LhBehFq9EPuFRBdcKE5S2q9eabP1Ruel1R9LYY1X7uuQcVVB/jGVXQJ5ilPPOYouhz+lxW1nu2+R3X4uJIy4gbV1QpqGuOa4tHJKB6ANXeqH7vTdcf1ai46tCo4re642zgTIVPItvgBRe4wz9Q9Ir3UZ3gdr/zTstt/pboxAGq96IvvHCf2/nws/rYM17/We70Dz/8rD733IPuvO9F9SX0DkV/r7/PUXQyQxZupTfGGNOB8qYJpWtX99ZcgMPaAzjEMQxCtQ+pHgptYQtwJuhGYB2U3A0XjIc1q4HHYeWTQFRD+JTruUHfilF6HfAJMIoH+YLnH4pxa/WcZ2HOI8wF5gIwH+6sA/4nMsqSN2HKFPi/U95hEv8Nk/4TaL757cO1cP75sG5+Ge6j+s4C0r6zOVB694Evq2A4/aCyHDiTwbqHiooKvrrQvWJh+KnwbjlM2QJnnQnrXwPOAcaOhbW/Bf6Ty3RVzE/HDTfA6ze4D/uI5+GHYXYfoOYJfvnLJ2ngcawVPAVdu0BtNdQc43b36A7Ve4FBsH8nVPWFfl5c9wxg8KBBVOzaBXwFRDWEjxrFWVs2Rq41ca0lcvPdlVfAlY8CE7n22mtQXdq2LgsWwEcfwbxzuJ9Puf9+mAPs5zF4fDbwJPC0/+sgT+RNAm+rJ3Awg+nPw70TEy7mYlaxyuu/HJgIXIN7Y0Asd3v/58YY9kvcM/GpeSsyj//2/rtnMVezhvGtxt1IZzqLCX3pyz72Ae7lZk2GMRTlq0j3FjbT+gaO8YxnDdG3s16NmwSWAv8PWMLNQD31rGAF0HSyah4ww+9F6TQK6EIddUBtnDH6AN8Dw4HjgN3AD7xhw2hO1OUk+i2Jy7iUlaz0ulLZgftpnP7t216DJmkCF5GhwKvAQNw1+bKqviAixwKLgZNx7/m+SVW/z15VfTRpIkyK8W3eyv3c375yFyzA/bC8mmzMZiUl7ZuHT/I2riecAF99FX/4uee2a5392Ptr9lOgHvjC7Xz88XRqmbc6Lq5RO1x9+8I+94uZgQNh1662o59+uvuIhEzdeaf7SqjpqPehzOeXZ1JpA68H/kNVRwPjgRkiMhr4BbBSVUcAK71uExwW13CyuHYiSffAVXUXsMt7f1BEtuD+DNMU4HJvtIXAB8R6PqdpI9YlhblmcQ0n3+OqjYCD40B9fcvrv4Mk/sPngq1dbeAicjJwLvARMND7sIDb0DUw2fTFFMd8bl2XLu7TzaAIONqeKrVyBkS1I59/vnsjT0tXe69MpPOE1WWRd//8Z+Ixy8sBtqcxj/T4E9fUn0jYi17sZ3/qFTzjjOa7nNatSzLytd6r/WYz22vfDYdM49r69vaCAjeJuwqBGjLbXmMZD3gXHaTpER7xrTb5LuXLCEWkF/BH4EFVPRA9zLtOMeaZBhGZLiKlIlK6d+/ejCpr/GdxDSeLayzPA/d1dCV8lVICF5GuuB+GRar6J6/3HhEZ7A0fDHwba1pVfVlVx6rq2AEDBtDY2HJ4QYF7a254LARu6ehKpMTPuCqNsUZroyc9OJjR1UV+uB/i/OrOHObwUMBPdvkZ10SKiuCo3zvgAFwMkavGTCJJE7iICPAKsEVVn4sa9DbwE+/9T4h/TZ7JQxbXcLK4JjMXuLejK+GbVNrALwL+HdggIv/y+j0G/Bp4Q0TuAr4EbkplhiKg6j7ZQgtwz5mHziICsGC+xtULLO6OeNvrboso4rDv7aXpeyjYO9mJ+BvXhE+hAegGHE63riZDojl8pKKIHAS25myG2XMcUNnRlcjASaqa/AdGU2RxzRt+x3UvUE2w1wkEP64QJ7a5vhNzq6qOzfE8fScipWFYDh9ZXENIVQeEYZ2EYRnisYdZGWNMQFkCN8aYgMp1An85x/PLlrAsh1/Csj7Cshx+CsM6CcMyxJTTk5jGGGP8Y00oxhgTUDlL4CIySUS2isg2EQnMk9BEZIeIbBCRf4lIqdfvWBF5T0Q+8/736+h6dhSLazhZXIMhJwlcRAqAF4HJwGjgR94jLoPi31T1B1GXItmjObG4hpXFNThytQc+Dtimqp+rai3wOol+jiP/TaH5J14WAlM7sC4dyeIaThbXgMhVAj8B+Dqqe6fXLwgUWCEiZSIy3euXxqM5Q8niGk4W14DI49/EzBsXq2qFiBwPvCcin0YPVFUVEbuUJ3gsruHUqeKaqz3wCmBoVPeJXr+8p6oV3v9vgT/jHl6m9GjOTsDiGk4W14DIVQIvAUaIyCkiUghMw328ZV4TkZ4ickzTe9yf8tmIPZqzicU1nCyuAZGTJhRVrReRnwHLgQJggapuysW8MzQQ+LP7iGW6AK+p6jIRKSGtR3OGi8U1nCyuwWF3YhpjTEDZnZjGGBNQlsCNMSagLIEbY0xAWQI3xpiAsgRujDEBZQncGGMCyhK4McYElCVwY4wJKEvgxhgTUJbAjTEmoCyBG2NMQFkCN8aYgLIEbowxAWUJ3BhjAsoSuDHGBJQlcGOMCShL4MYYE1CWwI0xJqAsgRtjTEBZAjfGmICyBG6MMQFlCdwYYwLKErgxxgSUJXBjjAkoS+DGGBNQlsCNMSagLIEbY0xAWQI3xpiAsgRujDEBZQncGGMCyhK4McYElCVwY4wJKEvgxhgTUBklcBGZJCJbRWSbiPzCr0qZjmVxDS+LbbiIqqY3oUgBUA5MAHYCJcCPVHWzf9UzuWZxDS+Lbfhksgc+Dtimqp+rai3wOjDFn2qZDmRxDS+Lbch0yWDaE4Cvo7p3AhckmuC4447Tk08+OYNZGj/s2LGDyspKiTPY4hpQSeIK7Yyt/3GtBTYAhcAYH8sNv7KyskpVHdC6fyYJPCUiMh2YDjBs2DBKS0tparWRRB+1BFTTn9bA2LFjMy4jVlxTpSiCBdBvHR3XhCoq4MIT4SuAEwGfyu0kROTLWP0zaUKpAIZGdZ/o9WtBVV9W1bGqOnbAgAGoguNAQUF6M92zB4YMSW9ak5K04pqqaqrpTe/Ma2nSkTS26cbVdIxMEngJMEJEThGRQmAa8HbyyZpPmsY+f5reSVXjmzTjagKg/bFNcpFDatdA7ML9rsgt1VTrF1xpN6Goar2I/AxYDhQAC1R1U/IpHUBRhS5doKEhelgN0Ac4mm61TIbSjqsqKljTSB5LK7aOEzcL1tRAnz5wNE8316efdv8/+WTH1iObMmoDV9W/AX/LrAoKWdro27SVW+N5StKJqzoOjrrt23HH6YijK4t5C2nFNqNVuAewNs9sye2dmGVlrXo0AF2997VAtxQKSS0JrFsH48ZF9Vi1Cq66Kk6RIT/OygNHOUpPeua2hWzxYrj11hzOMFzKKENxd8Jbq62Fbv5trr6bPRueeqpj5p1LAbuVvhIY5G+RS5bAtGn+ltmpxd9ijxyGXr1yWBXTsSorYZDP26tpIVgJPNG3uR970bYnnpYyoo+sUry8KHpde+/jNrEkO5FG27JSmq/xXSQW2s4GswRnHDuk6S0g8iaBJw3Rvn0Q77Km7dth5Mg45cYquanfW8CN7ttFi+D225PW0/jg4CHo2xcA9eK6hz0MidVWWl4Oo0fHLWoVq7gKr2ls2TK47roYY6n7OZg/H2bMsISQFo3zvtlBDtKXvlBVxT6nf9zNtbkUdctav95tp2nR5ulawQomMzn9aodcXiTwOq2jiKJIt/tlrJEvZdUYHxlvePS3dvQ0oJRSwoVcCLoGuNwbaQUwuU2h2lxsZKbN9Wj7MvE1rUP11mON1tCd7m3Gq9Iq+tPfm6hp2tjrOfoz0RwfjZrOiyutPzOvsRCHu3CAe5jH73iABxLG1uLcmgIF3jqvx72TsnVsqsG7vj+VtVau5YzGAca0/GrQ5s/PSl3JRCZ6/ZPHqmXcOkfsOjyB19dDYWFz99Gj4DiHcZxeOA6RV//+URPt3kWFcyInOV+5A087jfLPPsNxRuM4cI6zHoqL3XHXfgSXXOK+//vfYeJEWLbcnW7qVAAWv+Ge61r4KtzlLADHYZ4zA8eZi+M4MV9z5szJzQoKmMZG6OI0UO84FDYFL9bZrgMHoF8/9/1338GgQezetbvFOj7NcWDkSLZ8Co6zEcc5h2JnHTgOa71xLr/8cv6+0g0rwNK/Nn1mljAtzrmN384Fx3k+bmyjX/Pnz8/SmgqYRqXB6ULXrlBXV09RkbvDVVPjru+mcxsH9jeHNa7tn0eOmDdu3MQ555wDQEmpW9YlzhpWOZdHrjlYvmx5SrGKfs2cOTMLKyH/ZP1W+sxogq54/eL3kThlJC/BpCTGiou3LpMfkMcflrzMeG2pJl3prlFtPVq80xztKDN12btEOW+099Akk1dxMZFGEZEG1Xqvo4s7ytGjhVrEEa2mu/bgUIsWlO/caOjxx6PffDNIh7BTv2SoO3j4Nh2xtXncTxijoDp27Mf64YcXKBet1ks/QN/nCmXCcuXdid6of1FAbwL9A+htoK9wh4Lqvbyoeh/6nKIPP+uWO+sJrzH1sWf02Wc1sIqLi1X9jmsj2ggqDWg9jhYU1GltbRcF1cLCo3pE0e7V6KEe3jqs6q19+nyv3ynK3v56PLv1m0HoEEX1S/SLk1C2DVdGbNVRm9ENZ6JjPkHLONeN3QUfKope+oEbm+UT3HKvecf7HPwQ1dfRP9yC3qboK+5c9V5F9QX0uQfduD7DYwqqs2Y9ofoYqs+i+iB6Hy8oL96rL+lLuQ1OBvyOKxRrY9MJhAZRh3qtK3C7uyp6VNGiI+76PtQD7XXAff99H5Tvmhq4Y72G64gRW3WzomduQD8Z45Y59mN3+tVcpJfygeoVqC5H32Wics07er2ib3pxRFF+f5v7WZj+kqLofepurzz7sPLYM8qsJ3TWrNzGIFuAUo0Row5vQjHGGJOejk/gBQVQV9vcXdQNqg9Dj55R+9/Ksd43zp49uxk8GCr0BIbpV6jCtu3etKNGgSpn6/rIPUPjx8PqNe77K6+A5Stg4qSmYqegqixW5ceqLFTlTl2AKszTn8LcF3K6KkLBEQq0gfp66NrVXc81NW1H690Hqqrc9/2Pgz27244z/FTYWg6cMQo2boCzx3CerkMVPlwbNeIVV8CK5e77a69xZ7rkzfh1vP8+eP65dJewUxIHGrQA6utaDuhW5K7v6kNud+/eUPU9/Y7tl2Dvfjvl5TFmcv5YUOViXcMqvQxWvp/15Qq6jk/ggHs3ZoytPGPnA2u5mItZxQcAXM3VLGNZFuZl4isCjsTo3xf4zpc5XM3VvMu7bfr/mFtYiHInyku8BNwLzPVlnp1JI40AdKELtdS2Gd6TnhzkQDtKPJ0zUDayIcE4V+I+tsXEkzSBi8hQEfmHiGwWkU0i8oDX/1gReU9EPvP+Jzv3nLIePaC6OvXxT+VUyk9X2LLFryp47gfCuaeW/bh2AepiDulFL/azH4BjOZZKKmHgQAbvUirY2WLc0zmdLWzhLM5iPesj/cczntWshssuhZUrAZjEJJay1BvjBtwfnGl2N3czj3kAPMRDzOHZ9BYtj+Vie+1KV2pj7XAdcwzs309f+rKPfakVdtZZnL3ebdIuoaTt8KuvZpIu452lbQeZ1PbA64H/UNXRwHhghoiMBn4BrFTVEcBKr9sEh49xdS/ZFJr31EyHse21E0mawFV1l6qu894fBLbg/jTTFGChN9pCYGq2KtmRwrqn1iFx7dG9ua00rhOAmD8+0obbNLYq/fo88gg8Mzv96fNQWLfXa7mWt/hLR1cj77SrDVxETgbOBT4CBqrqLm/QbmBg8hKKW3YWOO6dPIB7d1cq7eADcR8Qn9h550FJ9BHZZZdFDrVNS5nHNbludOMwh/0oyqQo07gWFzfdO2FX0OerlG/kEZFewB+BB1X1gEQ9IFhVVURiRrn1b+wF0iOPQF0d1ITv7i6/4qoS63kHaRo2DHZ8gXsSK7sef7z1j4qEQzi31ynAm0SeX2RS2wMXka64H4ZFqvonr/ceERnsDR8MfBtrWm31G3uNkSZSB/d54M2KivL31z3CyM+45qWbb3YfUtbJ+BpXjfetXIj9clbHS+UqFAFeAbaoavQlGW8DP/He/wT30X7h9fjj8MtZHV0L3+R7XE/mZLazPfmIPnjyyfD87Fa+xzVTN3ADr7e6uqgzS6UJ5SLg34ENIvIvr99jwK+BN0TkLtyzTjelMkORBF/qJpd8jWuq3OuFD/pZpGkpZ3EtooijthfeoURzmE1F5CCwNWczzJ7jcH8eKKhOUlXf2j0srnnD77juBaoJ9jqB4McV4sQ2108j3KqqY3M8T9+JSGkYlsNHFtcQUtUBYVgnYViGePLkVnpjjDHtZQncGGMCKtcJ/OUczy9bwrIcfgnL+gjLcvgpDOskDMsQU05PYhpjjPGPNaEYY0xA5SyBi8gkEdkqIttEJDBPQhORHSKyQUT+JSKlXr+sPUo3aCyu4WRxDYacJHARKQBeBCYDo4EfeY+4DIp/U9UfRF2KZI/mxOIaVhbX4MjVHvg4YJuqfq6qtbhP2p+So3lnQ6Afzekji2s4WVwDIlcJ/ATg66junV6/IFBghYiUeU9qgyw9cjWALK7hZHENiFzfiRlEF6tqhYgcD7wnIp9GD0z0aE6T1yyu4dSp4pqrPfAKYGhU94lev7ynqhXe/2+BP+MeXqb0aM5OwOIaThbXgMhVAi8BRojIKSJSCEzDfbxlXhORniJyTNN74GpgIyF5NKcPLK7hZHENiJw0oahqvYj8DFgOFAALVHVTLuadoYHAn71fM+kCvKaqy0SkhCw+cjUoLK7hZHENDrsT0xhjAsruxDTGmICyBG6MMQFlCdwYYwLKErgxxgSUJXBjjAkoS+DGGBNQlsCNMSagLIEbY0xAWQI3xpiAsgRujDEBZQncGGMCyhK4McYElCVwY4wJKEvgxhgTUJbAjTEmoCyBG2NMQFkCN8aYgLIEbowxAWUJ3BhjAsoSuDHGBJQlcGOMCShL4MYYE1CWwI0xJqAsgRtjTEBZAjfGmICyBG6MMQFlCdwYYwLKErgxxgSUJXBjjAkoS+DGGBNQlsCNMSagLIEbY0xAWQI3xpiAyiiBi8gkEdkqIttE5Bd+Vcp0LItreFlsw0VUNb0JRQqAcmACsBMoAX6kqpv9q57JNYtreFlswyeTPfBxwDZV/VxVa4HXgSn+VMt0IItreFlsQ6ZLBtOeAHwd1b0TuCDRBMcdd5yefPLJAJSVAcVlUHYexcXrgOLkc6yvh02b4Jxz0qyyAdixYweVlZUSZ3BGcTUdJ0lcoZ2xtbjmj7KyskpVHdC6fyYJPCUiMh2YDjBs2DBKS0tRVZwChY+6UlD0EaWl3VFKEOJ/9vaxj9Mr+1N55vFQWprtaofa2LFjMy4jVlxNxwpSXBVNuL2nZiGwCljgQ43ym4h8Gat/Jk0oFcDQqO4TvX4tqOrLqjpWVccOGDAARXFazbaOeoooijujKqroT/8MqmraIa24mkBIGttcxHU72xnJyIzLSe/sXbhkksBLgBEicoqIFALTgLf9qVb60jwnG7+8zvcxycu4Gl9kLba53k4WsYjbuT2n88xHaSdwVa0HfgYsB7YAb6jqpoxqEyP77mc//eiX0uRbtsCYMRnVoIW5zOXn/Ny/AgMgK3HNF35/uwdMtmJ7mMP0olemxbRP5w5lREZt4Kr6N+Bv7ZmmdfNJRG0dHNMNrTmaQduYQpJpVUGk7XvTLJ24+jh3ksUwLQsWwEcfwfz5/pcdIB0bW38sXgy3vg23LeromnS8nN6JWUZZwuE11NKd7pHugxykL31TKrucckYzOuE4K1fCxInu+6VLYerURGPPAx5Iad7Gr53bXbjNsv6zHbYwsWg2sVvpjS8c75OUKJGr9xfp1qgh0dOp4m6k2u621VjzWMhC7uKuNmWjGtVt0tEy3ppoIAA72MFpnJZolPjzQoEluE33rYZojPl3AqFM4C024BhBjZsUOnkbaaZUlYKC2MOOchQHx20rVWX/fqVfP4B9VFYOYNAgb8SKb+AkB3DYjtOuqxWWsQwHh6m4h1aLF8Ott0aN8PLLMMMtm+cd91tnpoPqUxb6FEVvOzU10D1ywHwY6N084r594F3FEpmm1UpuOmeVypf0Ul3KVKbGiNP/MH/+PcyY4R0xR76UO4fAJnAlak8q6gOwiY2cg3ujTwklXMiFLcZ/jxVMZnLUNN4e26JFcPvtdONBfi4AAAlvSURBVMZv8Uy5TWPRl4cmWIfVhznY2/GaxqrAp8tD4yWB11K4WuHpp92XSayBBrrSNWpdKzUcpSc9406zhz0MYQhUVPDVSQ6ncErUUG2xvca1bBlcdx1vvwU33phgvLm/db+UH3001UUKvLxM4O5RrcbNA7t0Fyfi7UnhAKe1HVfX4d45DGt0DZfjAFd5A5cD1wFvsQSHaZFDsleBu0DnAzP8W6BOpRHogqpGvWog6txGPPF2nFqW1fa1UlcykYktPgNqTSO+aF7PblwbaKCQQtw78bvFGd/9Yq7kOwYxCNhN63Mbn/FZi3NWCWOcUb0Tv4Iu7xJ4zVHo6Rym2nHo3bt32xG+/RaGDGnZb/vnMDLqUHv9Bij2bs1f+xFccknimS5+o/lYe8H/wD33pL8AhoaGRhzHiby6dWu7obf27bd7GNI6rsBn5Z+1KCvW66qrruK9FTB5sjvN22+9jeM4TJvWuq3UtEdZWVlkHRdEtY3V19VTVNT2xruDBw/hOA79+qV22W+TDes3JIzv5KbApmjOb36T9DPT9Fq4cGG7ys43Wb+Vvo1YX3rJvgjjXFmWaLKERcYYGHP8LF3RZprF3Qnyc+dIm//FD6cFOyXxtl9JMFr0wXTTGz9WdYyD9ODvU7dTqocafrwoRhu9RueGBlGceqWuQOlS23TxgBYdQavprvQ45Pap6q30+V77fYdqf3T37uN10KBvdGdkCpRtw5URWxVFz9yAfsIY5dwyHfsx+iEX6EUXrdYPvHEnLEffnYjyzjXK9X/RHyr6+us3Kbf8wR3jlTuU6S/pvS+iL9yHPqgPatgUFxer+hnX6JMR3l9B1ChHm/pWe3E9gNIb5XsU+mn//ntVd3unn4ag+iX6BScpw7fpCEU3bx7lnpka80l01JXVFymoXnHF+6pNcVX0em++ryvKH5rrNh1U7/Xq9RyqD3vvZ6E6a1bO1n+2+B7XYnd9Njat73q0oMAdXKNooaJHjqB0R3soqgfQqt7uuE3bq+5GvxnkTf+lF4vhuHFt2l7HNMf0gg/R1TTHdXl0vP/S5sSXwh06ffpLqoq+0PLTocx6QmfNekIfa92/6e+OV/T3v89lhNIHlGqMGOVdE4oxxpjU5F8C71ZEDz3MoerYgwcOhF27WvYbfipsLW/uPnsMlK1z34+/ANasSTzLm2+GP3h3dd1xJ7zUuW/Wa7fi4mJUlUZtTGn8Xsf0omp/FX369uG77/b5U4mrJ8Cyd9v0vuXHt0T2Vua/9JI/8+qknAKH+vq6Fv26dSui+nCcjbWVocOGoqps274trflfP+X6Nnugr7wS/icRJpI0gYvIUBH5h4hsFpFNIvKA1/9YEXlPRD7z/rfvzEVGBnNC1JHQdra3GeM8zqOEj72ui7kM5X3eB2ASE3mHpVzPFJagwGIAbuM2FrCAu7mbebyYo2XpGNmKqyDUU9+iXxGFHOGIj7Vv7UpgRRbLD45sxrWBBtzTZrUU0pUajsYctw992Md3uJeI7mYwg9jJzlZjjQDsh4AylcoeeD3wH6o6GhgPzBCR0cAvgJWqOgJY6XX7pic9OcCB9k941pmwfr37/vzzYe3alsOvnuBeV9rKj/kxCwn2Gel2ylpcCyignrqYw3rQk4McbDtg4PHwzTcxphiB+9yl9rgeeDP10Z98Ap58sp3zyFu+xbXY+5EVARqJPrrqCtS2neCYXrC/qmU/75D5BE7gK75qO81ZZ3L2ek34mI2JTOQd3klWXe7nvshO3TM8k3T8MEh6FYqq7sJ9SAWqelBEtuD+sscU4HJvtIXAB0DnuYI+4LIRV0FabejNutEN7XEYvKPtPvShiio4FiorjwP2eNUZAsMqODlyhUF5yul7EpPQyHUIS7iZm7iZqCce3X03cLf7/qEUCw2Y3G6vRcBR3LswewAHgf3uoGOPhcrKhFOfwRlsZGNKc7rW+2vtzjvhzjuj4trJtKsNXEROBs4FPgIGeh8WcK/UH+hrzUzOZCeu7qG2H844AzZsaO9UN9DUNNZZ+RFXjVzwkZrIF3M7ncd5fBxp8szc4zzOLH7pW3n5KuUELiK9gD8CD6pqi7YN7zKXmFEWkekiUioipcP2Dks4j0IKORqnXS2Z0zmdzUna1K7kSlZ4baXXXgtvvZVg5J/+FOa+kFZdgsSPuO7duzcHNTXtkcu49qAH1aR2IhPgVE6lnPLkI5qkUkrgItIV98OwSFX/5PXeIyKDveGDgW9jTautf6IpzpUKXelKDTXtXgCTPl/jGlNX8CmmZ50Fn6z3pajQy35cs+N8zmctH/pW3pNPhunURmypXIUiwCvAFlV9LmrQ28BPvPc/ARLtz6blGI6hqqlNLQXtaVNLxf3cz/M871t5+aQj4xrX4MFQ0ebnN0075GVcTdaksgd+EfDvwBUi8i/v9X+AXwMTROQz3KdE/TqL9TT+y1FcC/FrL/xszk76oyAm4Nvr+PGwOsmNG+3yS+AxH8vLL6lchbKG+E8uuLK9MxQEpZFGmh+O04Wu1MY54dWnD3xfBcN9ut/DuPyOq8kPFtfORTSHj1QUkYPA1pzNMHuOAxJfI5XfTlJV3xo4La55w++47sW98DPI6wSCH1eIE9tcP41wq6qOzfE8fScipWFYDh9ZXENIVQeEYZ2EYRniyb9noRhjjEmJJXBjjAmoXCfwl3M8v2wJy3L4JSzrIyzL4acwrJMwLENMOT2JaYwxxj/WhGKMMQGVswQuIpNEZKuIbBMRXx89m00iskNENng3RJR6/TrwWej5xeIaThbXYMhJAheRAuBFYDIwGviR94zioPg3Vf1B1KVIWX0WelBYXMPJ4hocudoDHwdsU9XPVbUWeB33+cRBNQUiv/6wEJjagXXpSBbXcLK4BkSuEvgJwNdR3Tu9fkGgwAoRKROR6V4/exa6y+IaThbXgMj1nZhBdLGqVojI8cB7IvJp9EBVVRGxS3mCx+IaTp0qrrnaA68AhkZ1n+j1y3uqWuH9/xb4M+7hZUrPVu4ELK7hZHENiFwl8BJghIicIiKFwDTc5xPnNRHpKSLHNL0HrgY2Ys9WbmJxDSeLa0DkpAlFVetF5GfAcqAAWKCqm3Ix7wwNBP7sPiOfLsBrqrpMREqAN0TkLuBL4KYOrGOHsbiGk8U1OOxOTGOMCSi7E9MYYwLKErgxxgSUJXBjjAkoS+DGGBNQlsCNMSagLIEbY0xAWQI3xpiAsgRujDEB9f8BihdSMvxbY0oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x_true = decode(x)\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
        "for i in range(9):\n",
        "  ax[i//3, i%3].imshow(x_true[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxJBjKXcMLlj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SimpleVAE",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "UuXEtFCubCjx"
   },
   "outputs": [],
   "source": [
    "link = 'D:/users/Marko/downloads/mirna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMR4QspjvRl"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aXljY6Cp4zU-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31000,
     "status": "ok",
     "timestamp": 1647023292835,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "VgKU5wNzDK4F",
    "outputId": "2edd95bf-9577-4772-eeca-95c5d32cf026",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: marko5kovic (generativemirna). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Users\\Marko\\Downloads\\mirna\\experiments\\WANDB\\wandb\\run-20220622_163454-3s314dcp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/generativemirna/VAE/runs/3s314dcp\" target=\"_blank\">serene-universe-2</a></strong> to <a href=\"https://wandb.ai/generativemirna/VAE\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/generativemirna/VAE/runs/3s314dcp?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1bd4852bf88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
    "sys.path.insert(0, link)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project=\"VAE\", entity=\"generativemirna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "HuLsYxyh6_ZM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "LATENT_DIM = 64\n",
    "BATCH_SIZE = 16\n",
    "PREWARMUP=100\n",
    "WARMUP=100\n",
    "BETA_KL=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr':LR,\n",
    "    'latent_dim':LATENT_DIM,\n",
    "    'batch_size':BATCH_SIZE,\n",
    "    'beta':BETA_KL,\n",
    "    'prewarmup':PREWARMUP,\n",
    "    'warmup':WARMUP\n",
    "}\n",
    "wandb.config=config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = f\"{link}/saved_models/wandb_models/{LR}_{LATENT_DIM}_{BATCH_SIZE}_{BETA_KL}_{PREWARMUP}_{WARMUP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"{model_folder}/tensorboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFkNf0cjx2V"
   },
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ae7NZhZGj7Zi"
   },
   "outputs": [],
   "source": [
    "class diva_args:\n",
    "\n",
    "    def __init__(self, z_dim=128, d_dim=45, x_dim=7500, y_dim=2,\n",
    "                 beta=1, rec = 1,\n",
    "                 warmup = 1, prewarmup = 1):\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.rec = rec\n",
    "        self.warmup = warmup\n",
    "        self.prewarmup = prewarmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb1vH-a1j7Rf"
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1647023293159,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "D6ouvuZX3WPs"
   },
   "outputs": [],
   "source": [
    "class MicroRNADataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds='train', create_encodings=False, use_subset=False):\n",
    "        \n",
    "        # loading images\n",
    "        self.images = np.load(f'{link}/data/modmirbase_{ds}_images.npz')['arr_0']/255\n",
    "        \n",
    "        \n",
    "        if create_encodings:\n",
    "            x_cat = self.get_encoded_values(self.images, ds)\n",
    "        else:\n",
    "            x_cat = np.load(f'{link}/data/modmirbase_{ds}_images_cattt.npz')['arr_0']\n",
    "        #self.images_cat = np.load(f'{link}/data/modmirbase_{ds}_images_cat_new.npz')\n",
    "        \n",
    "        self.images_cat = x_cat\n",
    "        \n",
    "        # loading labels\n",
    "        print('Loading Labels! (~10s)')     \n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        labels = np.load(f'{link}/data/modmirbase_{ds}_labels.npz')['arr_0']\n",
    "        self.labels = ohe.fit_transform(labels)\n",
    "        \n",
    "        \n",
    "        self.mountain = np.load(f'{link}/data/modmirbase_{ds}_mountain.npy')\n",
    "        \n",
    "        \n",
    "        # loading names\n",
    "        print('Loading Names! (~5s)')\n",
    "        names =  np.load(f'{link}/data/modmirbase_{ds}_names.npz')['arr_0']\n",
    "        names = [i.decode('utf-8') for i in names]\n",
    "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
    "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
    "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
    "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
    "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
    "                        'ppt', 'tca', 'dme', 'sbi']\n",
    "        # assigning a species label to each observation from species\n",
    "        # with more than 200 observations from past research\n",
    "        self.names = []\n",
    "        for i in names:\n",
    "            append = False\n",
    "            for j in self.species:\n",
    "                if j in i.lower():\n",
    "                    self.names.append(j)\n",
    "                    append = True\n",
    "                    break\n",
    "            if not append:\n",
    "                if 'random' in i.lower() or i.isdigit():\n",
    "                    self.names.append('hsa')\n",
    "                else:\n",
    "                    self.names.append('notfound')\n",
    "        \n",
    "        # performing one hot encoding\n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return(self.images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.names_ohe[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.images[idx]\n",
    "        x = np.transpose(x, (2,0,1))\n",
    "        x_cat = self.images_cat[idx]\n",
    "        return (x_cat, y, d, x)\n",
    "\n",
    "\n",
    "    def get_encoded_values(self, x, ds):\n",
    "        \"\"\"\n",
    "        given an image or batch of images\n",
    "        returns length of strand, length of bars and colors of bars\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        x = np.transpose(x, (0,3,1,2))\n",
    "        x_cat = np.zeros((n, 5, 25, 100), dtype=np.uint8)\n",
    "        \n",
    "        for i in range(n):\n",
    "            if i % 100 == 0:\n",
    "                print(f'at {i} out of {n}')\n",
    "            for j in range(100):\n",
    "                if (x[i,:,12,j] == np.array([1,1,1])).all():\n",
    "                    break\n",
    "                else:\n",
    "                    # loop through all pixels of the bar\n",
    "                    for k in range(25):\n",
    "                        if (x[i,:,k,j] == np.array([1,1,1])).all():\n",
    "                            continue\n",
    "                        else:\n",
    "                            x_cat[i,self.get_color(x[i,:,k,j]),k,j] = 1\n",
    "\n",
    "        np.savez_compressed(f'{link}/data/modmirbase_{ds}_images_cattt.npz', x_cat)\n",
    "        #with open(f'{link}/data/modmirbase_{ds}_images_cattt.npz', 'wb') as f:\n",
    "        #    np.save(f, out_len)\n",
    "        \n",
    "\n",
    "        return x_cat\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_color(self, pixel):\n",
    "        \"\"\"\n",
    "        returns the encoded value for a pixel\n",
    "        \"\"\"\n",
    "        if (pixel == np.array([0,0,0])).all():  \n",
    "            return 0 # black\n",
    "        elif (pixel == np.array([1,0,0])).all():  \n",
    "            return 1 # red\n",
    "        elif (pixel == np.array([0,0,1])).all():  \n",
    "            return 2 # blue\n",
    "        elif (pixel == np.array([0,1,0])).all():  \n",
    "            return 3 # green\n",
    "        elif (pixel == np.array([1,1,0])).all():  \n",
    "            return 4 # yellow\n",
    "        else:\n",
    "            print(\"Something wrong!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxj-WGXMj-Ne"
   },
   "source": [
    "## Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "RKizJuchX9uG"
   },
   "outputs": [],
   "source": [
    "# Decoders\n",
    "class px(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim, dim1=256, dim2=512):\n",
    "        super(px, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(z_dim, dim2),  \n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(.1),\n",
    "                                nn.Linear(dim2, dim2),\n",
    "                                nn.Dropout(.4),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        # Predicting length and color of each bar\n",
    "        \n",
    "        self.color = nn.Sequential(nn.Linear(dim2, 1000))\n",
    "        \n",
    "        \n",
    "        self.length_bar = nn.Sequential(nn.Linear(dim2,2800))\n",
    "        \n",
    "        # monster\n",
    "        self.stamp = torch.tensor([[0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                   [1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                   [1,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                                   [1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "                                   [1,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                   [1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "                                   [1,1,1,1,1,1,0,0,0,0,0,0,0],\n",
    "                                   [1,1,1,1,1,1,1,0,0,0,0,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,0,0,0,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,1,0,0,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,1,1,0,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,1,1,1,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,1,1,1,1,0],\n",
    "                                   [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "                                 ])[None,:].to(DEVICE).float()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        \n",
    "        h = self.fc(z)\n",
    "        \n",
    "        \n",
    "        len_bar = self.length_bar(h).reshape(-1,14,200)\n",
    "        len_bar_ = nn.Softmax(dim=1)(len_bar)\n",
    "        len_bar = len_bar_.permute(0,2,1)\n",
    "        len_bar = torch.bmm(len_bar, self.stamp.repeat(len_bar.shape[0],1,1))\n",
    "        #len_bar = len_bar.reshape(-1,2,100,13)\n",
    "        msk2 = len_bar[:,:100,:12]\n",
    "        msk1 = len_bar[:,100:,:].flip(2)\n",
    "        bars = torch.cat([msk1,msk2], 2).permute(0,2,1)[:,None]\n",
    "        bars2 = bars.repeat(1,5,1,1)\n",
    "        \n",
    "        col = nn.Softmax(dim=1)(self.color(h).reshape(-1,5,2,100))\n",
    "        col_top = col[:,:,0,None,:].repeat(1,1,13,1)\n",
    "        col_bot = col[:,:,1,None,:].repeat(1,1,12,1)\n",
    "        color = torch.cat([col_top,col_bot],2)\n",
    "        \n",
    "        rna = color*bars2\n",
    "        \n",
    "        return rna, col, len_bar_\n",
    "    \n",
    "    def sample(self, color, len_bar, mean=True):\n",
    "        \n",
    "        if mean:\n",
    "            bars = torch.argmax(len_bar, dim=1)\n",
    "            col = torch.argmax(color, dim=1)\n",
    "        else:\n",
    "            bars = dist.Categorical(len_bar).sample()\n",
    "            col = dist.Categorical(color).sample()\n",
    "        out = torch.ones((color.shape[0], 25, 100 ,3))\n",
    "        for i in range(color.shape[0]):\n",
    "            for j in range(100):\n",
    "                out[i, 13-bars[i, 100+j]:13, j] = self.get_color(col[i,0,j])\n",
    "                out[i, 13: 13+bars[i,j], j] = self.get_color(col[i,1,j])\n",
    "                \n",
    "        return out\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "    def get_color(self, color):\n",
    "        if color == 0:\n",
    "            return torch.tensor([0,0,0])\n",
    "        elif color == 1:\n",
    "            return torch.tensor([1,0,0])\n",
    "        elif color == 2:\n",
    "            return torch.tensor([0,0,1])\n",
    "        elif color == 3:\n",
    "            return torch.tensor([0,1,0])\n",
    "        elif color == 4:\n",
    "            return torch.tensor([1,1,0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "1y8G2S1zxzTH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "px                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 512]                  --\n",
       "│    └─Linear: 2-1                       [1, 512]                  262,656\n",
       "│    └─ReLU: 2-2                         [1, 512]                  --\n",
       "│    └─Dropout: 2-3                      [1, 512]                  --\n",
       "│    └─Linear: 2-4                       [1, 512]                  262,656\n",
       "│    └─Dropout: 2-5                      [1, 512]                  --\n",
       "│    └─ReLU: 2-6                         [1, 512]                  --\n",
       "├─Sequential: 1-2                        [1, 2800]                 --\n",
       "│    └─Linear: 2-7                       [1, 2800]                 1,436,400\n",
       "├─Sequential: 1-3                        [1, 1000]                 --\n",
       "│    └─Linear: 2-8                       [1, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 2,474,712\n",
       "Trainable params: 2,474,712\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.47\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 9.90\n",
       "Estimated Total Size (MB): 9.94\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pzy_ = px(45, 7500, 2, 512)\n",
    "summary(pzy_, (1,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmNnZWXvkCDP"
   },
   "source": [
    "## Endcoder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647023293469,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "78ZFH8gYl_-z"
   },
   "outputs": [],
   "source": [
    "class qz(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim, h_dim=2592):\n",
    "        super(qz, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(5, 48, kernel_size=5, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, kernel_size=5, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(60, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(72, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.fc11 = nn.Sequential(nn.Linear(self.h_dim, z_dim))\n",
    "        self.fc12 = nn.Sequential(nn.Linear(self.h_dim, z_dim), nn.Softplus())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(-1, self.h_dim)\n",
    "        z_loc = self.fc11(h)\n",
    "        z_scale = self.fc12(h) + 1e-7\n",
    "\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "qz                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 72, 3, 12]            --\n",
       "│    └─Conv2d: 2-1                       [1, 48, 25, 100]          6,048\n",
       "│    └─ReLU: 2-2                         [1, 48, 25, 100]          --\n",
       "│    └─Conv2d: 2-3                       [1, 48, 25, 100]          57,648\n",
       "│    └─ReLU: 2-4                         [1, 48, 25, 100]          --\n",
       "│    └─MaxPool2d: 2-5                    [1, 48, 12, 50]           --\n",
       "│    └─Conv2d: 2-6                       [1, 60, 12, 50]           25,980\n",
       "│    └─ReLU: 2-7                         [1, 60, 12, 50]           --\n",
       "│    └─Conv2d: 2-8                       [1, 60, 12, 50]           32,460\n",
       "│    └─ReLU: 2-9                         [1, 60, 12, 50]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 60, 6, 25]            --\n",
       "│    └─Conv2d: 2-11                      [1, 72, 6, 25]            38,952\n",
       "│    └─ReLU: 2-12                        [1, 72, 6, 25]            --\n",
       "│    └─Conv2d: 2-13                      [1, 72, 6, 25]            46,728\n",
       "│    └─ReLU: 2-14                        [1, 72, 6, 25]            --\n",
       "│    └─MaxPool2d: 2-15                   [1, 72, 3, 12]            --\n",
       "├─Sequential: 1-2                        [1, 512]                  --\n",
       "│    └─Linear: 2-16                      [1, 512]                  1,327,616\n",
       "├─Sequential: 1-3                        [1, 512]                  --\n",
       "│    └─Linear: 2-17                      [1, 512]                  1,327,616\n",
       "│    └─Softplus: 2-18                    [1, 512]                  --\n",
       "==========================================================================================\n",
       "Total params: 2,863,048\n",
       "Trainable params: 2,863,048\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 209.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 2.68\n",
       "Params size (MB): 11.45\n",
       "Estimated Total Size (MB): 14.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = qz(128,10,10,512)\n",
    "summary(enc, (1,5,25,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn_gJdNSkH_V"
   },
   "source": [
    "## Full model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "BgR5BnQN1WWG"
   },
   "outputs": [],
   "source": [
    "class StampDIVA(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StampDIVA, self).__init__()\n",
    "        self.z_dim = args.z_dim\n",
    "        self.d_dim = args.d_dim\n",
    "        self.x_dim = args.x_dim\n",
    "        self.y_dim = args.y_dim\n",
    "\n",
    "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "\n",
    "        self.beta = args.beta\n",
    "        \n",
    "        self.rec = args.rec\n",
    "        self.warmup = args.warmup\n",
    "        self.prewarmup = args.prewarmup\n",
    "\n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, d, x, y):\n",
    "        # Encode\n",
    "        zd_q_loc, zd_q_scale = self.qz(x)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        qz = dist.Normal(zd_q_loc, zd_q_scale)\n",
    "        z_q = qz.rsample()\n",
    "        \n",
    "        \n",
    "        # Decode\n",
    "        x_hat, color, bars = self.px(z_q)\n",
    "        z_p_loc, z_p_scale = torch.zeros(z_q.size()[0], self.z_dim).cuda(),\\\n",
    "                        torch.ones(z_q.size()[0], self.z_dim).cuda()\n",
    "        \n",
    "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
    "        \n",
    "        return x_hat, qz, pz, z_q, color ,bars\n",
    "\n",
    "    def loss_function(self, d, x, y):\n",
    "        \n",
    "        x_hat, qz, pz, z_q, _, _ = self.forward(d, x, y)\n",
    "       \n",
    "        rec_loss = F.mse_loss(x_hat, x, reduction='sum')\n",
    "        \n",
    "        KL_z = torch.sum(pz.log_prob(z_q) - qz.log_prob(z_q))\n",
    "          \n",
    "        return self.rec * rec_loss - self.beta * KL_z, rec_loss, KL_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOsLfYJjBBe"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH1E5J-ps3GD"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16152,
     "status": "ok",
     "timestamp": 1647023309618,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "myflmDPxjV40",
    "outputId": "0befed1a-e175-47eb-e1c0-f9f28da53d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset = MicroRNADataset(create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ut2P5RSaMoDR",
    "outputId": "eafab284-1376-4f62-c8c9-bb8e87351bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset_test = MicroRNADataset('test', create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34721"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RNA_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "eVGq463Y2m20"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    no_batches = 0\n",
    "    mse_t = 0\n",
    "    kl_t = 0\n",
    "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
    "                                     desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (x, y, d, _) in pbar:\n",
    "        # To device\n",
    "        x, y, d = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, mse, kl = model.loss_function(d.float(), x.float(), y.float())\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item()/x.shape[0])\n",
    "        train_loss += loss\n",
    "        mse_t += mse\n",
    "        kl_t += kl\n",
    "        no_batches += 1\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    mse_t /= len(train_loader.dataset)\n",
    "    kl_t /= len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss, mse_t, kl_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dT7E0C3nM3qh"
   },
   "outputs": [],
   "source": [
    "def test_single_epoch(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    mse_t = 0\n",
    "    kl_t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x,y,d,_) in enumerate(test_loader):\n",
    "            x, y, d= x.to(DEVICE), y.to(DEVICE), d.to(DEVICE)\n",
    "            loss , mse, kl = model.loss_function(d.float(), x.float(), y.float())\n",
    "            test_loss += loss\n",
    "            mse_t += mse\n",
    "            kl_t += kl\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    mse_t /= len(test_loader.dataset)\n",
    "    kl_t /= len(test_loader.dataset)\n",
    "    return test_loss, mse_t, kl_t\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "npLjVGs0jHYn"
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch=0, save_folder='sd_1.0.0',save_interval=5):\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(f\"{save_folder}/checkpoints/\"):\n",
    "        os.makedirs(f\"{save_folder}/checkpoints/\")\n",
    "    \n",
    "    if not os.path.exists(f\"{save_folder}/reconstructions/\"):\n",
    "        os.makedirs(f\"{save_folder}/reconstructions/\")\n",
    "    \n",
    "    wandb.watch(diva)\n",
    "    epoch_loss_sup = []\n",
    "    test_loss = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch+1, end_epoch+1):\n",
    "        #idx1, idx2 = choose_index(epoch)\n",
    "        diva.beta = max(1,min([args.beta, args.beta * (epoch - args.prewarmup * 1.) / (args.warmup)]))\n",
    "        if epoch < args.prewarmup:\n",
    "            diva.beta = 1\n",
    "        train_loss , mtr, _ = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
    "        str_loss_sup = train_loss\n",
    "        epoch_loss_sup.append(train_loss)\n",
    "        str_print = \"epoch {}: avg train loss {:.2f}\".format(epoch, str_loss_sup)\n",
    "        str_print += \", ce {:.3f}\".format(mtr)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_train = diva.rec * mtr\n",
    "        dis_loss_train = train_loss - rec_loss_train\n",
    "\n",
    "        test_lss, mte, _ = test_single_epoch(test_loader, diva, epoch)\n",
    "        test_loss.append(test_lss)\n",
    "       \n",
    "        str_print = \"epoch {}: avg test  loss {:.2f}\".format(epoch, test_lss)\n",
    "        str_print += \", ce {:.3f}\".format(mte)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_test = diva.rec* mte\n",
    "        dis_loss_test = test_lss - rec_loss_test\n",
    "\n",
    "        \n",
    "        wandb.log({'epoch':epoch,\n",
    "                   'train_loss': train_loss,\n",
    "                   'test_loss': test_lss,\n",
    "                   'train_mse': mtr,\n",
    "                   'test_mse': mte,\n",
    "                   'train_rec': rec_loss_train,\n",
    "                   'test_rec': rec_loss_test,\n",
    "                   'train_kl': dis_loss_train,\n",
    "                   'test_kl': dis_loss_test,\n",
    "                   'diva_beta': diva.beta})\n",
    "        \n",
    "        if writer is not None:\n",
    "            \n",
    "            writer.add_scalars(\"Total_Loss\", {'train': train_loss, 'test': test_lss} ,epoch)\n",
    "            writer.add_scalars(\"Reconstruction_vs_Disentanglement\",{'rec':rec_loss_train, 'dis':dis_loss_train}, epoch)\n",
    "            writer.add_scalars(\"bar_mse\",{'train': mtr, 'test':mte}, epoch)\n",
    "           \n",
    "        if epoch % save_interval == 0:\n",
    "            save_reconstructions(epoch, test_loader, diva, name=save_folder)\n",
    "            save_reconstructions(epoch, train_loader, diva, name=save_folder, estr='tr')\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(diva.state_dict(), f'{model_folder}/checkpoints/{epoch}.pth')\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.flush()\n",
    "\n",
    "    epoch_loss_sup = [i.detach().cpu().numpy() for i in epoch_loss_sup]\n",
    "    test_loss = [i.detach().cpu().numpy() for i in test_loss]\n",
    "    return epoch_loss_sup, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "XxN8U8YK0Qi1"
   },
   "outputs": [],
   "source": [
    "def save_reconstructions(epoch, test_loader, diva, name='diva', estr=''):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:10].to(DEVICE).float()\n",
    "        x = a[1][0][:10].to(DEVICE).float()\n",
    "        y = a[1][1][:10].to(DEVICE).float()\n",
    "        x_org = a[1][-1][:10]\n",
    "        x_hat ,qz, pz, z_q, color, bar = diva(d,x,y)\n",
    "        \n",
    "        rec = diva.px.sample(color, bar)\n",
    "        \n",
    "        \n",
    "        #out = x_hat.round().permute(0,2,3,1)\n",
    "\n",
    "    plt.figure(figsize=(80,20))\n",
    "    fig, ax = plt.subplots(nrows=10, ncols=2)\n",
    "\n",
    "    ax[0,0].set_title(\"Original\")\n",
    "    ax[0,1].set_title(\"Reconstructed\")\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i, 1].imshow(rec[i].cpu())\n",
    "        ax[i, 0].imshow(x_org[i].cpu().permute(1,2,0))\n",
    "        ax[i, 0].xaxis.set_visible(False)\n",
    "        ax[i, 0].yaxis.set_visible(False)\n",
    "        ax[i, 1].xaxis.set_visible(False)\n",
    "        ax[i, 1].yaxis.set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig(f'{model_folder}/reconstructions/e{epoch}{estr}.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "YVAD-Mjwh7yq",
    "outputId": "f330c11c-e358-41af-9ef4-bc36c146f907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI4-NzHxjmci"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023317083,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "sJE0HTJE1ayP"
   },
   "outputs": [],
   "source": [
    "default_args = diva_args(z_dim=LATENT_DIM, rec = 1, \n",
    "                         beta=BETA_KL, warmup=WARMUP, prewarmup=PREWARMUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "kxIMSeUD1949",
    "outputId": "45991358-df3b-4e61-9d8a-c48b71b9fa49"
   },
   "outputs": [],
   "source": [
    "diva = StampDIVA(default_args).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "StampDIVA                                --                        --\n",
       "├─qz: 1-1                                [1, 64]                   --\n",
       "│    └─Sequential: 2-1                   [1, 72, 3, 12]            --\n",
       "│    │    └─Conv2d: 3-1                  [1, 48, 25, 100]          6,048\n",
       "│    │    └─ReLU: 3-2                    [1, 48, 25, 100]          --\n",
       "│    │    └─Conv2d: 3-3                  [1, 48, 25, 100]          57,648\n",
       "│    │    └─ReLU: 3-4                    [1, 48, 25, 100]          --\n",
       "│    │    └─MaxPool2d: 3-5               [1, 48, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-6                  [1, 60, 12, 50]           25,980\n",
       "│    │    └─ReLU: 3-7                    [1, 60, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-8                  [1, 60, 12, 50]           32,460\n",
       "│    │    └─ReLU: 3-9                    [1, 60, 12, 50]           --\n",
       "│    │    └─MaxPool2d: 3-10              [1, 60, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-11                 [1, 72, 6, 25]            38,952\n",
       "│    │    └─ReLU: 3-12                   [1, 72, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-13                 [1, 72, 6, 25]            46,728\n",
       "│    │    └─ReLU: 3-14                   [1, 72, 6, 25]            --\n",
       "│    │    └─MaxPool2d: 3-15              [1, 72, 3, 12]            --\n",
       "│    └─Sequential: 2-2                   [1, 64]                   --\n",
       "│    │    └─Linear: 3-16                 [1, 64]                   165,952\n",
       "│    └─Sequential: 2-3                   [1, 64]                   --\n",
       "│    │    └─Linear: 3-17                 [1, 64]                   165,952\n",
       "│    │    └─Softplus: 3-18               [1, 64]                   --\n",
       "├─px: 1-2                                [1, 5, 25, 100]           --\n",
       "│    └─Sequential: 2-4                   [1, 512]                  --\n",
       "│    │    └─Linear: 3-19                 [1, 512]                  33,280\n",
       "│    │    └─ReLU: 3-20                   [1, 512]                  --\n",
       "│    │    └─Dropout: 3-21                [1, 512]                  --\n",
       "│    │    └─Linear: 3-22                 [1, 512]                  262,656\n",
       "│    │    └─Dropout: 3-23                [1, 512]                  --\n",
       "│    │    └─ReLU: 3-24                   [1, 512]                  --\n",
       "│    └─Sequential: 2-5                   [1, 2800]                 --\n",
       "│    │    └─Linear: 3-25                 [1, 2800]                 1,436,400\n",
       "│    └─Sequential: 2-6                   [1, 1000]                 --\n",
       "│    │    └─Linear: 3-26                 [1, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 2,785,056\n",
       "Trainable params: 2,785,056\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 209.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 2.71\n",
       "Params size (MB): 11.14\n",
       "Estimated Total Size (MB): 13.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(diva,[ (1,1),(1,5,25,100),(1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318259,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "PUHyoMi7iwJC"
   },
   "outputs": [],
   "source": [
    "#diva.load_state_dict(torch.load(f'{link}/saved_models/new/CIMVAE1/checkpoints/1750.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318260,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "48B39rFl79Yh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(RNA_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(RNA_dataset_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "J6y2Ek2677z1"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(diva.parameters(), lr=0.00001, momentum=0.1, nesterov=True)\n",
    "optimizer = optim.Adam(diva.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNA_dataset.x_len.min(), RNA_dataset.x_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "vQGakzXN6V-Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19552), started 0:00:32 ago. (Use '!kill 19552' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d2cf05960aa2838e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d2cf05960aa2838e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=D:/users/Marko/downloads/mirna/saved_models/wandb_models/  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "0m47XoL87oLs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2171batch [00:41, 52.18batch/s, loss=559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg train loss 451.67, ce 449.246\n",
      "epoch 1: avg test  loss 446.76, ce 443.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 2171batch [00:39, 54.68batch/s, loss=285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg train loss 442.45, ce 437.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 6batch [00:00, 54.55batch/s, loss=444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg test  loss 436.63, ce 430.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 2171batch [00:39, 54.68batch/s, loss=311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg train loss 436.49, ce 430.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 5batch [00:00, 45.87batch/s, loss=420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg test  loss 432.48, ce 426.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 2171batch [00:38, 56.25batch/s, loss=415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg train loss 433.82, ce 426.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 6batch [00:00, 53.57batch/s, loss=396]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg test  loss 430.31, ce 423.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 2171batch [00:39, 55.54batch/s, loss=348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg train loss 432.43, ce 425.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 6batch [00:00, 56.08batch/s, loss=368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg test  loss 429.12, ce 421.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 2171batch [00:38, 55.98batch/s, loss=558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg train loss 431.12, ce 423.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 6batch [00:00, 51.72batch/s, loss=430]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg test  loss 427.03, ce 418.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 2171batch [00:38, 56.13batch/s, loss=350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg train loss 429.05, ce 420.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 6batch [00:00, 55.05batch/s, loss=427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg test  loss 425.25, ce 417.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 2171batch [00:38, 55.85batch/s, loss=219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg train loss 427.61, ce 419.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 6batch [00:00, 56.08batch/s, loss=419]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg test  loss 424.00, ce 415.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 2171batch [00:38, 56.84batch/s, loss=318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg train loss 426.74, ce 418.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 6batch [00:00, 54.05batch/s, loss=416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg test  loss 422.97, ce 414.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 2171batch [00:38, 56.41batch/s, loss=208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg train loss 426.08, ce 417.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 6batch [00:00, 53.57batch/s, loss=431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg test  loss 421.93, ce 413.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 2171batch [00:38, 56.41batch/s, loss=199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg train loss 425.46, ce 416.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 6batch [00:00, 54.55batch/s, loss=368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg test  loss 421.45, ce 412.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 2171batch [00:38, 55.97batch/s, loss=234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg train loss 425.01, ce 415.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 6batch [00:00, 57.69batch/s, loss=430]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg test  loss 420.94, ce 411.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 2171batch [00:38, 55.96batch/s, loss=361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg train loss 424.70, ce 415.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 6batch [00:00, 51.28batch/s, loss=420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg test  loss 420.86, ce 411.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 2171batch [00:39, 55.58batch/s, loss=399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg train loss 424.41, ce 415.102\n",
      "epoch 14: avg test  loss 420.15, ce 410.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 2171batch [00:39, 55.41batch/s, loss=466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg train loss 424.15, ce 414.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 6batch [00:00, 52.63batch/s, loss=470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg test  loss 420.85, ce 412.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 2171batch [00:39, 55.03batch/s, loss=395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg train loss 423.80, ce 414.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 6batch [00:00, 53.57batch/s, loss=405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg test  loss 419.96, ce 410.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 2171batch [00:39, 54.90batch/s, loss=423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg train loss 423.60, ce 414.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 6batch [00:00, 53.57batch/s, loss=431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg test  loss 420.09, ce 410.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 2171batch [00:39, 54.62batch/s, loss=436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg train loss 423.44, ce 413.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 6batch [00:00, 52.17batch/s, loss=433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg test  loss 419.36, ce 409.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 2171batch [00:39, 54.38batch/s, loss=558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg train loss 423.10, ce 413.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 6batch [00:00, 52.17batch/s, loss=400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg test  loss 420.45, ce 411.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 2171batch [00:40, 54.06batch/s, loss=399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg train loss 422.91, ce 413.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 6batch [00:00, 52.63batch/s, loss=430]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg test  loss 419.05, ce 408.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 2171batch [00:40, 53.84batch/s, loss=416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg train loss 422.64, ce 412.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 6batch [00:00, 53.10batch/s, loss=432]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg test  loss 418.76, ce 408.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 2171batch [00:40, 53.52batch/s, loss=512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg train loss 422.37, ce 412.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 6batch [00:00, 52.17batch/s, loss=395]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg test  loss 418.36, ce 408.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 2171batch [00:40, 53.12batch/s, loss=464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg train loss 422.20, ce 412.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 6batch [00:00, 53.57batch/s, loss=385]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg test  loss 418.72, ce 408.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 2171batch [00:41, 52.76batch/s, loss=347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg train loss 422.09, ce 411.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 5batch [00:00, 46.73batch/s, loss=369]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg test  loss 418.59, ce 408.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 2171batch [00:41, 51.72batch/s, loss=328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: avg train loss 422.02, ce 411.866\n",
      "epoch 25: avg test  loss 417.83, ce 407.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 2171batch [00:45, 48.17batch/s, loss=473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg train loss 421.68, ce 411.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 5batch [00:00, 49.51batch/s, loss=425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg test  loss 418.98, ce 409.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 2171batch [00:43, 50.12batch/s, loss=514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg train loss 421.59, ce 411.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 5batch [00:00, 49.02batch/s, loss=407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg test  loss 417.45, ce 407.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 2171batch [00:43, 50.13batch/s, loss=261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg train loss 421.46, ce 411.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 5batch [00:00, 45.46batch/s, loss=428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg test  loss 417.80, ce 407.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 2171batch [00:43, 49.85batch/s, loss=438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg train loss 421.39, ce 411.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 5batch [00:00, 46.73batch/s, loss=489]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg test  loss 417.87, ce 407.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 2171batch [00:44, 48.78batch/s, loss=490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg train loss 421.30, ce 410.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 5batch [00:00, 46.30batch/s, loss=416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg test  loss 417.40, ce 407.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 2171batch [00:44, 48.25batch/s, loss=659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg train loss 421.19, ce 410.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 6batch [00:00, 52.63batch/s, loss=408]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg test  loss 417.57, ce 407.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 2171batch [00:45, 47.39batch/s, loss=398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg train loss 421.11, ce 410.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 5batch [00:00, 49.51batch/s, loss=422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg test  loss 417.29, ce 407.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 2171batch [00:44, 48.69batch/s, loss=384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg train loss 420.96, ce 410.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 4batch [00:00, 35.71batch/s, loss=392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg test  loss 416.94, ce 406.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 2171batch [00:45, 48.18batch/s, loss=753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg train loss 420.96, ce 410.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 6batch [00:00, 50.85batch/s, loss=375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg test  loss 416.96, ce 406.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 2171batch [00:49, 44.06batch/s, loss=425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg train loss 420.71, ce 410.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 5batch [00:00, 47.62batch/s, loss=417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg test  loss 417.98, ce 407.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 317batch [00:06, 45.55batch/s, loss=426]"
     ]
    }
   ],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1000, 0, save_folder=model_folder,save_interval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4182003,
     "status": "ok",
     "timestamp": 1647010362327,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "NprX9l7G73MJ",
    "outputId": "e970b2ef-1d7d-4702-dd1f-3bb4b59c0326"
   },
   "outputs": [],
   "source": [
    "lss2, lss_t2 = train(default_args, train_loader, test_loader, diva, optimizer, 2000, 1000, save_folder=\"new/CIMVAE1\", save_interval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1600, 1000, save_folder=\"VAEFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "\n",
    "\n",
    "def get_color( color):\n",
    "    if color == 0:\n",
    "        return torch.tensor([0,0,0])\n",
    "    elif color == 1:\n",
    "        return torch.tensor([1,0,0])\n",
    "    elif color == 2:\n",
    "        return torch.tensor([0,0,1])\n",
    "    elif color == 3:\n",
    "        return torch.tensor([0,1,0])\n",
    "    elif color == 4:\n",
    "        return torch.tensor([1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(enumerate(train_loader))\n",
    "with torch.no_grad():\n",
    "    diva.eval()\n",
    "    d = a[1][2][:10].to(DEVICE).float()\n",
    "    x = a[1][0][:10].to(DEVICE).float()\n",
    "    y = a[1][1][:10].to(DEVICE).float()\n",
    "    x_org = a[1][-1][:10]\n",
    "    x_hat ,qz, pz, z_q, color, bar = diva(d,x,y)\n",
    "\n",
    "#x_hat[x_hat < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar.shape\n",
    "\n",
    "bar[0,:,1]\n",
    "bar[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat[0,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((10,25,100,3))\n",
    "for i in range(10):\n",
    "    for j in range(100):\n",
    "        for k in range(25):\n",
    "            if torch.max(x_hat[i,:,k,j]) < 0.5:\n",
    "                break\n",
    "            else: \n",
    "                col = torch.argmax(x_hat[i,:,k,j])\n",
    "                out[i,k,j] = get_color(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4r_UyPUGXqT"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(lss, lss_t):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(lss, label=\"train loss\")\n",
    "    ax.plot(lss_t, label = \"test loss\")\n",
    "    #ax1 = ax.twinx()\n",
    "    #ax1.plot(yacc, label = \"train accuracy\", ls='--')\n",
    "    #ax1.plot(yacc_t, label = \"test accuracy\", ls='--')\n",
    "\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    #lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(lines, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1645822416415,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "fTFZZmoguwtU",
    "outputId": "540c8c1f-99d7-4931-c102-7c96747243aa"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss, lss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1645623855467,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "mq2FG26TznE1",
    "outputId": "152eddd3-a440-4b25-c437-498efb0a7ffe"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss3, lss_t3, yacc3, yacc_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FyP02qPdgso"
   },
   "outputs": [],
   "source": [
    "def plot_change_latent_var(diva, lat_space=\"y\", var_idx=[0,1,2,3,4,5,6,7], step = 5):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:len(var_idx)].to(DEVICE).float()\n",
    "        x = a[1][0][:len(var_idx)].to(DEVICE).float()\n",
    "        y = a[1][1][:len(var_idx)].to(DEVICE).float()\n",
    "\n",
    "        zx, zx_sc = diva.qzx(x)\n",
    "        zy, zy_sc = diva.qzy(x)\n",
    "        zd, zd_sc =  diva.qzd(x)\n",
    "\n",
    "        print(torch.max(zy), torch.min(zy), \"sdmax:\", torch.max(zy_sc))\n",
    "\n",
    "        out = change(zx, zy, zd, var_idx, lat_space, diva, step)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=out.shape[0],nrows=len(var_idx),figsize=(10*4*out.shape[0],10*len(var_idx)))\n",
    "    for i in range(out.shape[0]):\n",
    "      for j in range(len(var_idx)):\n",
    "        ax[j,i].imshow(out[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6kJu1APenFe"
   },
   "outputs": [],
   "source": [
    "def change(zx, zy, zd, idx, lat = \"y\", model=diva, step = 2):\n",
    "    \n",
    "    dif = np.arange(-30,15,step)\n",
    "    print(torch.max(zy), torch.min(zy))\n",
    "    out = np.zeros((dif.shape[0], len(idx), 25, 100 ,3))  \n",
    "    #print(zy.shape, dif.shape[0])\n",
    "    for i in range(dif.shape[0]):\n",
    "      for j in range(len(idx)):\n",
    "        if lat == \"y\":\n",
    "            zy[j,idx] = dif[i]\n",
    "        elif lat == \"x\":\n",
    "            zx[j,idx] = dif[i]\n",
    "        elif lat == \"d\":\n",
    "            zd[j,idx] = dif[i]\n",
    "        len_, bar, col = model.px(zd[j],zx[j],zy[j])\n",
    "        out[i,j] = model.px.reconstruct_image(len_[None,:], bar, col)\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 33513,
     "status": "ok",
     "timestamp": 1645623900042,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "4U1JHmTKh0cE",
    "outputId": "b0a1850e-9f0d-4163-813b-8686f4bb05fc"
   },
   "outputs": [],
   "source": [
    "plot_change_latent_var(diva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpZoRZMGHcui"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss2], label=\"train loss\")\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss_t2], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(50,120), yacc2, label = \"train\")\n",
    "ax1.plot(np.arange(50,120), yacc_t2, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1645563980004,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OQMW85JXM6oO",
    "outputId": "dd28a6c2-0024-498e-d571-c705ee67fbd6"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss3], label=\"train loss\")\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss_t3], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(120,180), yacc3, label = \"train\",c='green')\n",
    "ax1.plot(np.arange(120,180), yacc_t3, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whsgNltzXDhK"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfcwhSNIjqIE"
   },
   "source": [
    "## Sampling from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NWGV4Xd7bn8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z5XA4QI1Mb1"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(lat_space=\"y\"):\n",
    "    '''\n",
    "    lat_space: y, d, x\n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1645556291755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "USZ7nIDugT1S",
    "outputId": "174d53bb-845f-458b-ca85-9d749c9c0865"
   },
   "outputs": [],
   "source": [
    "plot(x, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1645550689935,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OE3qVVFFLaPm",
    "outputId": "93953e16-3bda-464b-b765-3aedb9fbe428"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i in range(9):\n",
    "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
    "  \n",
    "plt.savefig('divastamporg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQU05xQEx28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StampVAE (Beta)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

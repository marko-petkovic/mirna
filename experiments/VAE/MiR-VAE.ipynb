{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "UuXEtFCubCjx"
   },
   "outputs": [],
   "source": [
    "link = 'D:/users/Marko/downloads/mirna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMR4QspjvRl"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aXljY6Cp4zU-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31000,
     "status": "ok",
     "timestamp": 1647023292835,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "VgKU5wNzDK4F",
    "outputId": "2edd95bf-9577-4772-eeca-95c5d32cf026"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
    "sys.path.insert(0, link)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"{link}/saved_models/VAE5/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "HuLsYxyh6_ZM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFkNf0cjx2V"
   },
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ae7NZhZGj7Zi"
   },
   "outputs": [],
   "source": [
    "class diva_args:\n",
    "\n",
    "    def __init__(self, z_dim=64, d_dim=45, x_dim=7500, y_dim=2,\n",
    "                 beta=10, rec_alpha = 1, rec_beta = 1, \n",
    "                 rec_gamma = 1, warmup = 1, prewarmup = 1):\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.rec_alpha = rec_alpha\n",
    "        self.rec_beta = rec_beta\n",
    "        self.rec_gamma = rec_gamma\n",
    "        self.warmup = warmup\n",
    "        self.prewarmup = prewarmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb1vH-a1j7Rf"
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1647023293159,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "D6ouvuZX3WPs"
   },
   "outputs": [],
   "source": [
    "class MicroRNADataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds='train', create_encodings=False):\n",
    "        \n",
    "        # loading images\n",
    "        self.images = np.load(f'{link}/data/modmirbase_{ds}_images.npz')['arr_0']/255\n",
    "        \n",
    "        \n",
    "        # loading labels\n",
    "        print('Loading Labels! (~10s)')     \n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        labels = np.load(f'{link}/data/modmirbase_{ds}_labels.npz')['arr_0']\n",
    "        self.labels = ohe.fit_transform(labels)\n",
    "        \n",
    "        # loading encoded images\n",
    "        print(\"loading encodings\")\n",
    "        if create_encodings:\n",
    "            x_len, x_col, x_bar = self.get_encoded_values(self.images, ds)\n",
    "        else:\n",
    "            x_len = np.load(f'{link}/data/modmirbase_{ds}_images_len.npz')\n",
    "            x_bar = np.load(f'{link}/data/modmirbase_{ds}_images_bar.npz')\n",
    "            x_col = np.load(f'{link}/data/modmirbase_{ds}_images_col.npz')\n",
    "        \n",
    "        self.x_len = x_len\n",
    "        self.x_bar = x_bar\n",
    "        self.x_col = x_col\n",
    "        \n",
    "\n",
    "        # loading names\n",
    "        print('Loading Names! (~5s)')\n",
    "        names =  np.load(f'{link}/data/modmirbase_{ds}_names.npz')['arr_0']\n",
    "        names = [i.decode('utf-8') for i in names]\n",
    "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
    "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
    "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
    "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
    "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
    "                        'ppt', 'tca', 'dme', 'sbi']\n",
    "        # assigning a species label to each observation from species\n",
    "        # with more than 200 observations from past research\n",
    "        self.names = []\n",
    "        for i in names:\n",
    "            append = False\n",
    "            for j in self.species:\n",
    "                if j in i.lower():\n",
    "                    self.names.append(j)\n",
    "                    append = True\n",
    "                    break\n",
    "            if not append:\n",
    "                if 'random' in i.lower() or i.isdigit():\n",
    "                    self.names.append('hsa')\n",
    "                else:\n",
    "                    self.names.append('notfound')\n",
    "        \n",
    "        # performing one hot encoding\n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
    "      \n",
    "    def __len__(self):\n",
    "        return(self.images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.names_ohe[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.images[idx]\n",
    "        x = np.transpose(x, (2,0,1))\n",
    "        x_len = self.x_len[idx]\n",
    "        x_col = self.x_col[idx]\n",
    "        x_bar = self.x_bar[idx]\n",
    "        return (x, y, d, x_len, x_col, x_bar)\n",
    "\n",
    "\n",
    "    def get_encoded_values(self, x, ds):\n",
    "        \"\"\"\n",
    "        given an image or batch of images\n",
    "        returns length of strand, length of bars and colors of bars\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        print(x.shape, \"x\")\n",
    "        x = np.transpose(x, (0,3,1,2))\n",
    "        out_len = np.zeros((n,100), dtype=np.uint8)\n",
    "        out_col = np.zeros((n,5,200), dtype=np.uint8)\n",
    "        out_bar = np.zeros((n,13,200), dtype=np.uint8)\n",
    "\n",
    "        for i in range(n):\n",
    "            if i % 100 == 0:\n",
    "                print(f'at {i} out of {n}')\n",
    "            rna_len = 0\n",
    "            broke = False\n",
    "            for j in range(100):\n",
    "                #print(x[i,:,12,j])\n",
    "                if (x[i,:,12,j] == np.array([1,1,1])).all():\n",
    "                    out_len[i,rna_len-1] = 1\n",
    "                    broke = True\n",
    "                    break\n",
    "                else:\n",
    "                    rna_len += 1\n",
    "                    # check color of bars\n",
    "                    out_col[i, self.get_color(x[i,:,12,j]) ,2*j] = 1 \n",
    "                    out_col[i, self.get_color(x[i,:,13,j]), 2*j+1] = 1\n",
    "                    # check length of bars\n",
    "                    len1 = 0\n",
    "                    # loop until white pixel\n",
    "                    while not (x[i,:,12-len1,j] == np.array([1.,1.,1.])).all():\n",
    "                        len1 += 1\n",
    "                        if 13-len1 == 0:\n",
    "                            break\n",
    "                    out_bar[i, len1-1, 2*j] = 1\n",
    "\n",
    "                    len2 = 0\n",
    "                    while not (x[i,:,13+len2,j] == np.array([1.,1.,1.])).all():\n",
    "                        len2 += 1\n",
    "                        if 13+len2 == 25:\n",
    "                            break\n",
    "                    out_bar[i, len2-1, 2*j+1] = 1\n",
    "            if not broke:\n",
    "                out_len[i, rna_len-1] = 1\n",
    "\n",
    "\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_len.npz', 'wb') as f:\n",
    "            np.save(f, out_len)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_col.npz', 'wb') as f:\n",
    "            np.save(f, out_col)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_bar.npz', 'wb') as f:\n",
    "            np.save(f, out_bar)\n",
    "        \n",
    "\n",
    "        return out_len, out_bar, out_col\n",
    "\n",
    "    def get_color(self, pixel):\n",
    "        \"\"\"\n",
    "        returns the encoded value for a pixel\n",
    "        \"\"\"\n",
    "        if (pixel == np.array([0,0,0])).all():  \n",
    "            return 0 # black\n",
    "        elif (pixel == np.array([1,0,0])).all():  \n",
    "            return 1 # red\n",
    "        elif (pixel == np.array([0,0,1])).all():  \n",
    "            return 2 # blue\n",
    "        elif (pixel == np.array([0,1,0])).all():  \n",
    "            return 3 # green\n",
    "        elif (pixel == np.array([1,1,0])).all():  \n",
    "            return 4 # yellow\n",
    "        else:\n",
    "            print(\"Something wrong!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxj-WGXMj-Ne"
   },
   "source": [
    "## Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "RKizJuchX9uG"
   },
   "outputs": [],
   "source": [
    "# Decoders\n",
    "class px(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
    "        super(px, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(z_dim, 400, bias=False),  \n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(400, 200, bias=False),  \n",
    "                                 nn.ReLU())\n",
    "        # Predicting length and color of each bar\n",
    "        self.up1 = nn.Upsample(scale_factor=5)\n",
    "        self.de1 = nn.Sequential(nn.ConvTranspose1d(5,25,kernel_size = 5,\n",
    "                                                    stride = 1, padding = 2,\n",
    "                                                    bias=False),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.ConvTranspose1d(25,50,kernel_size = 5,\n",
    "                                                    stride = 1, padding = 2,\n",
    "                                                    bias=False),\n",
    "                                 nn.ReLU(),\n",
    "                                 )\n",
    "        # Predicting color of each bar\n",
    "        self.color_bar = nn.Sequential(nn.Conv1d(50,5, kernel_size = 3, padding = 'same'),\n",
    "                                      nn.Softmax(dim=1))\n",
    "        \n",
    "        # Predicting the length of each bar\n",
    "        self.length_bar = nn.Sequential(nn.Conv1d(50, 13, kernel_size = 3, padding = 'same'),\n",
    "                                        nn.Softmax(dim=1))\n",
    "\n",
    "        # Predicting length of the RNA strand\n",
    "        self.length_RNA = nn.Sequential(nn.Linear(200,100), nn.Softmax(dim=0))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \n",
    "        h = self.fc1(z)\n",
    "        h = self.fc2(h)\n",
    "        len_RNA = self.length_RNA(h)\n",
    "        \n",
    "        h = h.view(-1, 5, 40)\n",
    "        h = self.up1(h)\n",
    "        h = self.de1(h)\n",
    "        \n",
    "        len_bar = self.length_bar(h)\n",
    "        col_bar = self.color_bar(h)\n",
    "        \n",
    "        return len_RNA, len_bar, col_bar\n",
    "\n",
    "    def reconstruct_image(self, len_RNA, len_bar, col_bar, sample=False):\n",
    "        \"\"\"\n",
    "        reconstructs RNA image given output from decoder\n",
    "        even indexes of len_bar and col_bar   -> top\n",
    "        uneven indexes of len_bar and col_bar -> bottom\n",
    "        function does not support sampling yet\n",
    "        color reconstructions: 0: black\n",
    "                               1: red\n",
    "                               2: blue\n",
    "                               3: green\n",
    "                               4: yellow\n",
    "        \"\"\"\n",
    "        color_dict = {\n",
    "                  0: np.array([0,0,0]), # black\n",
    "                  1: np.array([1,0,0]), # red\n",
    "                  3: np.array([0,1,0]), # green\n",
    "                  2: np.array([0,0,1]), # blue\n",
    "                  4: np.array([1,1,0])  # yellow\n",
    "                  }\n",
    "    \n",
    "        \n",
    "        len_RNA = len_RNA.cpu().numpy()#.reshape((100,))\n",
    "        len_bar = len_bar.cpu().numpy()\n",
    "        col_bar = col_bar.cpu().numpy()\n",
    "        n = len_RNA.shape[0]\n",
    "        output = np.ones((n,25,100,3))\n",
    "\n",
    "        for i in range(n):\n",
    "            if sample:\n",
    "                limit = np.random.choice(np.arange(100), p = len_RNA[i])\n",
    "            else:\n",
    "                limit = np.argmax(len_RNA[i])\n",
    "\n",
    "            for j in range(limit+1):\n",
    "                if sample:\n",
    "                    _len_bar_1 = np.random.choice(np.arange(1,14), p = len_bar[i, :,2*j]) \n",
    "                    _len_bar_2 = np.random.choice(np.arange(1,14), p = len_bar[i, :, 2*j+1])\n",
    "                    _col_bar_1 = np.random.choice(np.arange(5), p = col_bar[i, :, 2*j])\n",
    "                    _col_bar_2 = np.random.choice(np.arange(5), p = col_bar[i,:, 2*j+1])\n",
    "                else:\n",
    "                    _len_bar_1 = np.argmax(len_bar[i,:, 2*j]) + 1 \n",
    "                    _len_bar_2 = np.argmax(len_bar[i,:, 2*j + 1]) + 1\n",
    "                    _col_bar_1 = np.argmax(col_bar[i,:, 2*j])\n",
    "                    _col_bar_2 = np.argmax(col_bar[i,:, 2*j+1])\n",
    "                \n",
    "                h1 = 13-_len_bar_1\n",
    "                # paint upper bar\n",
    "                output[i, h1:13, j] = color_dict[_col_bar_1]\n",
    "        \n",
    "                # paint lower bar\n",
    "                output[i, 13:13+_len_bar_2, j] = color_dict[_col_bar_2]\n",
    "        \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "1y8G2S1zxzTH"
   },
   "outputs": [],
   "source": [
    "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, (1,2))\n",
    "# pzy_ = px(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, [(1,32),(1,32),(1,32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmNnZWXvkCDP"
   },
   "source": [
    "## Endcoder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647013220008,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "tt82wvITwg4j"
   },
   "outputs": [],
   "source": [
    "#pzy_.reconstruct_image(torch.zeros((1,100)), torch.zeros((1,13,200)), torch.zeros(1,5,200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647023293469,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "78ZFH8gYl_-z"
   },
   "outputs": [],
   "source": [
    "class qz(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
    "        super(qz, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding = 'same',bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding = 'same', bias=False),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, bias=False),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.fc11 = nn.Sequential(nn.Linear(5632, z_dim))\n",
    "        self.fc12 = nn.Sequential(nn.Linear(5632, z_dim), nn.Softplus())\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
    "        self.fc11[0].bias.data.zero_()\n",
    "        torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
    "        self.fc12[0].bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(-1, 5632)\n",
    "        z_loc = self.fc11(h)\n",
    "        z_scale = self.fc12(h) + 1e-7\n",
    "\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "qz                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 256, 2, 11]           --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 25, 100]          4,800\n",
       "│    └─ReLU: 2-2                         [1, 64, 25, 100]          --\n",
       "│    └─MaxPool2d: 2-3                    [1, 64, 12, 50]           --\n",
       "│    └─Conv2d: 2-4                       [1, 128, 12, 50]          73,728\n",
       "│    └─ReLU: 2-5                         [1, 128, 12, 50]          --\n",
       "│    └─MaxPool2d: 2-6                    [1, 128, 6, 25]           --\n",
       "│    └─Conv2d: 2-7                       [1, 256, 4, 23]           294,912\n",
       "│    └─ReLU: 2-8                         [1, 256, 4, 23]           --\n",
       "│    └─MaxPool2d: 2-9                    [1, 256, 2, 11]           --\n",
       "├─Sequential: 1-2                        [1, 10]                   --\n",
       "│    └─Linear: 2-10                      [1, 10]                   56,330\n",
       "├─Sequential: 1-3                        [1, 10]                   --\n",
       "│    └─Linear: 2-11                      [1, 10]                   56,330\n",
       "│    └─Softplus: 2-12                    [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 486,100\n",
       "Trainable params: 486,100\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 83.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 2.08\n",
       "Params size (MB): 1.94\n",
       "Estimated Total Size (MB): 4.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = qz(128,10,10,10)\n",
    "summary(enc, (1,3,25,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn_gJdNSkH_V"
   },
   "source": [
    "## Full model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "BgR5BnQN1WWG"
   },
   "outputs": [],
   "source": [
    "class StampDIVA(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StampDIVA, self).__init__()\n",
    "        self.z_dim = args.z_dim\n",
    "        self.d_dim = args.d_dim\n",
    "        self.x_dim = args.x_dim\n",
    "        self.y_dim = args.y_dim\n",
    "\n",
    "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "\n",
    "        self.beta = args.beta\n",
    "        \n",
    "        self.rec_alpha = args.rec_alpha\n",
    "        self.rec_beta = args.rec_beta\n",
    "        self.rec_gamma = args.rec_gamma\n",
    "\n",
    "        self.warmup = args.warmup\n",
    "        self.prewarmup = args.prewarmup\n",
    "\n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, d, x, y):\n",
    "        # Encode\n",
    "        zd_q_loc, zd_q_scale = self.qz(x)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        qz = dist.Normal(zd_q_loc, zd_q_scale)\n",
    "        z_q = qz.rsample()\n",
    "        \n",
    "        \n",
    "        # Decode\n",
    "        x_len, x_bar, x_col = self.px(z_q)\n",
    "        \n",
    "        z_p_loc, z_p_scale = torch.zeros(z_q.size()[0], self.z_dim).cuda(),\\\n",
    "                        torch.ones(z_q.size()[0], self.z_dim).cuda()\n",
    "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
    "        \n",
    "        return x_len, x_bar, x_col, qz, pz, z_q\n",
    "\n",
    "    def loss_function(self, d, x, y, out_len, out_bar, out_col):\n",
    "        #print(1111)\n",
    "        x_len, x_bar, x_col, qz, pz, z_q = self.forward(d, x, y)\n",
    "          \n",
    "          #print(x_len.shape, x_bar.shape)\n",
    "\n",
    "        #print(out_len.shape)\n",
    "        mask = 1 - F.one_hot(torch.argmax(out_len, dim =1)*2+1, 200).cumsum(dim=1)[:,None,:]\n",
    "         # print(mask.shape)\n",
    "        #print(222222) \n",
    "        x_bar = mask.repeat(1,13,1)*x_bar\n",
    "        x_col = mask.repeat(1,5,1)*x_col\n",
    "        CE_len = F.cross_entropy(x_len, out_len, reduction='sum')\n",
    "        CE_bar = F.cross_entropy(x_bar, out_bar, reduction='sum')\n",
    "        CE_col = F.cross_entropy(x_col, out_col, reduction='sum')\n",
    "\n",
    "        KL_z = torch.sum(pz.log_prob(z_q) - qz.log_prob(z_q))\n",
    "          \n",
    "        return self.rec_alpha * CE_len \\\n",
    "                  + self.rec_beta * CE_bar \\\n",
    "                  + self.rec_gamma * CE_col \\\n",
    "                  - self.beta * KL_z, \\\n",
    "                  CE_bar, CE_len, CE_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "g7jIbjazb08Y"
   },
   "outputs": [],
   "source": [
    "w = torch.zeros((5,100))\n",
    "w[0,55] = 1\n",
    "w[1,66] = 1\n",
    "w[2,15] = 1\n",
    "w[3,35] = 1\n",
    "w[4,45] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dVXsu2w9t1aQ"
   },
   "outputs": [],
   "source": [
    "x = torch.argmax(w, dim =1)*2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293471,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "B_XiwRh6uBP3"
   },
   "outputs": [],
   "source": [
    "r = F.one_hot(x,200)\n",
    "b = 1-r.cumsum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293471,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "bUYICFD-u_g9"
   },
   "outputs": [],
   "source": [
    "out = torch.randn((5,6,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293471,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aDHLC1jGvIOA",
    "outputId": "a7f06a9c-a4ac-483a-8f3c-27d1d9116e38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293472,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "pbEEKNdUupi6"
   },
   "outputs": [],
   "source": [
    "b = b[:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023293472,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "v51m0XZcvyIp",
    "outputId": "78596414-95cb-407b-f02c-4994beb0dec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOsLfYJjBBe"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH1E5J-ps3GD"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16152,
     "status": "ok",
     "timestamp": 1647023309618,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "myflmDPxjV40",
    "outputId": "0befed1a-e175-47eb-e1c0-f9f28da53d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset = MicroRNADataset(create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ut2P5RSaMoDR",
    "outputId": "eafab284-1376-4f62-c8c9-bb8e87351bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset_test = MicroRNADataset('test', create_encodings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdYaqWvbjN26"
   },
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "eVGq463Y2m20"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "    no_batches = 0\n",
    "    train_corr = 0\n",
    "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
    "                                     desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (x, y, d, x_len, x_col, x_bar) in pbar:\n",
    "        # To device\n",
    "        x, y, d , x_len, x_bar, x_col = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, bar_loss, len_loss, col_loss = model.loss_function(d.float(), x.float(), y.float(), x_len.float(), x_bar.float(), x_col.float())\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item()/x.shape[0])\n",
    "        train_loss += loss\n",
    "        epoch_bar_loss += bar_loss\n",
    "        epoch_col_loss += col_loss\n",
    "        epoch_len_loss += len_loss\n",
    "        no_batches += 1\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    epoch_bar_loss /= len(train_loader.dataset)\n",
    "    epoch_len_loss /= len(train_loader.dataset)\n",
    "    epoch_col_loss /= len(train_loader.dataset)\n",
    "    \n",
    "\n",
    "    return train_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dT7E0C3nM3qh"
   },
   "outputs": [],
   "source": [
    "def test_single_epoch(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x,y,d,x_len,x_col,x_bar) in enumerate(test_loader):\n",
    "            x, y, d, x_len, x_bar, x_col = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE)\n",
    "            loss, bar_loss, len_loss, col_loss = model.loss_function(d.float(), x.float(), y.float(),x_len.float(),x_bar.float(),x_col.float())\n",
    "            test_loss += loss\n",
    "            epoch_bar_loss += bar_loss\n",
    "            epoch_col_loss += col_loss\n",
    "            epoch_len_loss += len_loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    epoch_bar_loss /= len(train_loader.dataset)\n",
    "    epoch_len_loss /= len(train_loader.dataset)\n",
    "    epoch_col_loss /= len(train_loader.dataset)\n",
    "  \n",
    "    return test_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "npLjVGs0jHYn"
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch=0, save_folder='sd_1.0.0',save_interval=5):\n",
    "    \n",
    "    epoch_loss_sup = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(start_epoch+1, end_epoch+1):\n",
    "        diva.beta = min([args.beta, args.beta * (epoch - args.prewarmup * 1.) / (args.warmup)])\n",
    "        if epoch< args.prewarmup:\n",
    "            diva.beta = args.beta/args.prewarmup\n",
    "        train_loss, avg_loss_bar, avg_loss_len, avg_loss_col = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
    "        str_loss_sup = train_loss\n",
    "        epoch_loss_sup.append(train_loss)\n",
    "        str_print = \"epoch {}: avg train loss {:.2f}\".format(epoch, str_loss_sup)\n",
    "        str_print += \", bar train loss {:.3f}\".format(avg_loss_bar)\n",
    "        str_print += \", len train loss {:.3f}\".format(avg_loss_len)\n",
    "        str_print += \", col train loss {:.3f}\".format(avg_loss_col)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_train = diva.rec_alpha * avg_loss_len + diva.rec_beta * avg_loss_bar + diva.rec_gamma * avg_loss_col\n",
    "        dis_loss_train = train_loss - rec_loss_train\n",
    "\n",
    "        test_lss, avg_loss_bar_test, avg_loss_len_test, avg_loss_col_test = test_single_epoch(test_loader, diva, epoch)\n",
    "        test_loss.append(test_lss)\n",
    "       \n",
    "        str_print = \"epoch {}: avg test  loss {:.2f}\".format(epoch, test_lss)\n",
    "        str_print += \", bar  test loss {:.3f}\".format(avg_loss_bar_test)\n",
    "        str_print += \", len  test loss {:.3f}\".format(avg_loss_len_test)\n",
    "        str_print += \", col  test loss {:.3f}\".format(avg_loss_col_test)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_test = diva.rec_alpha * avg_loss_len_test + diva.rec_beta * avg_loss_bar_test + diva.rec_gamma * avg_loss_col_test\n",
    "        dis_loss_test = test_lss - rec_loss_test\n",
    "\n",
    "        if writer is not None:\n",
    "            \n",
    "            writer.add_scalars(\"Total_Loss\", {'train': train_loss, 'test': test_lss} ,epoch)\n",
    "            writer.add_scalars(\"Reconstruction_vs_Disentanglement\",{'rec':rec_loss_train, 'dis':dis_loss_train}, epoch)\n",
    "\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            torch.save(diva.state_dict(), f'{link}/saved_models/{save_folder}/checkpoints/{epoch}.pth')\n",
    "            save_reconstructions(epoch, test_loader, diva, name=save_folder)\n",
    "\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.flush()\n",
    "\n",
    "    epoch_loss_sup = [i.cpu().detach().numpy() for i in epoch_loss_sup]\n",
    "    test_loss = [i.cpu().detach().numpy() for i in test_loss]\n",
    "    return epoch_loss_sup, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "XxN8U8YK0Qi1"
   },
   "outputs": [],
   "source": [
    "def save_reconstructions(epoch, test_loader, diva, name='diva'):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:10].to(DEVICE).float()\n",
    "        x = a[1][0][:10].to(DEVICE).float()\n",
    "        y = a[1][1][:10].to(DEVICE).float()\n",
    "        x_1, x_2, x_3, _, _, _ = diva(d,x,y)\n",
    "        out = diva.px.reconstruct_image(x_1, x_2, x_3)\n",
    "\n",
    "    plt.figure(figsize=(80,20))\n",
    "    fig, ax = plt.subplots(nrows=10, ncols=2)\n",
    "\n",
    "    ax[0,0].set_title(\"Original\")\n",
    "    ax[0,1].set_title(\"Reconstructed\")\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i, 1].imshow(out[i])\n",
    "        ax[i, 0].imshow(x[i].cpu().permute(1,2,0))\n",
    "        ax[i, 0].xaxis.set_visible(False)\n",
    "        ax[i, 0].yaxis.set_visible(False)\n",
    "        ax[i, 1].xaxis.set_visible(False)\n",
    "        ax[i, 1].yaxis.set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig(f'{link}/saved_models/{name}/reconstructions/e{epoch}.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "YVAD-Mjwh7yq",
    "outputId": "f330c11c-e358-41af-9ef4-bc36c146f907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI4-NzHxjmci"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023317083,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "sJE0HTJE1ayP"
   },
   "outputs": [],
   "source": [
    "default_args = diva_args(z_dim=1024, rec_alpha = 1000, rec_beta = 300, rec_gamma = 200, \n",
    "                         beta=1, warmup=1, prewarmup=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "kxIMSeUD1949",
    "outputId": "45991358-df3b-4e61-9d8a-c48b71b9fa49"
   },
   "outputs": [],
   "source": [
    "diva = StampDIVA(default_args).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318259,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "PUHyoMi7iwJC"
   },
   "outputs": [],
   "source": [
    "#diva.load_state_dict(torch.load(f'{link}/saved_models/VAE1/checkpoints/1400.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318260,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "48B39rFl79Yh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(RNA_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(RNA_dataset_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "J6y2Ek2677z1"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(diva.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "vQGakzXN6V-Y",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22272), started 3 days, 3:49:50 ago. (Use '!kill 22272' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cef441ec4048b39f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cef441ec4048b39f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard  --logdir=\"D:/users/Marko/downloads/mirna/saved_models/VAE5/tensorboard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "0m47XoL87oLs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 272batch [00:17, 15.60batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg train loss 113555.60, bar train loss 250.212, len train loss 4.601, col train loss 169.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg test  loss 112666.75, bar  test loss 106.344, len  test loss 1.972, col  test loss 71.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 272batch [00:14, 18.75batch/s, loss=1.1e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg train loss 112258.09, bar train loss 247.707, len train loss 4.600, col train loss 166.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 2batch [00:00, 18.87batch/s, loss=1.19e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg test  loss 111576.99, bar  test loss 105.945, len  test loss 1.971, col  test loss 70.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 272batch [00:14, 18.25batch/s, loss=1.17e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg train loss 111269.19, bar train loss 247.001, len train loss 4.597, col train loss 162.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 2batch [00:00, 19.42batch/s, loss=1.15e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg test  loss 111048.46, bar  test loss 105.789, len  test loss 1.969, col  test loss 69.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 272batch [00:14, 18.46batch/s, loss=1.05e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg train loss 110916.99, bar train loss 246.730, len train loss 4.590, col train loss 160.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 2batch [00:00, 18.87batch/s, loss=1.08e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg test  loss 110820.34, bar  test loss 105.738, len  test loss 1.966, col  test loss 68.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 272batch [00:14, 18.76batch/s, loss=1.09e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg train loss 110718.76, bar train loss 246.640, len train loss 4.581, col train loss 160.071\n",
      "epoch 5: avg test  loss 110643.35, bar  test loss 105.684, len  test loss 1.964, col  test loss 68.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 272batch [00:14, 18.64batch/s, loss=1.14e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg train loss 110474.02, bar train loss 246.506, len train loss 4.576, col train loss 158.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 2batch [00:00, 19.05batch/s, loss=1.06e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg test  loss 110320.91, bar  test loss 105.624, len  test loss 1.960, col  test loss 67.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 272batch [00:14, 18.49batch/s, loss=1.09e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg train loss 109548.83, bar train loss 245.893, len train loss 4.566, col train loss 154.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 2batch [00:00, 19.05batch/s, loss=1.08e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg test  loss 108892.00, bar  test loss 105.146, len  test loss 1.957, col  test loss 65.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 272batch [00:14, 18.84batch/s, loss=1.1e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg train loss 108556.11, bar train loss 245.051, len train loss 4.555, col train loss 151.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 2batch [00:00, 18.52batch/s, loss=1.07e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg test  loss 108398.05, bar  test loss 104.959, len  test loss 1.953, col  test loss 64.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 272batch [00:14, 18.52batch/s, loss=9.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg train loss 108142.55, bar train loss 244.652, len train loss 4.546, col train loss 149.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 2batch [00:00, 17.39batch/s, loss=1.12e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg test  loss 108029.96, bar  test loss 104.780, len  test loss 1.950, col  test loss 63.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 272batch [00:14, 18.35batch/s, loss=1.09e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg train loss 107828.92, bar train loss 244.272, len train loss 4.534, col train loss 148.395\n",
      "epoch 10: avg test  loss 107789.88, bar  test loss 104.670, len  test loss 1.947, col  test loss 63.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 272batch [00:14, 18.51batch/s, loss=1.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg train loss 105974.07, bar train loss 238.346, len train loss 4.533, col train loss 147.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 2batch [00:00, 18.87batch/s, loss=1.07e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg test  loss 105292.84, bar  test loss 101.075, len  test loss 1.946, col  test loss 63.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 272batch [00:14, 18.39batch/s, loss=1.17e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg train loss 104920.49, bar train loss 235.025, len train loss 4.526, col train loss 147.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 2batch [00:00, 19.05batch/s, loss=1.06e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg test  loss 104829.68, bar  test loss 100.590, len  test loss 1.945, col  test loss 63.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 272batch [00:14, 18.50batch/s, loss=1.03e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg train loss 104568.59, bar train loss 234.185, len train loss 4.519, col train loss 146.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 2batch [00:00, 18.69batch/s, loss=1.03e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg test  loss 104641.25, bar  test loss 100.361, len  test loss 1.940, col  test loss 62.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 272batch [00:14, 18.52batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg train loss 104303.05, bar train loss 233.593, len train loss 4.511, col train loss 146.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 2batch [00:00, 18.87batch/s, loss=1.08e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg test  loss 104376.54, bar  test loss 100.135, len  test loss 1.939, col  test loss 62.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 272batch [00:14, 18.50batch/s, loss=1.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg train loss 104082.23, bar train loss 233.109, len train loss 4.505, col train loss 145.806\n",
      "epoch 15: avg test  loss 104227.65, bar  test loss 100.005, len  test loss 1.938, col  test loss 62.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 272batch [00:14, 18.33batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg train loss 103871.77, bar train loss 232.643, len train loss 4.499, col train loss 145.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 2batch [00:00, 19.23batch/s, loss=1e+5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg test  loss 104014.05, bar  test loss 99.768, len  test loss 1.934, col  test loss 62.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 272batch [00:14, 18.64batch/s, loss=1.1e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg train loss 103670.94, bar train loss 232.212, len train loss 4.490, col train loss 145.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 2batch [00:00, 18.69batch/s, loss=1.04e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg test  loss 103871.12, bar  test loss 99.672, len  test loss 1.930, col  test loss 62.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 272batch [00:14, 18.64batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg train loss 103475.47, bar train loss 231.774, len train loss 4.483, col train loss 144.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 2batch [00:00, 19.05batch/s, loss=1.03e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg test  loss 103670.23, bar  test loss 99.457, len  test loss 1.928, col  test loss 62.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 272batch [00:14, 18.66batch/s, loss=1.15e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg train loss 103288.37, bar train loss 231.374, len train loss 4.476, col train loss 144.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 2batch [00:00, 18.87batch/s, loss=1.03e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg test  loss 103510.02, bar  test loss 99.318, len  test loss 1.925, col  test loss 62.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 272batch [00:14, 18.73batch/s, loss=9.86e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg train loss 103114.45, bar train loss 230.982, len train loss 4.466, col train loss 144.018\n",
      "epoch 20: avg test  loss 103385.87, bar  test loss 99.223, len  test loss 1.920, col  test loss 61.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 272batch [00:14, 18.42batch/s, loss=1.08e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg train loss 102946.08, bar train loss 230.634, len train loss 4.458, col train loss 143.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 2batch [00:00, 18.87batch/s, loss=1.03e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg test  loss 103178.52, bar  test loss 98.996, len  test loss 1.915, col  test loss 61.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 272batch [00:14, 18.75batch/s, loss=9.83e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg train loss 102774.66, bar train loss 230.258, len train loss 4.450, col train loss 143.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 2batch [00:00, 18.35batch/s, loss=1.04e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg test  loss 103088.63, bar  test loss 98.925, len  test loss 1.911, col  test loss 61.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 272batch [00:14, 18.61batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg train loss 102618.29, bar train loss 229.899, len train loss 4.441, col train loss 143.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 2batch [00:00, 19.05batch/s, loss=1.01e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg test  loss 102952.27, bar  test loss 98.718, len  test loss 1.908, col  test loss 61.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 272batch [00:14, 18.69batch/s, loss=1.02e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg train loss 102460.37, bar train loss 229.563, len train loss 4.433, col train loss 142.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 2batch [00:00, 18.35batch/s, loss=1.05e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg test  loss 102834.80, bar  test loss 98.635, len  test loss 1.908, col  test loss 61.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 272batch [00:14, 18.60batch/s, loss=1.09e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: avg train loss 102328.97, bar train loss 229.276, len train loss 4.425, col train loss 142.594\n",
      "epoch 25: avg test  loss 102731.76, bar  test loss 98.572, len  test loss 1.903, col  test loss 61.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 272batch [00:14, 18.34batch/s, loss=9.97e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg train loss 102212.77, bar train loss 229.034, len train loss 4.413, col train loss 142.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 2batch [00:00, 18.35batch/s, loss=1.04e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg test  loss 102618.56, bar  test loss 98.445, len  test loss 1.900, col  test loss 61.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 272batch [00:14, 18.62batch/s, loss=9.65e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg train loss 102068.02, bar train loss 228.728, len train loss 4.406, col train loss 142.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 2batch [00:00, 18.87batch/s, loss=1.02e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg test  loss 102497.95, bar  test loss 98.395, len  test loss 1.895, col  test loss 61.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 272batch [00:14, 18.68batch/s, loss=9.27e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg train loss 101670.40, bar train loss 227.508, len train loss 4.396, col train loss 141.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 2batch [00:00, 18.69batch/s, loss=1e+5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg test  loss 101408.16, bar  test loss 96.723, len  test loss 1.891, col  test loss 61.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 272batch [00:14, 18.74batch/s, loss=1.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg train loss 100661.86, bar train loss 224.016, len train loss 4.388, col train loss 142.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 2batch [00:00, 18.35batch/s, loss=9.86e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg test  loss 100966.14, bar  test loss 96.197, len  test loss 1.886, col  test loss 61.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 272batch [00:14, 18.47batch/s, loss=1.03e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg train loss 100444.71, bar train loss 223.436, len train loss 4.380, col train loss 141.875\n",
      "epoch 30: avg test  loss 100859.76, bar  test loss 96.095, len  test loss 1.880, col  test loss 61.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 272batch [00:14, 18.53batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg train loss 100269.84, bar train loss 223.047, len train loss 4.371, col train loss 141.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 2batch [00:00, 18.87batch/s, loss=1.02e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg test  loss 100690.25, bar  test loss 95.923, len  test loss 1.879, col  test loss 61.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 272batch [00:14, 18.75batch/s, loss=9.59e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg train loss 100128.02, bar train loss 222.717, len train loss 4.365, col train loss 141.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 2batch [00:00, 18.87batch/s, loss=9.95e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg test  loss 100538.86, bar  test loss 95.732, len  test loss 1.872, col  test loss 61.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 272batch [00:14, 18.85batch/s, loss=9.97e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg train loss 99995.05, bar train loss 222.418, len train loss 4.361, col train loss 141.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 2batch [00:00, 18.87batch/s, loss=1.01e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg test  loss 100505.41, bar  test loss 95.720, len  test loss 1.873, col  test loss 60.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 272batch [00:14, 18.82batch/s, loss=9.9e+4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg train loss 99866.53, bar train loss 222.121, len train loss 4.355, col train loss 140.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 2batch [00:00, 19.23batch/s, loss=1.02e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg test  loss 100326.95, bar  test loss 95.555, len  test loss 1.873, col  test loss 60.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 272batch [00:14, 18.74batch/s, loss=8.95e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg train loss 99744.29, bar train loss 221.841, len train loss 4.352, col train loss 140.782\n",
      "epoch 35: avg test  loss 100197.37, bar  test loss 95.428, len  test loss 1.870, col  test loss 60.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 272batch [00:14, 18.52batch/s, loss=9.74e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg train loss 99625.02, bar train loss 221.551, len train loss 4.348, col train loss 140.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 2batch [00:00, 19.23batch/s, loss=9.99e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg test  loss 100150.67, bar  test loss 95.344, len  test loss 1.867, col  test loss 60.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 272batch [00:14, 18.78batch/s, loss=9.57e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg train loss 99512.82, bar train loss 221.304, len train loss 4.345, col train loss 140.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 2batch [00:00, 18.69batch/s, loss=9.57e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg test  loss 100001.76, bar  test loss 95.195, len  test loss 1.865, col  test loss 60.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 272batch [00:14, 18.74batch/s, loss=9.83e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg train loss 99403.83, bar train loss 221.066, len train loss 4.338, col train loss 140.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 2batch [00:00, 18.87batch/s, loss=9.87e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg test  loss 100009.98, bar  test loss 95.267, len  test loss 1.866, col  test loss 60.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 272batch [00:14, 18.77batch/s, loss=9.68e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg train loss 99308.83, bar train loss 220.848, len train loss 4.337, col train loss 140.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 2batch [00:00, 18.52batch/s, loss=9.88e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg test  loss 99848.98, bar  test loss 95.065, len  test loss 1.865, col  test loss 60.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 272batch [00:14, 18.77batch/s, loss=9.45e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: avg train loss 99203.51, bar train loss 220.620, len train loss 4.330, col train loss 139.909\n",
      "epoch 40: avg test  loss 99823.32, bar  test loss 95.034, len  test loss 1.861, col  test loss 60.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 272batch [00:14, 18.49batch/s, loss=1.04e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg train loss 99129.00, bar train loss 220.464, len train loss 4.328, col train loss 139.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 2batch [00:00, 18.69batch/s, loss=9.77e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg test  loss 99724.70, bar  test loss 94.946, len  test loss 1.861, col  test loss 60.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 272batch [00:14, 18.77batch/s, loss=1.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg train loss 99031.91, bar train loss 220.255, len train loss 4.323, col train loss 139.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 2batch [00:00, 18.52batch/s, loss=9.95e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg test  loss 99723.86, bar  test loss 94.979, len  test loss 1.857, col  test loss 60.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 272batch [00:14, 18.56batch/s, loss=9.77e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg train loss 98923.80, bar train loss 220.035, len train loss 4.321, col train loss 139.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 2batch [00:00, 18.87batch/s, loss=9.76e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg test  loss 99573.34, bar  test loss 94.805, len  test loss 1.857, col  test loss 60.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 272batch [00:14, 18.52batch/s, loss=9.88e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg train loss 98858.16, bar train loss 219.873, len train loss 4.318, col train loss 139.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 2batch [00:00, 18.69batch/s, loss=9.71e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg test  loss 99719.57, bar  test loss 94.965, len  test loss 1.858, col  test loss 60.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 272batch [00:14, 18.52batch/s, loss=1.02e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45: avg train loss 98782.51, bar train loss 219.729, len train loss 4.314, col train loss 139.132\n",
      "epoch 45: avg test  loss 99437.50, bar  test loss 94.674, len  test loss 1.857, col  test loss 60.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 272batch [00:14, 18.26batch/s, loss=9.66e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg train loss 98695.18, bar train loss 219.539, len train loss 4.314, col train loss 138.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 2batch [00:00, 19.05batch/s, loss=1.03e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg test  loss 99398.10, bar  test loss 94.671, len  test loss 1.856, col  test loss 60.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 272batch [00:14, 18.56batch/s, loss=9.75e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg train loss 98613.44, bar train loss 219.391, len train loss 4.312, col train loss 138.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 2batch [00:00, 18.18batch/s, loss=9.93e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg test  loss 99303.73, bar  test loss 94.606, len  test loss 1.854, col  test loss 60.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 272batch [00:14, 18.25batch/s, loss=9.38e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg train loss 98552.56, bar train loss 219.267, len train loss 4.310, col train loss 138.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 2batch [00:00, 18.35batch/s, loss=9.95e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg test  loss 99258.01, bar  test loss 94.561, len  test loss 1.852, col  test loss 60.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 272batch [00:15, 18.05batch/s, loss=9.08e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg train loss 98490.53, bar train loss 219.122, len train loss 4.308, col train loss 138.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 2batch [00:00, 18.02batch/s, loss=1.01e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg test  loss 99218.25, bar  test loss 94.479, len  test loss 1.852, col  test loss 60.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 272batch [00:15, 18.03batch/s, loss=9.2e+4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: avg train loss 98397.74, bar train loss 218.937, len train loss 4.305, col train loss 138.394\n",
      "epoch 50: avg test  loss 99367.59, bar  test loss 94.617, len  test loss 1.851, col  test loss 60.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 272batch [00:15, 17.96batch/s, loss=1.04e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg train loss 98349.81, bar train loss 218.855, len train loss 4.305, col train loss 138.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 2batch [00:00, 19.05batch/s, loss=1.01e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg test  loss 99160.87, bar  test loss 94.413, len  test loss 1.850, col  test loss 59.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 272batch [00:14, 18.35batch/s, loss=1.08e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg train loss 98284.32, bar train loss 218.700, len train loss 4.303, col train loss 138.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 2batch [00:00, 18.69batch/s, loss=9.99e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg test  loss 99052.51, bar  test loss 94.341, len  test loss 1.854, col  test loss 59.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 272batch [00:15, 18.09batch/s, loss=9.24e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg train loss 98225.15, bar train loss 218.602, len train loss 4.302, col train loss 138.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 2batch [00:00, 18.52batch/s, loss=9.55e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg test  loss 99019.99, bar  test loss 94.350, len  test loss 1.851, col  test loss 59.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 272batch [00:14, 18.16batch/s, loss=9.98e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg train loss 98151.17, bar train loss 218.463, len train loss 4.301, col train loss 137.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 2batch [00:00, 18.52batch/s, loss=9.96e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg test  loss 98964.27, bar  test loss 94.279, len  test loss 1.851, col  test loss 59.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 272batch [00:15, 17.86batch/s, loss=1.05e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55: avg train loss 98102.88, bar train loss 218.361, len train loss 4.300, col train loss 137.760\n",
      "epoch 55: avg test  loss 98874.04, bar  test loss 94.215, len  test loss 1.851, col  test loss 59.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 272batch [00:15, 18.04batch/s, loss=9.97e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg train loss 98044.40, bar train loss 218.270, len train loss 4.300, col train loss 137.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 2batch [00:00, 18.35batch/s, loss=9.87e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg test  loss 98889.07, bar  test loss 94.223, len  test loss 1.848, col  test loss 59.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 272batch [00:14, 18.75batch/s, loss=9.46e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg train loss 97992.91, bar train loss 218.163, len train loss 4.299, col train loss 137.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 2batch [00:00, 18.69batch/s, loss=9.78e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg test  loss 98851.29, bar  test loss 94.165, len  test loss 1.848, col  test loss 59.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 272batch [00:14, 18.66batch/s, loss=9.58e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg train loss 97910.18, bar train loss 218.014, len train loss 4.296, col train loss 137.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 2batch [00:00, 18.69batch/s, loss=9.64e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg test  loss 98820.85, bar  test loss 94.169, len  test loss 1.848, col  test loss 59.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 272batch [00:14, 18.28batch/s, loss=1.02e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg train loss 97857.84, bar train loss 217.915, len train loss 4.296, col train loss 137.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 2batch [00:00, 17.09batch/s, loss=9.86e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg test  loss 98704.81, bar  test loss 94.066, len  test loss 1.850, col  test loss 59.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 272batch [00:14, 18.30batch/s, loss=1.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60: avg train loss 97776.01, bar train loss 217.746, len train loss 4.296, col train loss 137.042\n",
      "epoch 60: avg test  loss 98724.05, bar  test loss 94.109, len  test loss 1.846, col  test loss 59.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 272batch [00:15, 17.75batch/s, loss=9.58e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg train loss 97746.16, bar train loss 217.712, len train loss 4.294, col train loss 136.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 2batch [00:00, 17.39batch/s, loss=9.77e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg test  loss 98699.48, bar  test loss 94.075, len  test loss 1.850, col  test loss 59.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 272batch [00:15, 17.75batch/s, loss=9.41e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg train loss 97696.14, bar train loss 217.610, len train loss 4.295, col train loss 136.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 2batch [00:00, 17.54batch/s, loss=9.96e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg test  loss 98697.27, bar  test loss 94.080, len  test loss 1.848, col  test loss 59.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 272batch [00:15, 18.05batch/s, loss=9.58e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg train loss 97629.39, bar train loss 217.484, len train loss 4.295, col train loss 136.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 2batch [00:00, 17.86batch/s, loss=95594.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg test  loss 98634.54, bar  test loss 94.058, len  test loss 1.848, col  test loss 59.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 272batch [00:15, 17.54batch/s, loss=1.03e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg train loss 97582.67, bar train loss 217.429, len train loss 4.291, col train loss 136.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 2batch [00:00, 17.54batch/s, loss=1.02e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg test  loss 98538.58, bar  test loss 93.950, len  test loss 1.848, col  test loss 59.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 272batch [00:15, 17.62batch/s, loss=1.03e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: avg train loss 97528.69, bar train loss 217.321, len train loss 4.293, col train loss 136.427\n",
      "epoch 65: avg test  loss 98507.91, bar  test loss 93.928, len  test loss 1.848, col  test loss 59.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 116batch [00:06, 17.07batch/s, loss=9.77e+4]"
     ]
    }
   ],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1000, 0, save_folder=\"VAE5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4182003,
     "status": "ok",
     "timestamp": 1647010362327,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "NprX9l7G73MJ",
    "outputId": "e970b2ef-1d7d-4702-dd1f-3bb4b59c0326"
   },
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 2200, 1000, save_folder=\"VAE5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 5600, 2200, save_folder=\"VAE4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4r_UyPUGXqT"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(lss, lss_t):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(lss, label=\"train loss\")\n",
    "    ax.plot(lss_t, label = \"test loss\")\n",
    "    #ax1 = ax.twinx()\n",
    "    #ax1.plot(yacc, label = \"train accuracy\", ls='--')\n",
    "    #ax1.plot(yacc_t, label = \"test accuracy\", ls='--')\n",
    "\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    #lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(lines, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1645822416415,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "fTFZZmoguwtU",
    "outputId": "540c8c1f-99d7-4931-c102-7c96747243aa"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss, lss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1645623855467,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "mq2FG26TznE1",
    "outputId": "152eddd3-a440-4b25-c437-498efb0a7ffe"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss3, lss_t3, yacc3, yacc_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FyP02qPdgso"
   },
   "outputs": [],
   "source": [
    "def plot_change_latent_var(diva, lat_space=\"y\", var_idx=[0,1,2,3,4,5,6,7], step = 5):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:len(var_idx)].to(DEVICE).float()\n",
    "        x = a[1][0][:len(var_idx)].to(DEVICE).float()\n",
    "        y = a[1][1][:len(var_idx)].to(DEVICE).float()\n",
    "\n",
    "        zx, zx_sc = diva.qzx(x)\n",
    "        zy, zy_sc = diva.qzy(x)\n",
    "        zd, zd_sc =  diva.qzd(x)\n",
    "\n",
    "        print(torch.max(zy), torch.min(zy), \"sdmax:\", torch.max(zy_sc))\n",
    "\n",
    "        out = change(zx, zy, zd, var_idx, lat_space, diva, step)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=out.shape[0],nrows=len(var_idx),figsize=(10*4*out.shape[0],10*len(var_idx)))\n",
    "    for i in range(out.shape[0]):\n",
    "      for j in range(len(var_idx)):\n",
    "        ax[j,i].imshow(out[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6kJu1APenFe"
   },
   "outputs": [],
   "source": [
    "def change(zx, zy, zd, idx, lat = \"y\", model=diva, step = 2):\n",
    "    \n",
    "    dif = np.arange(-30,15,step)\n",
    "    print(torch.max(zy), torch.min(zy))\n",
    "    out = np.zeros((dif.shape[0], len(idx), 25, 100 ,3))  \n",
    "    #print(zy.shape, dif.shape[0])\n",
    "    for i in range(dif.shape[0]):\n",
    "      for j in range(len(idx)):\n",
    "        if lat == \"y\":\n",
    "            zy[j,idx] = dif[i]\n",
    "        elif lat == \"x\":\n",
    "            zx[j,idx] = dif[i]\n",
    "        elif lat == \"d\":\n",
    "            zd[j,idx] = dif[i]\n",
    "        len_, bar, col = model.px(zd[j],zx[j],zy[j])\n",
    "        out[i,j] = model.px.reconstruct_image(len_[None,:], bar, col)\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 33513,
     "status": "ok",
     "timestamp": 1645623900042,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "4U1JHmTKh0cE",
    "outputId": "b0a1850e-9f0d-4163-813b-8686f4bb05fc"
   },
   "outputs": [],
   "source": [
    "plot_change_latent_var(diva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpZoRZMGHcui"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss2], label=\"train loss\")\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss_t2], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(50,120), yacc2, label = \"train\")\n",
    "ax1.plot(np.arange(50,120), yacc_t2, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1645563980004,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OQMW85JXM6oO",
    "outputId": "dd28a6c2-0024-498e-d571-c705ee67fbd6"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss3], label=\"train loss\")\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss_t3], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(120,180), yacc3, label = \"train\",c='green')\n",
    "ax1.plot(np.arange(120,180), yacc_t3, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whsgNltzXDhK"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfcwhSNIjqIE"
   },
   "source": [
    "## Sampling from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NWGV4Xd7bn8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z5XA4QI1Mb1"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(lat_space=\"y\"):\n",
    "    '''\n",
    "    lat_space: y, d, x\n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1645556291755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "USZ7nIDugT1S",
    "outputId": "174d53bb-845f-458b-ca85-9d749c9c0865"
   },
   "outputs": [],
   "source": [
    "plot(x, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1645550689935,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OE3qVVFFLaPm",
    "outputId": "93953e16-3bda-464b-b765-3aedb9fbe428"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i in range(9):\n",
    "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
    "  \n",
    "plt.savefig('divastamporg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQU05xQEx28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StampVAE (Beta)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

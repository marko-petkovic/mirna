{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "UuXEtFCubCjx"
   },
   "outputs": [],
   "source": [
    "link = 'D:/users/Marko/downloads/mirna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMR4QspjvRl"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aXljY6Cp4zU-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31000,
     "status": "ok",
     "timestamp": 1647023292835,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "VgKU5wNzDK4F",
    "outputId": "2edd95bf-9577-4772-eeca-95c5d32cf026"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
    "sys.path.insert(0, link)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"{link}/saved_models/HVAEFCP1/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "HuLsYxyh6_ZM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFkNf0cjx2V"
   },
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ae7NZhZGj7Zi"
   },
   "outputs": [],
   "source": [
    "class diva_args:\n",
    "\n",
    "    def __init__(self, z1_dim=1000, z2_dim=1000, d_dim=45, x_dim=7500, y_dim=2,\n",
    "                 h_dim = 600, h2_dim = 600, number_components = 500,\n",
    "                 beta=1, rec_alpha = 100, rec_beta = 20, \n",
    "                 rec_gamma = 1, warmup = 1, prewarmup = 1):\n",
    "\n",
    "        self.z1_dim = z1_dim\n",
    "        self.z2_dim = z2_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        \n",
    "        self.h_dim = h_dim\n",
    "        self.h2_dim = h2_dim\n",
    "        \n",
    "        self.number_components = number_components\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.rec_alpha = rec_alpha\n",
    "        self.rec_beta = rec_beta\n",
    "        self.rec_gamma = rec_gamma\n",
    "        self.warmup = warmup\n",
    "        self.prewarmup = prewarmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb1vH-a1j7Rf"
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1647023293159,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "D6ouvuZX3WPs"
   },
   "outputs": [],
   "source": [
    "class MicroRNADataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds='train', create_encodings=False, use_subset=False):\n",
    "        \n",
    "        # loading images\n",
    "        self.images = np.load(f'{link}/data/modmirbase_{ds}_images.npz')['arr_0']/255\n",
    "        \n",
    "        \n",
    "        # loading labels\n",
    "        print('Loading Labels! (~10s)')     \n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        labels = np.load(f'{link}/data/modmirbase_{ds}_labels.npz')['arr_0']\n",
    "        self.labels = ohe.fit_transform(labels)\n",
    "        \n",
    "        # loading encoded images\n",
    "        print(\"loading encodings\")\n",
    "        if create_encodings:\n",
    "            x_len, x_col, x_bar = self.get_encoded_values(self.images, ds)\n",
    "        else:\n",
    "            x_len = np.load(f'{link}/data/modmirbase_{ds}_images_len2.npz')\n",
    "            x_bar = np.load(f'{link}/data/modmirbase_{ds}_images_bar2.npz')\n",
    "            x_col = np.load(f'{link}/data/modmirbase_{ds}_images_col2.npz')\n",
    "        \n",
    "        self.x_len = x_len\n",
    "        self.x_bar = x_bar\n",
    "        self.x_col = x_col\n",
    "        \n",
    "        \n",
    "        self.mountain = np.load(f'{link}/data/modmirbase_{ds}_mountain.npy')\n",
    "        \n",
    "        \n",
    "        # loading names\n",
    "        print('Loading Names! (~5s)')\n",
    "        names =  np.load(f'{link}/data/modmirbase_{ds}_names.npz')['arr_0']\n",
    "        names = [i.decode('utf-8') for i in names]\n",
    "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
    "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
    "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
    "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
    "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
    "                        'ppt', 'tca', 'dme', 'sbi']\n",
    "        # assigning a species label to each observation from species\n",
    "        # with more than 200 observations from past research\n",
    "        self.names = []\n",
    "        for i in names:\n",
    "            append = False\n",
    "            for j in self.species:\n",
    "                if j in i.lower():\n",
    "                    self.names.append(j)\n",
    "                    append = True\n",
    "                    break\n",
    "            if not append:\n",
    "                if 'random' in i.lower() or i.isdigit():\n",
    "                    self.names.append('hsa')\n",
    "                else:\n",
    "                    self.names.append('notfound')\n",
    "        \n",
    "        # performing one hot encoding\n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
    "          \n",
    "        if use_subset:    \n",
    "            idxes = [i == 'hsa' and np.random.choice([True, False]) for i in self.names]\n",
    "            self.names_ohe = self.names_ohe[idxes]\n",
    "            self.labels = self.labels[idxes]\n",
    "            self.images = self.images[idxes]\n",
    "            self.x_len = self.x_len[idxes]\n",
    "            self.x_col = self.x_col[idxes]\n",
    "            self.x_bar = self.x_bar[idxes]\n",
    "            self.mountain = self.mountain[idxes]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.names_ohe[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.images[idx]\n",
    "        x = np.transpose(x, (2,0,1))\n",
    "        x_len = self.x_len[idx]\n",
    "        x_col = self.x_col[idx]\n",
    "        x_bar = self.x_bar[idx]\n",
    "        mount = self.mountain[idx]                        \n",
    "        return (x, y, d, x_len, x_col, x_bar, mount)\n",
    "\n",
    "\n",
    "    def get_encoded_values(self, x, ds):\n",
    "        \"\"\"\n",
    "        given an image or batch of images\n",
    "        returns length of strand, length of bars and colors of bars\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        x = np.transpose(x, (0,3,1,2))\n",
    "        out_len = np.zeros((n), dtype=np.uint8)\n",
    "        out_col = np.zeros((n,5,200), dtype=np.uint8)\n",
    "        out_bar = np.zeros((n,2,100), dtype=np.uint8)\n",
    "\n",
    "        for i in range(n):\n",
    "            if i % 100 == 0:\n",
    "                print(f'at {i} out of {n}')\n",
    "            rna_len = 0\n",
    "            broke = False\n",
    "            for j in range(100):\n",
    "                if (x[i,:,12,j] == np.array([1,1,1])).all():\n",
    "                    out_len[i] = rna_len\n",
    "                    broke = True\n",
    "                    break\n",
    "                else:\n",
    "                    rna_len += 1\n",
    "                    # check color of bars\n",
    "                    out_col[i, self.get_color(x[i,:,12,j]) ,2*j] = 1 \n",
    "                    out_col[i, self.get_color(x[i,:,13,j]), 2*j+1] = 1\n",
    "                    # check length of bars\n",
    "                    len1 = 0\n",
    "                    # loop until white pixel\n",
    "                    while not (x[i,:,12-len1,j] == np.array([1.,1.,1.])).all():\n",
    "                        len1 += 1\n",
    "                        if 13-len1 == 0:\n",
    "                            break\n",
    "                    out_bar[i, 0, j] = len1\n",
    "\n",
    "                    len2 = 0\n",
    "                    while not (x[i,:,13+len2,j] == np.array([1.,1.,1.])).all():\n",
    "                        len2 += 1\n",
    "                        if 13+len2 == 25:\n",
    "                            break\n",
    "                    out_bar[i, 1, j] = len2\n",
    "            if not broke:\n",
    "                out_len[i] = rna_len\n",
    "\n",
    "\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_len2.npz', 'wb') as f:\n",
    "            np.save(f, out_len)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_col2.npz', 'wb') as f:\n",
    "            np.save(f, out_col)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_bar2.npz', 'wb') as f:\n",
    "            np.save(f, out_bar)\n",
    "        \n",
    "\n",
    "        return out_len, out_bar, out_col\n",
    "\n",
    "    def get_color(self, pixel):\n",
    "        \"\"\"\n",
    "        returns the encoded value for a pixel\n",
    "        \"\"\"\n",
    "        if (pixel == np.array([0,0,0])).all():  \n",
    "            return 0 # black\n",
    "        elif (pixel == np.array([1,0,0])).all():  \n",
    "            return 1 # red\n",
    "        elif (pixel == np.array([0,0,1])).all():  \n",
    "            return 2 # blue\n",
    "        elif (pixel == np.array([0,1,0])).all():  \n",
    "            return 3 # green\n",
    "        elif (pixel == np.array([1,1,0])).all():  \n",
    "            return 4 # yellow\n",
    "        else:\n",
    "            print(\"Something wrong!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxj-WGXMj-Ne"
   },
   "source": [
    "## Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "RKizJuchX9uG"
   },
   "outputs": [],
   "source": [
    "# Decoders\n",
    "class px(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z1_dim, z2_dim, \n",
    "                 h_dim, h2_dim, dim0=2000, dim1=1200, dim2=400):\n",
    "        super(px, self).__init__()\n",
    "\n",
    "        \n",
    "        # p(z1|z2)\n",
    "        \n",
    "        self.p_z1 = nn.Sequential(nn.Linear(z2_dim+200, h2_dim),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(h2_dim, h2_dim),\n",
    "                                  nn.ReLU())\n",
    "        self.mu_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim))\n",
    "        self.si_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim), nn.Softplus())\n",
    "        \n",
    "        \n",
    "        # p(x|z1,z2,m)\n",
    "        \n",
    "        self.px_z1 = nn.Sequential(nn.Linear(z1_dim, h_dim),\n",
    "                                   nn.ReLU())\n",
    "        self.px_z2 = nn.Sequential(nn.Linear(z2_dim+200, h_dim),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(2*h_dim, dim0, bias=False),  \n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(dim0, dim2, bias=False),  \n",
    "                                 nn.ReLU())\n",
    "#         self.fc3 = nn.Sequential(nn.Linear(dim1, dim2, bias=False),\n",
    "#                                  nn.ReLU())\n",
    "        \n",
    "        # Predicting length and color of each bar\n",
    "        #self.color = nn.Sequential(nn.Conv1d(1,5, kernel_size=1, bias=False), \n",
    "                                  # nn.Softmax(dim=1))\n",
    "        # Predicting color of each bar\n",
    "        self.color_bar_black = nn.Linear(dim2,200)\n",
    "        self.color_bar_reddd = nn.Linear(dim2,200)\n",
    "        self.color_bar_bluee = nn.Linear(dim2,200)\n",
    "        self.color_bar_green = nn.Linear(dim2,200)\n",
    "        self.color_bar_yelow = nn.Linear(dim2,200)\n",
    "        \n",
    "        # Predicting the length of each bar\n",
    "        self.length_bar_top = nn.Sequential(nn.Linear(dim2,100), nn.Softplus())\n",
    "        self.length_bar_bot = nn.Sequential(nn.Linear(dim2,100), nn.Softplus())\n",
    "        #self.length_bar_scale = nn.Sequential(nn.Conv1d(100, 1, kernel_size = 3, padding = 'same', bias=False), nn.Sigmoid())\n",
    "        \n",
    "        # Predicting length of the RNA strand\n",
    "        self.length_RNA = nn.Sequential(nn.Linear(dim2,400), nn.ReLU(),nn.Linear(400,1), nn.Softplus())\n",
    "        #self.length_RNA_scale = nn.Sequential(nn.Linear(400,1, bias=False), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, z1, mz2):\n",
    "        \n",
    "        # p(z1|z2)\n",
    "        pz1 = self.p_z1(mz2)\n",
    "        pz1_m = self.mu_z1(pz1)\n",
    "        pz1_s = self.si_z1(pz1)\n",
    "        \n",
    "        # p(x|z1,z2,m)\n",
    "        hz1 = self.px_z1(z1)\n",
    "        hz2 = self.px_z2(mz2)\n",
    "        h = torch.cat([hz1,hz2],1)\n",
    "        h = self.fc1(h)\n",
    "        h = nn.Dropout(0.2)(h)\n",
    "        h = self.fc2(h)\n",
    "        h = nn.Dropout(0.2)(h)\n",
    "        len_RNA = self.length_RNA(h)\n",
    "        len_bar = torch.cat([self.length_bar_top(h)[:,None,:],self.length_bar_bot(h)[:,None,:]], dim=1) \n",
    "#         h = self.fc3(h)\n",
    "#         h = nn.Dropout(0.3)(h)\n",
    "        \n",
    "        len_RNA_sc = nn.Parameter(torch.tensor([1.])).to(DEVICE)\n",
    "        #len_RNA_sc = torch.exp(self.length_RNA_scale(h))\n",
    "        \n",
    "        \n",
    "        \n",
    "        len_bar_sc = nn.Parameter(torch.tensor([1.])).to(DEVICE)\n",
    "        #len_bar_sc = torch.exp(self.length_bar_scale(h))\n",
    "        \n",
    "#        col_bar = self.color(h[:,None,:])\n",
    "        black = self.color_bar_black(h)\n",
    "        black = nn.Sigmoid()(black)[:,None,:]\n",
    "        reddd = self.color_bar_reddd(h)[:,None,:]\n",
    "        bluee = self.color_bar_bluee(h)[:,None,:]\n",
    "        green = self.color_bar_green(h)[:,None,:]\n",
    "        yelow = self.color_bar_yelow(h)[:,None,:]\n",
    "        \n",
    "        col = torch.cat([reddd,bluee,green,yelow], dim=1)\n",
    "        \n",
    "        col = nn.Softmax(dim=1)(col)\n",
    "        \n",
    "        \n",
    "        col_bar = torch.cat([black,col*((1-black).repeat(1,4,1))], 1)\n",
    "        \n",
    "        return len_RNA, len_RNA_sc, len_bar, len_bar_sc, col_bar, pz1_m, pz1_s\n",
    "\n",
    "    def reconstruct_image(self, len_RNA, var_RNA, len_bar, var_bar ,col_bar, sample=False):\n",
    "        \"\"\"\n",
    "        reconstructs RNA image given output from decoder\n",
    "        even indexes of len_bar and col_bar   -> top\n",
    "        uneven indexes of len_bar and col_bar -> bottom\n",
    "        function does not support sampling yet\n",
    "        color reconstructions: 0: black\n",
    "                               1: red\n",
    "                               2: blue\n",
    "                               3: green\n",
    "                               4: yellow\n",
    "        \"\"\"\n",
    "        color_dict = {\n",
    "                  0: np.array([0,0,0]), # black\n",
    "                  1: np.array([1,0,0]), # red\n",
    "                  3: np.array([0,1,0]), # green\n",
    "                  2: np.array([0,0,1]), # blue\n",
    "                  4: np.array([1,1,0])  # yellow\n",
    "                  }\n",
    "    \n",
    "        \n",
    "        len_RNA = len_RNA.cpu().numpy()\n",
    "        var_RNA = var_RNA.cpu().numpy()\n",
    "        #.reshape((100,))\n",
    "        len_bar = len_bar.cpu().numpy()\n",
    "        var_bar = var_bar.cpu().numpy()\n",
    "        col_bar = col_bar.cpu().numpy()\n",
    "        n = len_RNA.shape[0]\n",
    "        output = np.ones((n,25,100,3))\n",
    "\n",
    "        for i in range(n):\n",
    "            if sample:\n",
    "                limit = int(np.round(np.random.normal(loc=len_RNA[i], scale=var_RNA[i])))\n",
    "            else:\n",
    "                limit = int(np.round(len_RNA[i]))\n",
    "            limit = min(100, limit)\n",
    "            for j in range(limit):\n",
    "                if sample:\n",
    "                    _len_bar_1 = int(np.round(np.random.normal(loc=len_bar[i,0,j], scale=var_bar[i,0,j])))\n",
    "                    _len_bar_2 = int(np.round(np.random.normal(loc=len_bar[i,1,j], scale=var_bar[i,1,j])))\n",
    "                    _col_bar_1 = np.random.choice(np.arange(5), p = col_bar[i, :, 2*j])\n",
    "                    _col_bar_2 = np.random.choice(np.arange(5), p = col_bar[i,:, 2*j+1])\n",
    "                else:\n",
    "                    _len_bar_1 = int(np.round(len_bar[i,0,j])) \n",
    "                    _len_bar_2 = int(np.round(len_bar[i,1,j]))\n",
    "                    _col_bar_1 = np.argmax(col_bar[i,:, 2*j])\n",
    "                    _col_bar_2 = np.argmax(col_bar[i,:, 2*j+1])\n",
    "                \n",
    "                h1 = max(0,13-_len_bar_1)\n",
    "                # paint upper bar\n",
    "                output[i, h1:13, j] = color_dict[_col_bar_1]\n",
    "                h2 = min(25,13+_len_bar_2)\n",
    "                # paint lower bar\n",
    "                output[i, 13:h2, j] = color_dict[_col_bar_2]\n",
    "        \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.round(3.7, 0))\n",
    "int(3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "1y8G2S1zxzTH"
   },
   "outputs": [],
   "source": [
    "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, (1,2))\n",
    "# pzy_ = px(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, [(1,32),(1,32),(1,32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmNnZWXvkCDP"
   },
   "source": [
    "## Endcoder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647013220008,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "tt82wvITwg4j"
   },
   "outputs": [],
   "source": [
    "#pzy_.reconstruct_image(torch.zeros((1,100)), torch.zeros((1,13,200)), torch.zeros(1,5,200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647023293469,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "78ZFH8gYl_-z"
   },
   "outputs": [],
   "source": [
    "class qz(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z1_dim ,z2_dim, h_dim, h2_dim):\n",
    "        super(qz, self).__init__()\n",
    "\n",
    "        # q(z2 | x)\n",
    "        self.encoder_z2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding = 'valid',bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding = 'valid',bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding = 'valid', bias=False),\n",
    "            nn.ReLU(), \n",
    "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding = 'same', bias=False),\n",
    "#             nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, bias=False),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.mu_z2 = nn.Sequential(nn.Linear(2560, z2_dim))\n",
    "        self.si_z2 = nn.Sequential(nn.Linear(2560, z2_dim), nn.Softplus())\n",
    "        \n",
    "        \n",
    "        # q(z1 | x, z2)\n",
    "        self.encoder_z1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding = 'valid',bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding = 'valid',bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding = 'valid', bias=False),\n",
    "            nn.ReLU(), \n",
    "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding = 'same', bias=False),\n",
    "#             nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, bias=False),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.fc_z2 = nn.Sequential(nn.Linear(z2_dim+200, h_dim), nn.ReLU())\n",
    "        self.fc_z1 = nn.Sequential(nn.Linear(2560, h_dim), nn.ReLU())\n",
    "        \n",
    "        self.fc_z1_z2 = nn.Sequential(nn.Linear(2*h_dim, h2_dim), nn.ReLU())\n",
    "        \n",
    "        self.mu_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim))\n",
    "        self.si_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim), nn.Softplus())\n",
    "\n",
    "#         torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
    "#         self.fc11[0].bias.data.zero_()\n",
    "#         torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
    "#         self.fc12[0].bias.data.zero_()\n",
    "    \n",
    "    def q_z2(self, x):\n",
    "        z2 = self.encoder_z2(x)\n",
    "        z2 = z2.view(-1, 2560)\n",
    "        z2_m = self.mu_z2(z2) \n",
    "        z2_s = self.si_z2(z2)\n",
    "        \n",
    "        return z2_m, z2_s\n",
    "    \n",
    "    def forward(self, x, m):\n",
    "        \n",
    "        # q(z2 | x) & m\n",
    "        z2_m, z2_s = self.q_z2(x)\n",
    "        # reparameterization trick\n",
    "        qz2 = dist.Normal(z2_m, z2_s)\n",
    "        z2 = qz2.rsample()\n",
    "        # z2 & m\n",
    "        mz2 = torch.cat([z2, m],1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # q(z1 | x, z2, m)\n",
    "        z1 = self.encoder_z1(x)\n",
    "        z1 = z1.view(-1, 2560)\n",
    "        z1 = self.fc_z1(z1)\n",
    "        \n",
    "        mz2_ = self.fc_z2(mz2)\n",
    "        \n",
    "        z1 = torch.cat([mz2_, z1],1)\n",
    "        z1 = self.fc_z1_z2(z1)\n",
    "        z1_m = self.mu_z1(z1)\n",
    "        z1_s = self.si_z1(z1)\n",
    "        \n",
    "        qz1 = dist.Normal(z1_m, z1_s)\n",
    "        z1 = qz1.rsample()\n",
    "        \n",
    "        \n",
    "        #z_loc = self.fc11(h)\n",
    "        #z_scale = self.fc12(h) + 1e-7\n",
    "\n",
    "        return z1, z2, mz2, z1_m, z1_s, z2_m, z2_s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 3],\n",
       "        [4, 5, 6, 4, 6]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[1,3],[4,6]])\n",
    "\n",
    "torch.cat([a,b],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "qz                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 256, 1, 10]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 23, 98]           864\n",
       "│    └─ReLU: 2-2                         [1, 32, 23, 98]           --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 21, 96]           18,432\n",
       "│    └─ReLU: 2-4                         [1, 64, 21, 96]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 10, 48]           --\n",
       "│    └─Conv2d: 2-6                       [1, 128, 8, 46]           73,728\n",
       "│    └─ReLU: 2-7                         [1, 128, 8, 46]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 128, 4, 23]           --\n",
       "│    └─Conv2d: 2-9                       [1, 256, 2, 21]           294,912\n",
       "│    └─ReLU: 2-10                        [1, 256, 2, 21]           --\n",
       "│    └─MaxPool2d: 2-11                   [1, 256, 1, 10]           --\n",
       "├─Sequential: 1-2                        [1, 500]                  --\n",
       "│    └─Linear: 2-12                      [1, 500]                  1,280,500\n",
       "├─Sequential: 1-3                        [1, 500]                  --\n",
       "│    └─Linear: 2-13                      [1, 500]                  1,280,500\n",
       "│    └─Softplus: 2-14                    [1, 500]                  --\n",
       "├─Sequential: 1-4                        [1, 256, 1, 10]           --\n",
       "│    └─Conv2d: 2-15                      [1, 32, 23, 98]           864\n",
       "│    └─ReLU: 2-16                        [1, 32, 23, 98]           --\n",
       "│    └─Conv2d: 2-17                      [1, 64, 21, 96]           18,432\n",
       "│    └─ReLU: 2-18                        [1, 64, 21, 96]           --\n",
       "│    └─MaxPool2d: 2-19                   [1, 64, 10, 48]           --\n",
       "│    └─Conv2d: 2-20                      [1, 128, 8, 46]           73,728\n",
       "│    └─ReLU: 2-21                        [1, 128, 8, 46]           --\n",
       "│    └─MaxPool2d: 2-22                   [1, 128, 4, 23]           --\n",
       "│    └─Conv2d: 2-23                      [1, 256, 2, 21]           294,912\n",
       "│    └─ReLU: 2-24                        [1, 256, 2, 21]           --\n",
       "│    └─MaxPool2d: 2-25                   [1, 256, 1, 10]           --\n",
       "├─Sequential: 1-5                        [1, 400]                  --\n",
       "│    └─Linear: 2-26                      [1, 400]                  1,024,400\n",
       "│    └─ReLU: 2-27                        [1, 400]                  --\n",
       "├─Sequential: 1-6                        [1, 400]                  --\n",
       "│    └─Linear: 2-28                      [1, 400]                  280,400\n",
       "│    └─ReLU: 2-29                        [1, 400]                  --\n",
       "├─Sequential: 1-7                        [1, 400]                  --\n",
       "│    └─Linear: 2-30                      [1, 400]                  320,400\n",
       "│    └─ReLU: 2-31                        [1, 400]                  --\n",
       "├─Sequential: 1-8                        [1, 10]                   --\n",
       "│    └─Linear: 2-32                      [1, 10]                   4,010\n",
       "├─Sequential: 1-9                        [1, 10]                   --\n",
       "│    └─Linear: 2-33                      [1, 10]                   4,010\n",
       "│    └─Softplus: 2-34                    [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 4,970,092\n",
       "Trainable params: 4,970,092\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 161.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 4.16\n",
       "Params size (MB): 19.88\n",
       "Estimated Total Size (MB): 24.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = qz(128,10,10,10,500,400,400)\n",
    "enc(torch.zeros((1,3,25,100)), torch.zeros((1,200)))\n",
    "summary(enc, [(1,3,25,100),(1,200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Normal_diag(x, mean, std, average=False, dim=None):\n",
    "    log_var = 2*torch.log(std)\n",
    "    log_normal = -0.5 * ( log_var + torch.pow( x - mean, 2 ) / torch.exp( log_var ) )\n",
    "    if average:\n",
    "        return torch.mean( log_normal, dim )\n",
    "    else:\n",
    "        return torch.sum( log_normal, dim )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn_gJdNSkH_V"
   },
   "source": [
    "## Full model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "BgR5BnQN1WWG"
   },
   "outputs": [],
   "source": [
    "class HVAE(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(HVAE, self).__init__()\n",
    "        self.z1_dim = args.z1_dim\n",
    "        self.z2_dim = args.z2_dim\n",
    "        self.d_dim = args.d_dim\n",
    "        self.x_dim = args.x_dim\n",
    "        self.y_dim = args.y_dim\n",
    "        self.h_dim = args.h_dim\n",
    "        self.h2_dim = args.h2_dim\n",
    "        self.number_components = args.number_components\n",
    "        \n",
    "        #d_dim, x_dim, y_dim, z1_dim ,z2_dim, h_dim, h2_dim\n",
    "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z1_dim, self.z2_dim, \n",
    "                     self.h_dim, self.h2_dim)\n",
    "        \n",
    "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z1_dim, self.z2_dim, \n",
    "                     self.h_dim, self.h2_dim)\n",
    "        \n",
    "\n",
    "        self.beta = args.beta\n",
    "        \n",
    "        self.rec_alpha = args.rec_alpha\n",
    "        self.rec_beta = args.rec_beta\n",
    "        self.rec_gamma = args.rec_gamma\n",
    "\n",
    "        self.warmup = args.warmup\n",
    "        self.prewarmup = args.prewarmup\n",
    "        \n",
    "        self.add_pseudoinputs()\n",
    "        \n",
    "        self.lqz1 = []\n",
    "        self.lqz2 = []\n",
    "        self.lpz1 = []\n",
    "        self.lpz2 = []\n",
    "        \n",
    "        self.bar = []\n",
    "        self.len = []\n",
    "        self.col = []\n",
    "        \n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, d, x, y, m):\n",
    "        # Encode\n",
    "        z1, z2, mz2, z1_m, z1_s, z2_m, z2_s = self.qz(x, m)\n",
    "        # Decode\n",
    "        x_len, x_len_scale, x_bar, x_bar_scale, x_col, pz1_m, pz1_s = self.px(z1, mz2)\n",
    "        \n",
    "        return x_len, x_len_scale, x_bar, x_bar_scale, x_col, z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s\n",
    "    \n",
    "    \n",
    "    def log_p_z2(self, z2):\n",
    "        C = self.number_components\n",
    "        \n",
    "        X = self.means(self.idle_input).view(-1,3,25,100)\n",
    "        \n",
    "        pz2_m, pz2_s = self.qz.q_z2(X)\n",
    "        \n",
    "        z_expand = z2.unsqueeze(1)\n",
    "        means = pz2_m.unsqueeze(0)\n",
    "        stds = pz2_s.unsqueeze(0)\n",
    "        \n",
    "        a = log_Normal_diag(z_expand, means, stds, dim=2) - math.log(C)\n",
    "        a_max, _ = torch.max(a,1)\n",
    "        \n",
    "        log_prior = (a_max + torch.log(torch.sum(torch.exp(a-a_max.unsqueeze(1)),1)))\n",
    "        \n",
    "        return log_prior\n",
    "    \n",
    "    def loss_function(self, d, x, y, m, out_len, out_bar, out_col):\n",
    "        \n",
    "        x_len, x_len_scale, x_bar, x_bar_scale, x_col, z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s = self.forward(d, x, y, m)\n",
    "        \n",
    "        # Reconstruction Loss\n",
    "        mask = 1 - F.one_hot(torch.round(out_len).to(torch.int64)*2-1, 200).cumsum(dim=1)[:,None,:]\n",
    "        mask1 = (1 - F.one_hot(torch.round(out_len).to(torch.int64)-1, 100).cumsum(dim=1)[:,None,:]).repeat(1,2,1)\n",
    "\n",
    "        x_col = mask.repeat(1,5,1)*x_col\n",
    "        \n",
    "#         x_gap = x_col[:,0,:]\n",
    "#         x_nuc = x_col[:,1:,:]\n",
    "                \n",
    "        \n",
    "        \n",
    "        dist_len = dist.Normal(x_len, x_len_scale+1e-7)\n",
    "        log_len = dist_len.log_prob(out_len[:,None]).mean()\n",
    "         \n",
    "        mse_bar = ((((x_bar - out_bar)**2)*mask1).sum(dim=(1,2))/(mask1.sum(dim=(1,2)))).sum()#.detach().item()\n",
    "        \n",
    "        max_bar = torch.argmax(x_col, dim=1)\n",
    "        #print(max_bar.shape, out_col.shape, mask.shape)\n",
    "        acc_bar = (((max_bar==torch.argmax(out_col, dim=1))*mask).sum().float()/(mask.sum(1))).sum()\n",
    "        acc_bar2 = (((max_bar==torch.argsort(out_col, dim=1)[:,1,:])*mask).sum().float()/(mask.sum(1))).sum() + acc_bar\n",
    "        #print(acc_bar.shape)\n",
    "        RE_len = -log_len\n",
    "        RE_bar = mse_bar#-log_bar\n",
    "        RE_col = F.cross_entropy(x_col, out_col, reduction='sum')\n",
    "          \n",
    "            \n",
    "        # KL loss\n",
    "        KL_p_z1 = log_Normal_diag(z1, pz1_m, pz1_s, dim=1).sum()\n",
    "        KL_q_z1 = log_Normal_diag(z1, z1_m, z1_s, dim=1).sum()\n",
    "        KL_p_z2 = self.log_p_z2(z2).sum()\n",
    "        KL_q_z2 = log_Normal_diag(z2, z2_m, z2_s, dim=1).sum()\n",
    "        KL = -(KL_p_z1 + KL_p_z2 - KL_q_z1 - KL_q_z2)\n",
    "        #print(KL_p_z1.shape,KL_p_z2.shape,KL_q_z1.shape,KL_q_z2.shape)\n",
    "        \n",
    "        \n",
    "#         self.lpz1.append(KL_p_z1.detach().item())\n",
    "#         self.lpz2.append(KL_p_z2.detach().item())\n",
    "#         self.lqz1.append(KL_q_z1.detach().item())\n",
    "#         self.lqz2.append(KL_q_z2.detach().item())\n",
    "        \n",
    "#         self.bar.append(RE_bar.detach())\n",
    "#         self.col.append(RE_col.detach())\n",
    "#         self.len.append(RE_len.detach())\n",
    "        \n",
    "        \n",
    "        return self.rec_alpha * RE_len \\\n",
    "                  + self.rec_beta * RE_bar \\\n",
    "                  + self.rec_gamma * RE_col \\\n",
    "                  + self.beta * KL, \\\n",
    "                  RE_bar, RE_len, RE_col, mse_bar, acc_bar, acc_bar2\n",
    "    \n",
    "    def add_pseudoinputs(self):\n",
    "        # TODO: rework pseudo generation based on reconstruction\n",
    "        nonlinearity = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
    "        self.means = nn.Sequential(nn.Linear(self.number_components, 3*25*100, bias=False), nonlinearity)\n",
    "        self.idle_input = Variable(torch.eye(self.number_components, self.number_components), requires_grad=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-50.9189)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dist.Normal(0,1)\n",
    "a.log_prob(torch.tensor(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "HVAE                                     --                        --\n",
       "├─px: 1-1                                --                        (recursive)\n",
       "│    └─Sequential: 2-1                   --                        (recursive)\n",
       "│    │    └─Linear: 3-1                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-2                    --                        --\n",
       "│    │    └─Linear: 3-3                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-4                    --                        --\n",
       "│    └─Sequential: 2-2                   --                        (recursive)\n",
       "│    │    └─Linear: 3-5                  --                        (recursive)\n",
       "│    └─Sequential: 2-3                   --                        (recursive)\n",
       "│    │    └─Linear: 3-6                  --                        (recursive)\n",
       "│    │    └─Softplus: 3-7                --                        --\n",
       "│    └─Sequential: 2-4                   --                        (recursive)\n",
       "│    │    └─Linear: 3-8                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-9                    --                        --\n",
       "│    └─Sequential: 2-5                   --                        (recursive)\n",
       "│    │    └─Linear: 3-10                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-11                   --                        --\n",
       "│    └─Sequential: 2-6                   --                        (recursive)\n",
       "│    │    └─Linear: 3-12                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-13                   --                        --\n",
       "│    └─Sequential: 2-7                   --                        (recursive)\n",
       "│    │    └─Linear: 3-14                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-15                   --                        --\n",
       "│    └─Linear: 2-8                       --                        (recursive)\n",
       "│    └─Linear: 2-9                       --                        (recursive)\n",
       "│    └─Linear: 2-10                      --                        (recursive)\n",
       "│    └─Linear: 2-11                      --                        (recursive)\n",
       "│    └─Linear: 2-12                      --                        (recursive)\n",
       "│    └─Sequential: 2-13                  --                        (recursive)\n",
       "│    │    └─Linear: 3-16                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-17               --                        --\n",
       "│    └─Sequential: 2-14                  --                        (recursive)\n",
       "│    │    └─Linear: 3-18                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-19               --                        --\n",
       "│    └─Sequential: 2-15                  --                        (recursive)\n",
       "│    │    └─Linear: 3-20                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-21                   --                        --\n",
       "│    │    └─Linear: 3-22                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-23               --                        --\n",
       "├─qz: 1-2                                [1, 1000]                 --\n",
       "│    └─Sequential: 2-16                  [1, 256, 1, 10]           --\n",
       "│    │    └─Conv2d: 3-24                 [1, 32, 23, 98]           864\n",
       "│    │    └─ReLU: 3-25                   [1, 32, 23, 98]           --\n",
       "│    │    └─Conv2d: 3-26                 [1, 64, 21, 96]           18,432\n",
       "│    │    └─ReLU: 3-27                   [1, 64, 21, 96]           --\n",
       "│    │    └─MaxPool2d: 3-28              [1, 64, 10, 48]           --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 8, 46]           73,728\n",
       "│    │    └─ReLU: 3-30                   [1, 128, 8, 46]           --\n",
       "│    │    └─MaxPool2d: 3-31              [1, 128, 4, 23]           --\n",
       "│    │    └─Conv2d: 3-32                 [1, 256, 2, 21]           294,912\n",
       "│    │    └─ReLU: 3-33                   [1, 256, 2, 21]           --\n",
       "│    │    └─MaxPool2d: 3-34              [1, 256, 1, 10]           --\n",
       "│    └─Sequential: 2-17                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-35                 [1, 1000]                 2,561,000\n",
       "│    └─Sequential: 2-18                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-36                 [1, 1000]                 2,561,000\n",
       "│    │    └─Softplus: 3-37               [1, 1000]                 --\n",
       "│    └─Sequential: 2-19                  [1, 256, 1, 10]           --\n",
       "│    │    └─Conv2d: 3-38                 [1, 32, 23, 98]           864\n",
       "│    │    └─ReLU: 3-39                   [1, 32, 23, 98]           --\n",
       "│    │    └─Conv2d: 3-40                 [1, 64, 21, 96]           18,432\n",
       "│    │    └─ReLU: 3-41                   [1, 64, 21, 96]           --\n",
       "│    │    └─MaxPool2d: 3-42              [1, 64, 10, 48]           --\n",
       "│    │    └─Conv2d: 3-43                 [1, 128, 8, 46]           73,728\n",
       "│    │    └─ReLU: 3-44                   [1, 128, 8, 46]           --\n",
       "│    │    └─MaxPool2d: 3-45              [1, 128, 4, 23]           --\n",
       "│    │    └─Conv2d: 3-46                 [1, 256, 2, 21]           294,912\n",
       "│    │    └─ReLU: 3-47                   [1, 256, 2, 21]           --\n",
       "│    │    └─MaxPool2d: 3-48              [1, 256, 1, 10]           --\n",
       "│    └─Sequential: 2-20                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-49                 [1, 600]                  1,536,600\n",
       "│    │    └─ReLU: 3-50                   [1, 600]                  --\n",
       "│    └─Sequential: 2-21                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-51                 [1, 600]                  720,600\n",
       "│    │    └─ReLU: 3-52                   [1, 600]                  --\n",
       "│    └─Sequential: 2-22                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-53                 [1, 600]                  720,600\n",
       "│    │    └─ReLU: 3-54                   [1, 600]                  --\n",
       "│    └─Sequential: 2-23                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-55                 [1, 1000]                 601,000\n",
       "│    └─Sequential: 2-24                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-56                 [1, 1000]                 601,000\n",
       "│    │    └─Softplus: 3-57               [1, 1000]                 --\n",
       "├─px: 1-3                                [1, 1]                    --\n",
       "│    └─Sequential: 2-25                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-58                 [1, 600]                  720,600\n",
       "│    │    └─ReLU: 3-59                   [1, 600]                  --\n",
       "│    │    └─Linear: 3-60                 [1, 600]                  360,600\n",
       "│    │    └─ReLU: 3-61                   [1, 600]                  --\n",
       "│    └─Sequential: 2-26                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-62                 [1, 1000]                 601,000\n",
       "│    └─Sequential: 2-27                  [1, 1000]                 --\n",
       "│    │    └─Linear: 3-63                 [1, 1000]                 601,000\n",
       "│    │    └─Softplus: 3-64               [1, 1000]                 --\n",
       "│    └─Sequential: 2-28                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-65                 [1, 600]                  600,600\n",
       "│    │    └─ReLU: 3-66                   [1, 600]                  --\n",
       "│    └─Sequential: 2-29                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-67                 [1, 600]                  720,600\n",
       "│    │    └─ReLU: 3-68                   [1, 600]                  --\n",
       "│    └─Sequential: 2-30                  [1, 2000]                 --\n",
       "│    │    └─Linear: 3-69                 [1, 2000]                 2,400,000\n",
       "│    │    └─ReLU: 3-70                   [1, 2000]                 --\n",
       "│    └─Sequential: 2-31                  [1, 400]                  --\n",
       "│    │    └─Linear: 3-71                 [1, 400]                  800,000\n",
       "│    │    └─ReLU: 3-72                   [1, 400]                  --\n",
       "│    └─Sequential: 2-32                  [1, 1]                    --\n",
       "│    │    └─Linear: 3-73                 [1, 400]                  160,400\n",
       "│    │    └─ReLU: 3-74                   [1, 400]                  --\n",
       "│    │    └─Linear: 3-75                 [1, 1]                    401\n",
       "│    │    └─Softplus: 3-76               [1, 1]                    --\n",
       "│    └─Sequential: 2-33                  [1, 100]                  --\n",
       "│    │    └─Linear: 3-77                 [1, 100]                  40,100\n",
       "│    │    └─Softplus: 3-78               [1, 100]                  --\n",
       "│    └─Sequential: 2-34                  [1, 100]                  --\n",
       "│    │    └─Linear: 3-79                 [1, 100]                  40,100\n",
       "│    │    └─Softplus: 3-80               [1, 100]                  --\n",
       "│    └─Linear: 2-35                      [1, 200]                  80,200\n",
       "│    └─Linear: 2-36                      [1, 200]                  80,200\n",
       "│    └─Linear: 2-37                      [1, 200]                  80,200\n",
       "│    └─Linear: 2-38                      [1, 200]                  80,200\n",
       "│    └─Linear: 2-39                      [1, 200]                  80,200\n",
       "==========================================================================================\n",
       "Total params: 17,524,073\n",
       "Trainable params: 17,524,073\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 174.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 4.26\n",
       "Params size (MB): 70.10\n",
       "Estimated Total Size (MB): 74.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_args = diva_args()\n",
    "enc = HVAE(default_args)\n",
    "summary(enc,[ (1,1),(1,3,25,100),(1,1),(1,200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOsLfYJjBBe"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH1E5J-ps3GD"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16152,
     "status": "ok",
     "timestamp": 1647023309618,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "myflmDPxjV40",
    "outputId": "0befed1a-e175-47eb-e1c0-f9f28da53d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset = MicroRNADataset(create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ut2P5RSaMoDR",
    "outputId": "eafab284-1376-4f62-c8c9-bb8e87351bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset_test = MicroRNADataset('test', create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34721"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RNA_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "eVGq463Y2m20"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "    no_batches = 0\n",
    "    train_corr = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0\n",
    "    acc_bar2 = 0\n",
    "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
    "                                     desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (x, y, d, x_len, x_col, x_bar, m) in pbar:\n",
    "        # To device\n",
    "        x, y, d , x_len, x_bar, x_col, m= x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE), m.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, bar_loss, len_loss, col_loss, mse, acc, acc2 = model.loss_function(d.float(), x.float(), y.float(), m.float(), x_len.float(), x_bar.float(), x_col.float())\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item()/x.shape[0])\n",
    "        train_loss += loss\n",
    "        epoch_bar_loss += bar_loss\n",
    "        epoch_col_loss += col_loss\n",
    "        epoch_len_loss += len_loss\n",
    "        mse_bar += mse\n",
    "        acc_bar += acc\n",
    "        acc_bar2 += acc2\n",
    "        no_batches += 1\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    epoch_bar_loss /= len(train_loader.dataset)\n",
    "    epoch_len_loss /= len(train_loader.dataset)\n",
    "    epoch_col_loss /= len(train_loader.dataset)\n",
    "    acc_bar /= len(train_loader.dataset)\n",
    "    acc_bar2 /= len(train_loader.dataset)\n",
    "    mse_bar /= len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss, mse_bar, acc_bar, acc_bar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dT7E0C3nM3qh"
   },
   "outputs": [],
   "source": [
    "def test_single_epoch(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0   \n",
    "    acc_bar2 = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x,y,d,x_len,x_col,x_bar, m) in enumerate(test_loader):\n",
    "            x, y, d, x_len, x_bar, x_col, m = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE), m.to(DEVICE)\n",
    "            loss, bar_loss, len_loss, col_loss, mse, acc, acc2 = model.loss_function(d.float(), x.float(), y.float(),m.float(),x_len.float(),x_bar.float(),x_col.float())\n",
    "            test_loss += loss\n",
    "            epoch_bar_loss += bar_loss\n",
    "            epoch_col_loss += col_loss\n",
    "            epoch_len_loss += len_loss\n",
    "            mse_bar += mse\n",
    "            acc_bar += acc\n",
    "            acc_bar2 += acc2\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    epoch_bar_loss /= len(test_loader.dataset)\n",
    "    epoch_len_loss /= len(test_loader.dataset)\n",
    "    epoch_col_loss /= len(test_loader.dataset)\n",
    "    acc_bar /= len(test_loader.dataset)\n",
    "    acc_bar2 /= len(test_loader.dataset)\n",
    "    mse_bar /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss, mse_bar, acc_bar, acc_bar2\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "npLjVGs0jHYn"
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch=0, save_folder='sd_1.0.0',save_interval=5):\n",
    "    \n",
    "    epoch_loss_sup = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(start_epoch+1, end_epoch+1):\n",
    "        diva.beta = min([args.beta, args.beta * (epoch - args.prewarmup * 1.) / (args.warmup)])\n",
    "        if epoch< args.prewarmup:\n",
    "            diva.beta = args.beta/args.prewarmup\n",
    "        train_loss, avg_loss_bar, avg_loss_len, avg_loss_col, mtr, atr, atr2 = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
    "        str_loss_sup = train_loss\n",
    "        epoch_loss_sup.append(train_loss)\n",
    "        str_print = \"epoch {}: avg train loss {:.2f}\".format(epoch, str_loss_sup)\n",
    "        str_print += \", bar train loss {:.3f}\".format(avg_loss_bar)\n",
    "        str_print += \", len train loss {:.3f}\".format(avg_loss_len)\n",
    "        str_print += \", col train loss {:.3f}\".format(avg_loss_col)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_train = diva.rec_alpha * avg_loss_len + diva.rec_beta * avg_loss_bar + diva.rec_gamma * avg_loss_col\n",
    "        dis_loss_train = train_loss - rec_loss_train\n",
    "\n",
    "        test_lss, avg_loss_bar_test, avg_loss_len_test, avg_loss_col_test, mte, ate, ate2 = test_single_epoch(test_loader, diva, epoch)\n",
    "        test_loss.append(test_lss)\n",
    "       \n",
    "        str_print = \"epoch {}: avg test  loss {:.2f}\".format(epoch, test_lss)\n",
    "        str_print += \", bar  test loss {:.3f}\".format(avg_loss_bar_test)\n",
    "        str_print += \", len  test loss {:.3f}\".format(avg_loss_len_test)\n",
    "        str_print += \", col  test loss {:.3f}\".format(avg_loss_col_test)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_test = diva.rec_alpha * avg_loss_len_test + diva.rec_beta * avg_loss_bar_test + diva.rec_gamma * avg_loss_col_test\n",
    "        dis_loss_test = test_lss - rec_loss_test\n",
    "\n",
    "        if writer is not None:\n",
    "            \n",
    "            writer.add_scalars(\"Total_Loss\", {'train': train_loss, 'test': test_lss} ,epoch)\n",
    "            writer.add_scalars(\"Reconstruction_vs_Disentanglement\",{'rec':rec_loss_train, 'dis':dis_loss_train}, epoch)\n",
    "            writer.add_scalars(\"bar_mse\",{'train': mtr, 'test':mte}, epoch)\n",
    "            writer.add_scalars(\"bar_acc\",{'train-top1': atr, 'test-top1':ate, 'train-top2': atr2, 'test-top2':ate2}, epoch)\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            save_reconstructions(epoch, test_loader, diva, name=save_folder)\n",
    "            save_reconstructions(epoch, train_loader, diva, name=save_folder, estr='tr')\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(diva.state_dict(), f'{link}/saved_models/{save_folder}/checkpoints/{epoch}.pth')\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.flush()\n",
    "\n",
    "    epoch_loss_sup = [i.detach().cpu().numpy() for i in epoch_loss_sup]\n",
    "    test_loss = [i.detach().cpu().numpy() for i in test_loss]\n",
    "    return epoch_loss_sup, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "XxN8U8YK0Qi1"
   },
   "outputs": [],
   "source": [
    "def save_reconstructions(epoch, test_loader, diva, name='diva', estr=''):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:10].to(DEVICE).float()\n",
    "        x = a[1][0][:10].to(DEVICE).float()\n",
    "        y = a[1][1][:10].to(DEVICE).float()\n",
    "        m = a[1][-1][:10].to(DEVICE).float()\n",
    "        x_1, x_1var, x_2, x_2var, x_3 ,z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s = diva(d,x,y,m)\n",
    "        out = diva.px.reconstruct_image(x_1, x_1var, x_2, x_2var, x_3)\n",
    "\n",
    "    plt.figure(figsize=(80,20))\n",
    "    fig, ax = plt.subplots(nrows=10, ncols=2)\n",
    "\n",
    "    ax[0,0].set_title(\"Original\")\n",
    "    ax[0,1].set_title(\"Reconstructed\")\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i, 1].imshow(out[i])\n",
    "        ax[i, 0].imshow(x[i].cpu().permute(1,2,0))\n",
    "        ax[i, 0].xaxis.set_visible(False)\n",
    "        ax[i, 0].yaxis.set_visible(False)\n",
    "        ax[i, 1].xaxis.set_visible(False)\n",
    "        ax[i, 1].yaxis.set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig(f'{link}/saved_models/{name}/reconstructions/e{epoch}{estr}.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "YVAD-Mjwh7yq",
    "outputId": "f330c11c-e358-41af-9ef4-bc36c146f907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI4-NzHxjmci"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023317083,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "sJE0HTJE1ayP"
   },
   "outputs": [],
   "source": [
    "default_args = diva_args(prewarmup=0, number_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "kxIMSeUD1949",
    "outputId": "45991358-df3b-4e61-9d8a-c48b71b9fa49"
   },
   "outputs": [],
   "source": [
    "diva = HVAE(default_args).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318259,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "PUHyoMi7iwJC"
   },
   "outputs": [],
   "source": [
    "#diva.load_state_dict(torch.load(f'{link}/saved_models/VAE10/checkpoints/905.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318260,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "48B39rFl79Yh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(RNA_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(RNA_dataset_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "J6y2Ek2677z1"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(diva.parameters(), lr=0.00001, momentum=0.1, nesterov=True)\n",
    "optimizer = optim.Adam(diva.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_dataset.x_len.min(), RNA_dataset.x_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "diva.rec_gamma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "vQGakzXN6V-Y",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-106389227576928\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-106389227576928\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"D:/users/Marko/downloads/mirna/saved_models/HVAEFCP1/tensorboard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "0m47XoL87oLs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 543batch [00:36, 14.81batch/s, loss=762]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg train loss 818.13, bar train loss 11.790, len train loss 0.638, col train loss 171.595\n",
      "epoch 1: avg test  loss 730.94, bar  test loss 9.307, len  test loss 0.301, col  test loss 169.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 543batch [00:36, 14.75batch/s, loss=774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg train loss 706.39, bar train loss 8.756, len train loss 0.193, col train loss 168.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 2batch [00:00, 13.89batch/s, loss=744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg test  loss 692.03, bar  test loss 8.329, len  test loss 0.153, col  test loss 168.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 543batch [00:37, 14.50batch/s, loss=743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg train loss 688.16, bar train loss 8.104, len train loss 0.167, col train loss 167.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 2batch [00:00, 14.39batch/s, loss=630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg test  loss 674.53, bar  test loss 7.725, len  test loss 0.132, col  test loss 166.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 543batch [00:37, 14.42batch/s, loss=693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg train loss 670.80, bar train loss 7.247, len train loss 0.207, col train loss 166.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 2batch [00:00, 14.18batch/s, loss=660]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg test  loss 651.84, bar  test loss 6.765, len  test loss 0.129, col  test loss 165.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 543batch [00:37, 14.61batch/s, loss=611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg train loss 650.31, bar train loss 6.537, len train loss 0.170, col train loss 165.018\n",
      "epoch 5: avg test  loss 642.37, bar  test loss 6.364, len  test loss 0.138, col  test loss 164.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 543batch [00:36, 14.72batch/s, loss=642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg train loss 641.45, bar train loss 6.157, len train loss 0.171, col train loss 164.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 2batch [00:00, 14.39batch/s, loss=644]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg test  loss 633.91, bar  test loss 5.987, len  test loss 0.140, col  test loss 164.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 543batch [00:37, 14.53batch/s, loss=682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg train loss 633.40, bar train loss 5.870, len train loss 0.161, col train loss 163.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 2batch [00:00, 14.39batch/s, loss=645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg test  loss 628.93, bar  test loss 5.739, len  test loss 0.155, col  test loss 163.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 543batch [00:37, 14.60batch/s, loss=598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg train loss 626.43, bar train loss 5.623, len train loss 0.154, col train loss 163.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 2batch [00:00, 13.61batch/s, loss=616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg test  loss 620.14, bar  test loss 5.497, len  test loss 0.121, col  test loss 163.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 543batch [00:37, 14.50batch/s, loss=652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg train loss 620.35, bar train loss 5.438, len train loss 0.142, col train loss 163.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 2batch [00:00, 13.89batch/s, loss=619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg test  loss 627.33, bar  test loss 5.454, len  test loss 0.211, col  test loss 163.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 543batch [00:37, 14.49batch/s, loss=601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg train loss 616.21, bar train loss 5.291, len train loss 0.140, col train loss 162.945\n",
      "epoch 10: avg test  loss 612.13, bar  test loss 5.216, len  test loss 0.118, col  test loss 162.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 543batch [00:37, 14.58batch/s, loss=623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg train loss 611.44, bar train loss 5.137, len train loss 0.132, col train loss 162.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 2batch [00:00, 14.39batch/s, loss=609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg test  loss 610.95, bar  test loss 5.095, len  test loss 0.130, col  test loss 162.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 543batch [00:36, 14.68batch/s, loss=590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg train loss 606.94, bar train loss 5.000, len train loss 0.122, col train loss 162.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 2batch [00:00, 14.29batch/s, loss=605]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg test  loss 606.62, bar  test loss 4.986, len  test loss 0.123, col  test loss 162.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 543batch [00:36, 14.72batch/s, loss=632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg train loss 604.54, bar train loss 4.904, len train loss 0.125, col train loss 162.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 2batch [00:00, 14.49batch/s, loss=557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg test  loss 606.59, bar  test loss 4.889, len  test loss 0.134, col  test loss 162.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 543batch [00:36, 14.73batch/s, loss=565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg train loss 601.00, bar train loss 4.804, len train loss 0.116, col train loss 161.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 2batch [00:00, 13.99batch/s, loss=604]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg test  loss 623.56, bar  test loss 4.847, len  test loss 0.330, col  test loss 162.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 543batch [00:37, 14.57batch/s, loss=678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg train loss 597.11, bar train loss 4.691, len train loss 0.106, col train loss 161.696\n",
      "epoch 15: avg test  loss 595.60, bar  test loss 4.682, len  test loss 0.085, col  test loss 161.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 543batch [00:36, 14.72batch/s, loss=570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg train loss 593.15, bar train loss 4.594, len train loss 0.092, col train loss 161.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 2batch [00:00, 14.39batch/s, loss=634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg test  loss 592.92, bar  test loss 4.617, len  test loss 0.080, col  test loss 161.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 543batch [00:37, 14.62batch/s, loss=570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg train loss 591.01, bar train loss 4.528, len train loss 0.089, col train loss 161.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 2batch [00:00, 14.60batch/s, loss=591]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg test  loss 595.07, bar  test loss 4.530, len  test loss 0.124, col  test loss 161.550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 543batch [00:36, 14.72batch/s, loss=578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg train loss 588.62, bar train loss 4.469, len train loss 0.083, col train loss 161.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 2batch [00:00, 14.18batch/s, loss=568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg test  loss 588.97, bar  test loss 4.433, len  test loss 0.076, col  test loss 161.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 543batch [00:37, 14.67batch/s, loss=614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg train loss 586.60, bar train loss 4.404, len train loss 0.080, col train loss 160.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 2batch [00:00, 14.18batch/s, loss=606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg test  loss 587.59, bar  test loss 4.403, len  test loss 0.072, col  test loss 161.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 543batch [00:36, 14.70batch/s, loss=609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg train loss 584.29, bar train loss 4.341, len train loss 0.074, col train loss 160.816\n",
      "epoch 20: avg test  loss 587.76, bar  test loss 4.487, len  test loss 0.074, col  test loss 161.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 543batch [00:37, 14.65batch/s, loss=606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg train loss 582.26, bar train loss 4.292, len train loss 0.069, col train loss 160.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 2batch [00:00, 14.29batch/s, loss=604]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg test  loss 584.81, bar  test loss 4.329, len  test loss 0.066, col  test loss 161.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 543batch [00:36, 14.71batch/s, loss=535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg train loss 581.00, bar train loss 4.248, len train loss 0.070, col train loss 160.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 2batch [00:00, 14.60batch/s, loss=559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg test  loss 583.31, bar  test loss 4.346, len  test loss 0.064, col  test loss 161.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 543batch [00:36, 14.70batch/s, loss=594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg train loss 579.39, bar train loss 4.204, len train loss 0.068, col train loss 160.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 2batch [00:00, 14.29batch/s, loss=567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg test  loss 582.57, bar  test loss 4.290, len  test loss 0.069, col  test loss 160.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 543batch [00:36, 14.72batch/s, loss=618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg train loss 578.13, bar train loss 4.155, len train loss 0.069, col train loss 160.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 2batch [00:00, 14.29batch/s, loss=565]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg test  loss 581.31, bar  test loss 4.248, len  test loss 0.064, col  test loss 160.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 543batch [00:36, 14.70batch/s, loss=579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: avg train loss 577.00, bar train loss 4.129, len train loss 0.067, col train loss 160.050\n",
      "epoch 25: avg test  loss 580.37, bar  test loss 4.249, len  test loss 0.059, col  test loss 160.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 543batch [00:36, 14.71batch/s, loss=576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg train loss 575.70, bar train loss 4.088, len train loss 0.066, col train loss 159.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 2batch [00:00, 14.29batch/s, loss=585]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg test  loss 579.77, bar  test loss 4.215, len  test loss 0.064, col  test loss 160.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 543batch [00:37, 14.61batch/s, loss=595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg train loss 574.32, bar train loss 4.055, len train loss 0.064, col train loss 159.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 2batch [00:00, 14.29batch/s, loss=586]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg test  loss 579.60, bar  test loss 4.203, len  test loss 0.060, col  test loss 160.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 543batch [00:37, 14.66batch/s, loss=614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg train loss 573.26, bar train loss 4.025, len train loss 0.064, col train loss 159.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 2batch [00:00, 14.29batch/s, loss=550]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg test  loss 578.57, bar  test loss 4.167, len  test loss 0.063, col  test loss 160.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 543batch [00:36, 14.70batch/s, loss=549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg train loss 572.64, bar train loss 3.996, len train loss 0.065, col train loss 159.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 2batch [00:00, 14.18batch/s, loss=543]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg test  loss 578.37, bar  test loss 4.117, len  test loss 0.070, col  test loss 160.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 543batch [00:37, 14.67batch/s, loss=592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg train loss 571.07, bar train loss 3.967, len train loss 0.061, col train loss 159.377\n",
      "epoch 30: avg test  loss 576.97, bar  test loss 4.116, len  test loss 0.059, col  test loss 160.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 543batch [00:36, 14.69batch/s, loss=547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg train loss 570.34, bar train loss 3.928, len train loss 0.063, col train loss 159.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 2batch [00:00, 14.39batch/s, loss=560]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg test  loss 576.28, bar  test loss 4.074, len  test loss 0.058, col  test loss 160.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 543batch [00:36, 14.69batch/s, loss=630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg train loss 569.35, bar train loss 3.906, len train loss 0.061, col train loss 159.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 2batch [00:00, 14.49batch/s, loss=569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg test  loss 577.19, bar  test loss 4.124, len  test loss 0.070, col  test loss 160.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 543batch [00:37, 14.53batch/s, loss=569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg train loss 568.67, bar train loss 3.880, len train loss 0.062, col train loss 159.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 2batch [00:00, 14.18batch/s, loss=560]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg test  loss 575.14, bar  test loss 4.086, len  test loss 0.057, col  test loss 160.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 543batch [00:36, 14.69batch/s, loss=650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg train loss 567.97, bar train loss 3.869, len train loss 0.060, col train loss 159.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 2batch [00:00, 14.49batch/s, loss=570]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg test  loss 575.05, bar  test loss 4.028, len  test loss 0.061, col  test loss 160.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 543batch [00:36, 14.68batch/s, loss=602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg train loss 566.75, bar train loss 3.837, len train loss 0.058, col train loss 158.887\n",
      "epoch 35: avg test  loss 574.82, bar  test loss 4.018, len  test loss 0.062, col  test loss 160.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 543batch [00:37, 14.65batch/s, loss=599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg train loss 566.44, bar train loss 3.821, len train loss 0.060, col train loss 158.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 2batch [00:00, 14.49batch/s, loss=552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg test  loss 573.78, bar  test loss 4.016, len  test loss 0.061, col  test loss 159.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 543batch [00:36, 14.69batch/s, loss=547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg train loss 565.45, bar train loss 3.795, len train loss 0.058, col train loss 158.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 2batch [00:00, 14.39batch/s, loss=543]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg test  loss 572.82, bar  test loss 3.990, len  test loss 0.059, col  test loss 159.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 543batch [00:36, 14.68batch/s, loss=576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg train loss 565.09, bar train loss 3.786, len train loss 0.059, col train loss 158.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 2batch [00:00, 14.29batch/s, loss=536]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg test  loss 573.45, bar  test loss 3.997, len  test loss 0.063, col  test loss 159.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 543batch [00:37, 14.62batch/s, loss=620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg train loss 564.29, bar train loss 3.766, len train loss 0.057, col train loss 158.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 2batch [00:00, 14.29batch/s, loss=569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg test  loss 574.87, bar  test loss 3.983, len  test loss 0.068, col  test loss 159.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 543batch [00:36, 14.71batch/s, loss=565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: avg train loss 563.81, bar train loss 3.751, len train loss 0.057, col train loss 158.545\n",
      "epoch 40: avg test  loss 572.91, bar  test loss 3.983, len  test loss 0.064, col  test loss 159.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 543batch [00:36, 14.68batch/s, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg train loss 562.98, bar train loss 3.728, len train loss 0.057, col train loss 158.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 2batch [00:00, 14.49batch/s, loss=557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg test  loss 573.68, bar  test loss 3.964, len  test loss 0.057, col  test loss 159.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 543batch [00:37, 14.67batch/s, loss=537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg train loss 562.88, bar train loss 3.722, len train loss 0.058, col train loss 158.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 2batch [00:00, 14.18batch/s, loss=569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg test  loss 572.80, bar  test loss 3.968, len  test loss 0.064, col  test loss 159.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 543batch [00:37, 14.65batch/s, loss=554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg train loss 561.78, bar train loss 3.692, len train loss 0.056, col train loss 158.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 2batch [00:00, 14.49batch/s, loss=526]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg test  loss 571.60, bar  test loss 3.961, len  test loss 0.054, col  test loss 159.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 543batch [00:37, 14.66batch/s, loss=563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg train loss 561.12, bar train loss 3.678, len train loss 0.055, col train loss 158.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 2batch [00:00, 14.49batch/s, loss=571]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg test  loss 571.09, bar  test loss 3.948, len  test loss 0.057, col  test loss 159.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 543batch [00:36, 14.68batch/s, loss=573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45: avg train loss 560.67, bar train loss 3.667, len train loss 0.055, col train loss 158.183\n",
      "epoch 45: avg test  loss 571.53, bar  test loss 3.953, len  test loss 0.060, col  test loss 159.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 543batch [00:37, 14.63batch/s, loss=608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg train loss 560.43, bar train loss 3.661, len train loss 0.056, col train loss 158.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 2batch [00:00, 14.39batch/s, loss=572]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg test  loss 572.18, bar  test loss 3.933, len  test loss 0.058, col  test loss 159.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 543batch [00:37, 14.65batch/s, loss=571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg train loss 560.01, bar train loss 3.650, len train loss 0.054, col train loss 158.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 2batch [00:00, 14.29batch/s, loss=586]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg test  loss 570.94, bar  test loss 3.916, len  test loss 0.055, col  test loss 159.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 543batch [00:37, 14.65batch/s, loss=594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg train loss 559.42, bar train loss 3.628, len train loss 0.055, col train loss 158.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 2batch [00:00, 14.60batch/s, loss=587]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg test  loss 570.30, bar  test loss 3.895, len  test loss 0.055, col  test loss 159.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 543batch [00:37, 14.66batch/s, loss=552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg train loss 558.88, bar train loss 3.618, len train loss 0.054, col train loss 157.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 2batch [00:00, 14.60batch/s, loss=547]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg test  loss 571.28, bar  test loss 3.927, len  test loss 0.065, col  test loss 159.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 543batch [00:37, 14.65batch/s, loss=539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: avg train loss 558.39, bar train loss 3.604, len train loss 0.053, col train loss 157.915\n",
      "epoch 50: avg test  loss 570.25, bar  test loss 3.949, len  test loss 0.057, col  test loss 159.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 543batch [00:37, 14.63batch/s, loss=562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg train loss 558.34, bar train loss 3.595, len train loss 0.055, col train loss 157.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 2batch [00:00, 14.39batch/s, loss=586]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg test  loss 572.91, bar  test loss 3.937, len  test loss 0.078, col  test loss 159.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 543batch [00:37, 14.64batch/s, loss=556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg train loss 557.41, bar train loss 3.580, len train loss 0.053, col train loss 157.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 2batch [00:00, 14.18batch/s, loss=562]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg test  loss 570.46, bar  test loss 3.916, len  test loss 0.058, col  test loss 159.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 543batch [00:37, 14.63batch/s, loss=558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg train loss 557.24, bar train loss 3.572, len train loss 0.053, col train loss 157.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 2batch [00:00, 14.29batch/s, loss=582]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg test  loss 569.64, bar  test loss 3.895, len  test loss 0.055, col  test loss 159.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 543batch [00:37, 14.62batch/s, loss=568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg train loss 556.90, bar train loss 3.567, len train loss 0.053, col train loss 157.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 2batch [00:00, 14.39batch/s, loss=552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg test  loss 571.04, bar  test loss 3.955, len  test loss 0.055, col  test loss 159.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 543batch [00:37, 14.63batch/s, loss=570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55: avg train loss 556.47, bar train loss 3.553, len train loss 0.054, col train loss 157.643\n",
      "epoch 55: avg test  loss 570.65, bar  test loss 3.916, len  test loss 0.058, col  test loss 159.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 543batch [00:37, 14.62batch/s, loss=603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg train loss 555.77, bar train loss 3.535, len train loss 0.053, col train loss 157.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 2batch [00:00, 14.29batch/s, loss=546]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg test  loss 569.86, bar  test loss 3.929, len  test loss 0.057, col  test loss 159.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 543batch [00:37, 14.64batch/s, loss=569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg train loss 555.28, bar train loss 3.527, len train loss 0.051, col train loss 157.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 2batch [00:00, 14.29batch/s, loss=559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg test  loss 569.50, bar  test loss 3.910, len  test loss 0.058, col  test loss 159.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 543batch [00:37, 14.63batch/s, loss=600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg train loss 554.97, bar train loss 3.519, len train loss 0.052, col train loss 157.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 2batch [00:00, 14.18batch/s, loss=539]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg test  loss 570.64, bar  test loss 3.916, len  test loss 0.059, col  test loss 159.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 543batch [00:37, 14.62batch/s, loss=569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg train loss 554.80, bar train loss 3.512, len train loss 0.053, col train loss 157.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 2batch [00:00, 14.39batch/s, loss=555]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg test  loss 570.12, bar  test loss 3.924, len  test loss 0.056, col  test loss 159.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 543batch [00:37, 14.59batch/s, loss=509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60: avg train loss 554.15, bar train loss 3.496, len train loss 0.052, col train loss 157.351\n",
      "epoch 60: avg test  loss 569.01, bar  test loss 3.882, len  test loss 0.052, col  test loss 159.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 543batch [00:37, 14.48batch/s, loss=569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg train loss 554.08, bar train loss 3.493, len train loss 0.052, col train loss 157.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 2batch [00:00, 12.42batch/s, loss=572]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg test  loss 569.44, bar  test loss 3.917, len  test loss 0.055, col  test loss 159.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 543batch [00:37, 14.60batch/s, loss=570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg train loss 553.90, bar train loss 3.490, len train loss 0.053, col train loss 157.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 2batch [00:00, 14.39batch/s, loss=565]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg test  loss 572.28, bar  test loss 3.924, len  test loss 0.063, col  test loss 159.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 543batch [00:37, 14.51batch/s, loss=553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg train loss 553.18, bar train loss 3.473, len train loss 0.052, col train loss 157.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 2batch [00:00, 13.79batch/s, loss=539]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg test  loss 570.21, bar  test loss 3.921, len  test loss 0.061, col  test loss 159.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 543batch [00:37, 14.40batch/s, loss=609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg train loss 553.07, bar train loss 3.470, len train loss 0.052, col train loss 157.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 2batch [00:00, 14.49batch/s, loss=536]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg test  loss 568.91, bar  test loss 3.877, len  test loss 0.056, col  test loss 159.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 543batch [00:36, 14.79batch/s, loss=579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: avg train loss 552.69, bar train loss 3.463, len train loss 0.051, col train loss 157.121\n",
      "epoch 65: avg test  loss 568.45, bar  test loss 3.883, len  test loss 0.056, col  test loss 159.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 543batch [00:36, 14.93batch/s, loss=569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg train loss 552.38, bar train loss 3.452, len train loss 0.052, col train loss 157.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 2batch [00:00, 14.29batch/s, loss=536]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg test  loss 569.03, bar  test loss 3.904, len  test loss 0.059, col  test loss 159.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 543batch [00:36, 14.94batch/s, loss=518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg train loss 551.86, bar train loss 3.440, len train loss 0.051, col train loss 157.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 2batch [00:00, 14.60batch/s, loss=549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg test  loss 569.75, bar  test loss 3.880, len  test loss 0.067, col  test loss 159.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 543batch [00:36, 14.92batch/s, loss=556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg train loss 551.68, bar train loss 3.434, len train loss 0.052, col train loss 156.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 2batch [00:00, 14.49batch/s, loss=553]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg test  loss 569.06, bar  test loss 3.889, len  test loss 0.055, col  test loss 159.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 543batch [00:36, 14.71batch/s, loss=578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg train loss 551.49, bar train loss 3.440, len train loss 0.051, col train loss 156.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 2batch [00:00, 13.89batch/s, loss=568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg test  loss 569.19, bar  test loss 3.888, len  test loss 0.057, col  test loss 159.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 543batch [00:37, 14.67batch/s, loss=582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70: avg train loss 551.15, bar train loss 3.430, len train loss 0.051, col train loss 156.892\n",
      "epoch 70: avg test  loss 568.92, bar  test loss 3.877, len  test loss 0.055, col  test loss 159.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 543batch [00:37, 14.41batch/s, loss=548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg train loss 550.91, bar train loss 3.430, len train loss 0.051, col train loss 156.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 2batch [00:00, 14.39batch/s, loss=567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg test  loss 569.81, bar  test loss 3.914, len  test loss 0.064, col  test loss 159.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 543batch [00:37, 14.51batch/s, loss=571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg train loss 550.71, bar train loss 3.417, len train loss 0.052, col train loss 156.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 2batch [00:00, 13.89batch/s, loss=544]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg test  loss 568.98, bar  test loss 3.883, len  test loss 0.054, col  test loss 159.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 4batch [00:00, 13.95batch/s, loss=545]"
     ]
    }
   ],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 500, 0, save_folder=\"HVAEFCP1\",save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diva.lqz1[-5:], diva.lqz2[-5:], diva.lpz1[-5:], diva.lpz2[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4182003,
     "status": "ok",
     "timestamp": 1647010362327,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "NprX9l7G73MJ",
    "outputId": "e970b2ef-1d7d-4702-dd1f-3bb4b59c0326"
   },
   "outputs": [],
   "source": [
    "lss2, lss_t2 = train(default_args, train_loader, test_loader, diva, optimizer, 1000, 500, save_folder=\"VAEFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1600, 1000, save_folder=\"VAEFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4r_UyPUGXqT"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(lss, lss_t):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(lss, label=\"train loss\")\n",
    "    ax.plot(lss_t, label = \"test loss\")\n",
    "    #ax1 = ax.twinx()\n",
    "    #ax1.plot(yacc, label = \"train accuracy\", ls='--')\n",
    "    #ax1.plot(yacc_t, label = \"test accuracy\", ls='--')\n",
    "\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    #lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(lines, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1645822416415,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "fTFZZmoguwtU",
    "outputId": "540c8c1f-99d7-4931-c102-7c96747243aa"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss, lss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1645623855467,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "mq2FG26TznE1",
    "outputId": "152eddd3-a440-4b25-c437-498efb0a7ffe"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss3, lss_t3, yacc3, yacc_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FyP02qPdgso"
   },
   "outputs": [],
   "source": [
    "def plot_change_latent_var(diva, lat_space=\"y\", var_idx=[0,1,2,3,4,5,6,7], step = 5):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:len(var_idx)].to(DEVICE).float()\n",
    "        x = a[1][0][:len(var_idx)].to(DEVICE).float()\n",
    "        y = a[1][1][:len(var_idx)].to(DEVICE).float()\n",
    "\n",
    "        zx, zx_sc = diva.qzx(x)\n",
    "        zy, zy_sc = diva.qzy(x)\n",
    "        zd, zd_sc =  diva.qzd(x)\n",
    "\n",
    "        print(torch.max(zy), torch.min(zy), \"sdmax:\", torch.max(zy_sc))\n",
    "\n",
    "        out = change(zx, zy, zd, var_idx, lat_space, diva, step)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=out.shape[0],nrows=len(var_idx),figsize=(10*4*out.shape[0],10*len(var_idx)))\n",
    "    for i in range(out.shape[0]):\n",
    "      for j in range(len(var_idx)):\n",
    "        ax[j,i].imshow(out[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6kJu1APenFe"
   },
   "outputs": [],
   "source": [
    "def change(zx, zy, zd, idx, lat = \"y\", model=diva, step = 2):\n",
    "    \n",
    "    dif = np.arange(-30,15,step)\n",
    "    print(torch.max(zy), torch.min(zy))\n",
    "    out = np.zeros((dif.shape[0], len(idx), 25, 100 ,3))  \n",
    "    #print(zy.shape, dif.shape[0])\n",
    "    for i in range(dif.shape[0]):\n",
    "      for j in range(len(idx)):\n",
    "        if lat == \"y\":\n",
    "            zy[j,idx] = dif[i]\n",
    "        elif lat == \"x\":\n",
    "            zx[j,idx] = dif[i]\n",
    "        elif lat == \"d\":\n",
    "            zd[j,idx] = dif[i]\n",
    "        len_, bar, col = model.px(zd[j],zx[j],zy[j])\n",
    "        out[i,j] = model.px.reconstruct_image(len_[None,:], bar, col)\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 33513,
     "status": "ok",
     "timestamp": 1645623900042,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "4U1JHmTKh0cE",
    "outputId": "b0a1850e-9f0d-4163-813b-8686f4bb05fc"
   },
   "outputs": [],
   "source": [
    "plot_change_latent_var(diva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpZoRZMGHcui"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss2], label=\"train loss\")\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss_t2], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(50,120), yacc2, label = \"train\")\n",
    "ax1.plot(np.arange(50,120), yacc_t2, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1645563980004,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OQMW85JXM6oO",
    "outputId": "dd28a6c2-0024-498e-d571-c705ee67fbd6"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss3], label=\"train loss\")\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss_t3], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(120,180), yacc3, label = \"train\",c='green')\n",
    "ax1.plot(np.arange(120,180), yacc_t3, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whsgNltzXDhK"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfcwhSNIjqIE"
   },
   "source": [
    "## Sampling from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NWGV4Xd7bn8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z5XA4QI1Mb1"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(lat_space=\"y\"):\n",
    "    '''\n",
    "    lat_space: y, d, x\n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1645556291755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "USZ7nIDugT1S",
    "outputId": "174d53bb-845f-458b-ca85-9d749c9c0865"
   },
   "outputs": [],
   "source": [
    "plot(x, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1645550689935,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OE3qVVFFLaPm",
    "outputId": "93953e16-3bda-464b-b765-3aedb9fbe428"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i in range(9):\n",
    "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
    "  \n",
    "plt.savefig('divastamporg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQU05xQEx28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StampVAE (Beta)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

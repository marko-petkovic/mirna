{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "UuXEtFCubCjx"
   },
   "outputs": [],
   "source": [
    "link = 'D:/users/Marko/downloads/mirna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMR4QspjvRl"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aXljY6Cp4zU-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31000,
     "status": "ok",
     "timestamp": 1647023292835,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "VgKU5wNzDK4F",
    "outputId": "2edd95bf-9577-4772-eeca-95c5d32cf026"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
    "sys.path.insert(0, link)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"{link}/saved_models/new/DOUBLEHVAE/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "HuLsYxyh6_ZM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFkNf0cjx2V"
   },
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ae7NZhZGj7Zi"
   },
   "outputs": [],
   "source": [
    "class diva_args:\n",
    "\n",
    "    def __init__(self, z1_dim=256, z2_dim=256, d_dim=45, x_dim=7500, y_dim=2,\n",
    "                 h_dim = 256, h2_dim = 256, number_components = 500,\n",
    "                 beta=1, rec_alpha = 100, rec_beta = 20, \n",
    "                 rec_gamma = 1, warmup = 1, prewarmup = 1):\n",
    "\n",
    "        self.z1_dim = z1_dim\n",
    "        self.z2_dim = z2_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        \n",
    "        self.h_dim = h_dim\n",
    "        self.h2_dim = h2_dim\n",
    "        \n",
    "        self.number_components = number_components\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.rec_alpha = rec_alpha\n",
    "        self.rec_beta = rec_beta\n",
    "        self.rec_gamma = rec_gamma\n",
    "        self.warmup = warmup\n",
    "        self.prewarmup = prewarmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb1vH-a1j7Rf"
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1647023293159,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "D6ouvuZX3WPs"
   },
   "outputs": [],
   "source": [
    "class MicroRNADataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds='train', create_encodings=False, use_subset=False):\n",
    "        \n",
    "        # loading images\n",
    "        self.images = np.load(f'{link}/data/modmirbase_{ds}_images.npz')['arr_0']/255\n",
    "        \n",
    "        \n",
    "        # loading labels\n",
    "        print('Loading Labels! (~10s)')     \n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        labels = np.load(f'{link}/data/modmirbase_{ds}_labels.npz')['arr_0']\n",
    "        self.labels = ohe.fit_transform(labels)\n",
    "        \n",
    "        # loading encoded images\n",
    "        print(\"loading encodings\")\n",
    "        if create_encodings:\n",
    "            x_len, x_bar, x_col = self.get_encoded_values(self.images, ds)\n",
    "        else:\n",
    "            x_len = np.load(f'{link}/data/modmirbase_{ds}_images_len4.npz')\n",
    "            x_bar = np.load(f'{link}/data/modmirbase_{ds}_images_bar4.npz')\n",
    "            x_col = np.load(f'{link}/data/modmirbase_{ds}_images_col4.npz')\n",
    "        \n",
    "        self.x_len = x_len\n",
    "        self.x_bar = x_bar\n",
    "        self.x_col = x_col\n",
    "        \n",
    "        \n",
    "        self.mountain = np.load(f'{link}/data/modmirbase_{ds}_mountain.npy')\n",
    "        \n",
    "        \n",
    "        # loading names\n",
    "        print('Loading Names! (~5s)')\n",
    "        names =  np.load(f'{link}/data/modmirbase_{ds}_names.npz')['arr_0']\n",
    "        names = [i.decode('utf-8') for i in names]\n",
    "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
    "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
    "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
    "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
    "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
    "                        'ppt', 'tca', 'dme', 'sbi']\n",
    "        # assigning a species label to each observation from species\n",
    "        # with more than 200 observations from past research\n",
    "        self.names = []\n",
    "        for i in names:\n",
    "            append = False\n",
    "            for j in self.species:\n",
    "                if j in i.lower():\n",
    "                    self.names.append(j)\n",
    "                    append = True\n",
    "                    break\n",
    "            if not append:\n",
    "                if 'random' in i.lower() or i.isdigit():\n",
    "                    self.names.append('hsa')\n",
    "                else:\n",
    "                    self.names.append('notfound')\n",
    "        \n",
    "        # performing one hot encoding\n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
    "          \n",
    "        if use_subset:    \n",
    "            idxes = [i == 'hsa' and np.random.choice([True, False]) for i in self.names]\n",
    "            self.names_ohe = self.names_ohe[idxes]\n",
    "            self.labels = self.labels[idxes]\n",
    "            self.images = self.images[idxes]\n",
    "            self.x_len = self.x_len[idxes]\n",
    "            self.x_col = self.x_col[idxes]\n",
    "            self.x_bar = self.x_bar[idxes]\n",
    "            self.mountain = self.mountain[idxes]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.names_ohe[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.images[idx]\n",
    "        x = np.transpose(x, (2,0,1))\n",
    "        x_len = self.x_len[idx]\n",
    "        x_col = self.x_col[idx]\n",
    "        x_bar = self.x_bar[idx]\n",
    "        mount = self.mountain[idx]                        \n",
    "        return (x, y, d, x_len, x_col, x_bar, mount)\n",
    "\n",
    "\n",
    "    def get_encoded_values(self, x, ds):\n",
    "        \"\"\"\n",
    "        given an image or batch of images\n",
    "        returns length of strand, length of bars and colors of bars\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        x = np.transpose(x, (0,3,1,2))\n",
    "        out_len = np.zeros((n), dtype=np.uint8)\n",
    "        out_col = np.zeros((n,25,100), dtype=np.uint8)\n",
    "        out_bar = np.zeros((n,2,100), dtype=np.uint8)\n",
    "\n",
    "        for i in range(n):\n",
    "            if i % 100 == 0:\n",
    "                print(f'at {i} out of {n}')\n",
    "            rna_len = 0\n",
    "            broke = False\n",
    "            for j in range(100):\n",
    "                if (x[i,:,12,j] == np.array([1,1,1])).all():\n",
    "                    out_len[i] = rna_len\n",
    "                    broke = True\n",
    "                    break\n",
    "                else:\n",
    "                    rna_len += 1\n",
    "                    # check color of bars\n",
    "                    out_col[i, self.get_color(x,i,j),j] = 1 \n",
    "                    #out_col[i, self.get_color(x[i,:,13,j]), 1, j] = 1\n",
    "                    # check length of bars\n",
    "                    len1 = 0\n",
    "                    # loop until white pixel\n",
    "                    while not (x[i,:,12-len1,j] == np.array([1.,1.,1.])).all():\n",
    "                        len1 += 1\n",
    "                        if 13-len1 == 0:\n",
    "                            break\n",
    "                    out_bar[i, 0, j] = len1\n",
    "\n",
    "                    len2 = 0\n",
    "                    while not (x[i,:,13+len2,j] == np.array([1.,1.,1.])).all():\n",
    "                        len2 += 1\n",
    "                        if 13+len2 == 25:\n",
    "                            break\n",
    "                    out_bar[i, 1, j] = len2\n",
    "            if not broke:\n",
    "                out_len[i] = rna_len\n",
    "\n",
    "\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_len4.npz', 'wb') as f:\n",
    "            np.save(f, out_len)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_col4.npz', 'wb') as f:\n",
    "            np.save(f, out_col)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_bar4.npz', 'wb') as f:\n",
    "            np.save(f, out_bar)\n",
    "        \n",
    "\n",
    "        return out_len, out_bar, out_col\n",
    "\n",
    "    def get_color(self, x, i, j):\n",
    "        \n",
    "        col = self._get_color(x[i,:,12,j])+self._get_color(x[i,:,13,j])\n",
    "        if col == '00':\n",
    "            return 0\n",
    "        if col == '01':\n",
    "            return 1\n",
    "        if col == '02':\n",
    "            return 2\n",
    "        if col == '03':\n",
    "            return 3\n",
    "        if col == '04':\n",
    "            return 4\n",
    "        if col == '10':\n",
    "            return 5\n",
    "        if col == '11':\n",
    "            return 6\n",
    "        if col == '12':\n",
    "            return 7\n",
    "        if col == '13':\n",
    "            return 8\n",
    "        if col == '14':\n",
    "            return 9\n",
    "        if col == '20':\n",
    "            return 10\n",
    "        if col == '21':\n",
    "            return 11\n",
    "        if col == '22':\n",
    "            return 12\n",
    "        if col == '23':\n",
    "            return 13\n",
    "        if col == '24':\n",
    "            return 14\n",
    "        if col == '30':\n",
    "            return 15\n",
    "        if col == '31':\n",
    "            return 16\n",
    "        if col == '32':\n",
    "            return 17\n",
    "        if col == '33':\n",
    "            return 18\n",
    "        if col == '34':\n",
    "            return 19\n",
    "        if col == '40':\n",
    "            return 20\n",
    "        if col == '41':\n",
    "            return 21\n",
    "        if col == '42':\n",
    "            return 22\n",
    "        if col == '43':\n",
    "            return 23\n",
    "        if col == '44':\n",
    "            return 24\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _get_color(self, pixel):\n",
    "        \"\"\"\n",
    "        returns the encoded value for a pixel\n",
    "        \"\"\"\n",
    "        if (pixel == np.array([0,0,0])).all():  \n",
    "            return \"0\" # black\n",
    "        elif (pixel == np.array([1,0,0])).all():  \n",
    "            return \"1\" # red\n",
    "        elif (pixel == np.array([0,0,1])).all():  \n",
    "            return \"2\" # blue\n",
    "        elif (pixel == np.array([0,1,0])).all():  \n",
    "            return \"3\" # green\n",
    "        elif (pixel == np.array([1,1,0])).all():  \n",
    "            return \"4\" # yellow\n",
    "        else:\n",
    "            print(\"Something wrong!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxj-WGXMj-Ne"
   },
   "source": [
    "## Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "RKizJuchX9uG"
   },
   "outputs": [],
   "source": [
    "# Decoders\n",
    "class px(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z1_dim, z2_dim, \n",
    "                 h_dim, h2_dim, dim0=2000, dim1=128, dim2=64):\n",
    "        super(px, self).__init__()\n",
    "\n",
    "        \n",
    "        # p(z1|z2)\n",
    "        \n",
    "        self.p_z1 = nn.Sequential(nn.Linear(z2_dim+200, h2_dim),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(h2_dim, h2_dim),\n",
    "                                  nn.ReLU())\n",
    "        self.mu_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim))\n",
    "        self.si_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim), nn.Softplus())\n",
    "        \n",
    "        \n",
    "        # p(x|z1,z2,m)\n",
    "        \n",
    "        self.px_z1 = nn.Sequential(nn.Linear(z1_dim, h_dim),\n",
    "                                   nn.ReLU())\n",
    "        self.px_z2 = nn.Sequential(nn.Linear(z2_dim+200, h_dim),\n",
    "                                   nn.ReLU())\n",
    "        # seperate decoders for length of RNA, color and size of bars\n",
    "        self.fc_col = nn.Sequential(nn.Linear(2*h_dim, 600),\n",
    "                                    nn.ReLU())\n",
    "        self.fc_col1 = nn.Sequential(nn.Linear(600,2500))\n",
    "        \n",
    "        self.fc_bar = nn.Sequential(nn.Linear(2*h_dim, dim1),  \n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(dim1, dim2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.4))\n",
    "        \n",
    "        self.fc_len = nn.Sequential(nn.Linear(2*h_dim, dim1),  \n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(dim1, dim2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.4))\n",
    "#         self.fc3 = nn.Sequential(nn.Linear(dim1, dim2, bias=False),\n",
    "#                                  nn.ReLU())\n",
    "        \n",
    "        # Predicting length and color of each bar\n",
    "        #self.color = nn.Sequential(nn.Conv1d(1,5, kernel_size=1, bias=False), \n",
    "                                  # nn.Softmax(dim=1))\n",
    "\n",
    "        \n",
    "        # Predicting the length of each bar\n",
    "        self.length_bar_top = nn.Sequential(nn.Linear(dim2,100), nn.Softplus())\n",
    "        self.length_bar_bot = nn.Sequential(nn.Linear(dim2,100), nn.Softplus())\n",
    "        #self.length_bar_scale = nn.Sequential(nn.Conv1d(100, 1, kernel_size = 3, padding = 'same', bias=False), nn.Sigmoid())\n",
    "        \n",
    "        # Predicting length of the RNA strand\n",
    "        self.length_RNA = nn.Sequential(nn.Linear(dim2,400), nn.ReLU(),nn.Linear(400,1), nn.Softplus())\n",
    "        #self.length_RNA_scale = nn.Sequential(nn.Linear(400,1, bias=False), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, z1, mz2):\n",
    "        \n",
    "        # p(z1|z2)\n",
    "        pz1 = self.p_z1(mz2)\n",
    "        pz1_m = self.mu_z1(pz1)\n",
    "        pz1_s = self.si_z1(pz1)\n",
    "        \n",
    "        # p(x|z1,z2,m)\n",
    "        hz1 = self.px_z1(z1)\n",
    "        hz2 = self.px_z2(mz2)\n",
    "        h = torch.cat([hz1,hz2],1)\n",
    "        \n",
    "        len_RNA = self.fc_len(h)\n",
    "        len_RNA = self.length_RNA(len_RNA)\n",
    "        len_RNA_sc = nn.Parameter(torch.tensor([1.])).to(DEVICE)\n",
    "\n",
    "        \n",
    "        len_bar = self.fc_bar(h)\n",
    "        len_bar = torch.cat([self.length_bar_top(len_bar)[:,None,:],self.length_bar_bot(len_bar)[:,None,:]], dim=1) \n",
    "        len_bar_sc = nn.Parameter(torch.tensor([1.])).to(DEVICE)\n",
    "\n",
    "        col = self.fc_col(h)\n",
    "        col = self.fc_col1(col).reshape(-1,25,100)\n",
    "        col_bar = nn.Softmax(dim=1)(col)\n",
    "        \n",
    "        return len_RNA, len_RNA_sc, len_bar, len_bar_sc, col_bar, pz1_m, pz1_s\n",
    "\n",
    "    def reconstruct_image(self, len_RNA, var_RNA, len_bar, var_bar ,col_bar, sample=False):\n",
    "        \"\"\"\n",
    "        reconstructs RNA image given output from decoder\n",
    "        even indexes of len_bar and col_bar   -> top\n",
    "        uneven indexes of len_bar and col_bar -> bottom\n",
    "        function does not support sampling yet\n",
    "        color reconstructions: 0: black\n",
    "                               1: red\n",
    "                               2: blue\n",
    "                               3: green\n",
    "                               4: yellow\n",
    "        \"\"\"\n",
    "        color_dict = {\n",
    "                  0: np.array([0,0,0]), # black\n",
    "                  1: np.array([1,0,0]), # red\n",
    "                  3: np.array([0,1,0]), # green\n",
    "                  2: np.array([0,0,1]), # blue\n",
    "                  4: np.array([1,1,0])  # yellow\n",
    "                  }\n",
    "    \n",
    "        _color_dict =  {0: (0,0),\n",
    "                        1: (0,1),\n",
    "                        2: (0,2),\n",
    "                        3: (0,3),\n",
    "                        4: (0,4),\n",
    "                        5: (1,0),\n",
    "                        6: (1,1),\n",
    "                        7: (1,2),\n",
    "                        8: (1,3),\n",
    "                        9: (1,4),\n",
    "                        10: (1,0),\n",
    "                        11: (2,1),\n",
    "                        12: (2,2),\n",
    "                        13: (2,3),\n",
    "                        14: (2,4),\n",
    "                        15: (2,0),\n",
    "                        16: (3,1),\n",
    "                        17: (3,2),\n",
    "                        18: (3,3),\n",
    "                        19: (3,4),\n",
    "                        20: (3,0),\n",
    "                        21: (4,1),\n",
    "                        22: (4,2),\n",
    "                        23: (4,3),\n",
    "                        24: (4,4),\n",
    "                        }       \n",
    "        len_RNA = len_RNA.cpu().numpy()\n",
    "        var_RNA = var_RNA.cpu().numpy()\n",
    "        #.reshape((100,))\n",
    "        len_bar = len_bar.cpu().numpy()\n",
    "        var_bar = var_bar.cpu().numpy()\n",
    "        col_bar = col_bar.cpu().numpy()\n",
    "        n = len_RNA.shape[0]\n",
    "        output = np.ones((n,25,100,3))\n",
    "\n",
    "        for i in range(n):\n",
    "            if sample:\n",
    "                limit = int(np.round(np.random.normal(loc=len_RNA[i], scale=var_RNA[i])))\n",
    "            else:\n",
    "                limit = int(np.round(len_RNA[i]))\n",
    "            limit = min(100, limit)\n",
    "            for j in range(limit):\n",
    "                if sample:\n",
    "                    _len_bar_1 = int(np.round(np.random.normal(loc=len_bar[i,0,j], scale=var_bar[i,0,j])))\n",
    "                    _len_bar_2 = int(np.round(np.random.normal(loc=len_bar[i,1,j], scale=var_bar[i,1,j])))\n",
    "                    _col_bar_1 = np.random.choice(np.arange(5), p = col_bar[i, :, 2*j])\n",
    "                    _col_bar_2 = np.random.choice(np.arange(5), p = col_bar[i,:, 2*j+1])\n",
    "                else:\n",
    "                    _len_bar_1 = int(np.round(len_bar[i,0,j])) \n",
    "                    _len_bar_2 = int(np.round(len_bar[i,1,j]))\n",
    "                    _col_bar_1, _col_bar_2 = _color_dict[np.argmax(col_bar[i,:,j])]\n",
    "                    \n",
    "                h1 = max(0,13-_len_bar_1)\n",
    "                # paint upper bar\n",
    "                output[i, h1:13, j] = color_dict[_col_bar_1]\n",
    "                h2 = min(25,13+_len_bar_2)\n",
    "                # paint lower bar\n",
    "                output[i, 13:h2, j] = color_dict[_col_bar_2]\n",
    "        \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.round(3.7, 0))\n",
    "int(3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "1y8G2S1zxzTH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "px                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 500]                  --\n",
       "│    └─Linear: 2-1                       [1, 500]                  350,500\n",
       "│    └─ReLU: 2-2                         [1, 500]                  --\n",
       "│    └─Linear: 2-3                       [1, 500]                  250,500\n",
       "│    └─ReLU: 2-4                         [1, 500]                  --\n",
       "├─Sequential: 1-2                        [1, 500]                  --\n",
       "│    └─Linear: 2-5                       [1, 500]                  250,500\n",
       "├─Sequential: 1-3                        [1, 500]                  --\n",
       "│    └─Linear: 2-6                       [1, 500]                  250,500\n",
       "│    └─Softplus: 2-7                     [1, 500]                  --\n",
       "├─Sequential: 1-4                        [1, 500]                  --\n",
       "│    └─Linear: 2-8                       [1, 500]                  250,500\n",
       "│    └─ReLU: 2-9                         [1, 500]                  --\n",
       "├─Sequential: 1-5                        [1, 500]                  --\n",
       "│    └─Linear: 2-10                      [1, 500]                  350,500\n",
       "│    └─ReLU: 2-11                        [1, 500]                  --\n",
       "├─Sequential: 1-6                        [1, 64]                   --\n",
       "│    └─Linear: 2-12                      [1, 128]                  128,128\n",
       "│    └─ReLU: 2-13                        [1, 128]                  --\n",
       "│    └─Linear: 2-14                      [1, 64]                   8,256\n",
       "│    └─ReLU: 2-15                        [1, 64]                   --\n",
       "│    └─Dropout: 2-16                     [1, 64]                   --\n",
       "├─Sequential: 1-7                        [1, 1]                    --\n",
       "│    └─Linear: 2-17                      [1, 400]                  26,000\n",
       "│    └─ReLU: 2-18                        [1, 400]                  --\n",
       "│    └─Linear: 2-19                      [1, 1]                    401\n",
       "│    └─Softplus: 2-20                    [1, 1]                    --\n",
       "├─Sequential: 1-8                        [1, 64]                   --\n",
       "│    └─Linear: 2-21                      [1, 128]                  128,128\n",
       "│    └─ReLU: 2-22                        [1, 128]                  --\n",
       "│    └─Linear: 2-23                      [1, 64]                   8,256\n",
       "│    └─ReLU: 2-24                        [1, 64]                   --\n",
       "│    └─Dropout: 2-25                     [1, 64]                   --\n",
       "├─Sequential: 1-9                        [1, 100]                  --\n",
       "│    └─Linear: 2-26                      [1, 100]                  6,500\n",
       "│    └─Softplus: 2-27                    [1, 100]                  --\n",
       "├─Sequential: 1-10                       [1, 100]                  --\n",
       "│    └─Linear: 2-28                      [1, 100]                  6,500\n",
       "│    └─Softplus: 2-29                    [1, 100]                  --\n",
       "├─Sequential: 1-11                       [1, 600]                  --\n",
       "│    └─Linear: 2-30                      [1, 600]                  600,600\n",
       "│    └─ReLU: 2-31                        [1, 600]                  --\n",
       "├─Sequential: 1-12                       [1, 2500]                 --\n",
       "│    └─Linear: 2-32                      [1, 2500]                 1,502,500\n",
       "==========================================================================================\n",
       "Total params: 4,118,269\n",
       "Trainable params: 4,118,269\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.12\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.06\n",
       "Params size (MB): 16.47\n",
       "Estimated Total Size (MB): 16.53\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, (1,2))\n",
    "pzy_ = px(45, 7500, 2, 500,500,500,500)\n",
    "summary(pzy_, [(1,500),(1,700)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmNnZWXvkCDP"
   },
   "source": [
    "## Endcoder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647013220008,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "tt82wvITwg4j"
   },
   "outputs": [],
   "source": [
    "#pzy_.reconstruct_image(torch.zeros((1,100)), torch.zeros((1,13,200)), torch.zeros(1,5,200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647023293469,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "78ZFH8gYl_-z"
   },
   "outputs": [],
   "source": [
    "class qz(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z1_dim ,z2_dim, h_dim, h2_dim):\n",
    "        super(qz, self).__init__()\n",
    "\n",
    "        # q(z2 | x)\n",
    "        self.encoder_z2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 48, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding = 'same', bias=False),\n",
    "#             nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(60, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(72, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.mu_z2 = nn.Sequential(nn.Linear(2592, z2_dim))\n",
    "        self.si_z2 = nn.Sequential(nn.Linear(2592, z2_dim), nn.Softplus())\n",
    "        \n",
    "        \n",
    "        # q(z1 | x, z2)\n",
    "        self.encoder_z1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 48, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 60, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding = 'same', bias=False),\n",
    "#             nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(60, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(72, 72, kernel_size=3, stride=1, padding = 'same'),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.fc_z2 = nn.Sequential(nn.Linear(z2_dim+200, h_dim), nn.ReLU())\n",
    "        self.fc_z1 = nn.Sequential(nn.Linear(2592, h_dim), nn.ReLU())\n",
    "        \n",
    "        self.fc_z1_z2 = nn.Sequential(nn.Linear(2*h_dim, h2_dim), nn.ReLU())\n",
    "        \n",
    "        self.mu_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim))\n",
    "        self.si_z1 = nn.Sequential(nn.Linear(h2_dim, z1_dim), nn.Softplus())\n",
    "\n",
    "#         torch.nn.init.xavier_uniform_(self.encoder[0].weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.encoder[3].weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc11[0].weight)\n",
    "#         self.fc11[0].bias.data.zero_()\n",
    "#         torch.nn.init.xavier_uniform_(self.fc12[0].weight)\n",
    "#         self.fc12[0].bias.data.zero_()\n",
    "    \n",
    "    def q_z2(self, x):\n",
    "        z2 = self.encoder_z2(x)\n",
    "        z2 = z2.view(-1, 2592)\n",
    "        z2_m = self.mu_z2(z2) \n",
    "        z2_s = self.si_z2(z2)\n",
    "        \n",
    "        return z2_m, z2_s\n",
    "    \n",
    "    def forward(self, x, m):\n",
    "        \n",
    "        # q(z2 | x) & m\n",
    "        z2_m, z2_s = self.q_z2(x)\n",
    "        # reparameterization trick\n",
    "        qz2 = dist.Normal(z2_m, z2_s)\n",
    "        z2 = qz2.rsample()\n",
    "        # z2 & m\n",
    "        mz2 = torch.cat([z2, m],1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # q(z1 | x, z2, m)\n",
    "        z1 = self.encoder_z1(x)\n",
    "        z1 = z1.view(-1, 2592)\n",
    "        z1 = self.fc_z1(z1)\n",
    "        \n",
    "        mz2_ = self.fc_z2(mz2)\n",
    "        \n",
    "        z1 = torch.cat([mz2_, z1],1)\n",
    "        z1 = self.fc_z1_z2(z1)\n",
    "        z1_m = self.mu_z1(z1)\n",
    "        z1_s = self.si_z1(z1)\n",
    "        \n",
    "        qz1 = dist.Normal(z1_m, z1_s)\n",
    "        z1 = qz1.rsample()\n",
    "        \n",
    "        \n",
    "        #z_loc = self.fc11(h)\n",
    "        #z_scale = self.fc12(h) + 1e-7\n",
    "\n",
    "        return z1, z2, mz2, z1_m, z1_s, z2_m, z2_s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 3],\n",
       "        [4, 5, 6, 4, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[1,3],[4,6]])\n",
    "\n",
    "torch.cat([a,b],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "qz                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 72, 3, 12]            --\n",
       "│    └─Conv2d: 2-1                       [1, 48, 25, 100]          1,344\n",
       "│    └─ReLU: 2-2                         [1, 48, 25, 100]          --\n",
       "│    └─Conv2d: 2-3                       [1, 48, 25, 100]          20,784\n",
       "│    └─ReLU: 2-4                         [1, 48, 25, 100]          --\n",
       "│    └─MaxPool2d: 2-5                    [1, 48, 12, 50]           --\n",
       "│    └─Conv2d: 2-6                       [1, 60, 12, 50]           25,980\n",
       "│    └─ReLU: 2-7                         [1, 60, 12, 50]           --\n",
       "│    └─Conv2d: 2-8                       [1, 60, 12, 50]           32,460\n",
       "│    └─ReLU: 2-9                         [1, 60, 12, 50]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 60, 6, 25]            --\n",
       "│    └─Conv2d: 2-11                      [1, 72, 6, 25]            38,952\n",
       "│    └─ReLU: 2-12                        [1, 72, 6, 25]            --\n",
       "│    └─Conv2d: 2-13                      [1, 72, 6, 25]            46,728\n",
       "│    └─ReLU: 2-14                        [1, 72, 6, 25]            --\n",
       "│    └─MaxPool2d: 2-15                   [1, 72, 3, 12]            --\n",
       "├─Sequential: 1-2                        [1, 256]                  --\n",
       "│    └─Linear: 2-16                      [1, 256]                  663,808\n",
       "├─Sequential: 1-3                        [1, 256]                  --\n",
       "│    └─Linear: 2-17                      [1, 256]                  663,808\n",
       "│    └─Softplus: 2-18                    [1, 256]                  --\n",
       "├─Sequential: 1-4                        [1, 72, 3, 12]            --\n",
       "│    └─Conv2d: 2-19                      [1, 48, 25, 100]          1,344\n",
       "│    └─ReLU: 2-20                        [1, 48, 25, 100]          --\n",
       "│    └─Conv2d: 2-21                      [1, 48, 25, 100]          20,784\n",
       "│    └─ReLU: 2-22                        [1, 48, 25, 100]          --\n",
       "│    └─MaxPool2d: 2-23                   [1, 48, 12, 50]           --\n",
       "│    └─Conv2d: 2-24                      [1, 60, 12, 50]           25,980\n",
       "│    └─ReLU: 2-25                        [1, 60, 12, 50]           --\n",
       "│    └─Conv2d: 2-26                      [1, 60, 12, 50]           32,460\n",
       "│    └─ReLU: 2-27                        [1, 60, 12, 50]           --\n",
       "│    └─MaxPool2d: 2-28                   [1, 60, 6, 25]            --\n",
       "│    └─Conv2d: 2-29                      [1, 72, 6, 25]            38,952\n",
       "│    └─ReLU: 2-30                        [1, 72, 6, 25]            --\n",
       "│    └─Conv2d: 2-31                      [1, 72, 6, 25]            46,728\n",
       "│    └─ReLU: 2-32                        [1, 72, 6, 25]            --\n",
       "│    └─MaxPool2d: 2-33                   [1, 72, 3, 12]            --\n",
       "├─Sequential: 1-5                        [1, 256]                  --\n",
       "│    └─Linear: 2-34                      [1, 256]                  663,808\n",
       "│    └─ReLU: 2-35                        [1, 256]                  --\n",
       "├─Sequential: 1-6                        [1, 256]                  --\n",
       "│    └─Linear: 2-36                      [1, 256]                  116,992\n",
       "│    └─ReLU: 2-37                        [1, 256]                  --\n",
       "├─Sequential: 1-7                        [1, 256]                  --\n",
       "│    └─Linear: 2-38                      [1, 256]                  131,328\n",
       "│    └─ReLU: 2-39                        [1, 256]                  --\n",
       "├─Sequential: 1-8                        [1, 256]                  --\n",
       "│    └─Linear: 2-40                      [1, 256]                  65,792\n",
       "├─Sequential: 1-9                        [1, 256]                  --\n",
       "│    └─Linear: 2-41                      [1, 256]                  65,792\n",
       "│    └─Softplus: 2-42                    [1, 256]                  --\n",
       "==========================================================================================\n",
       "Total params: 2,703,824\n",
       "Trainable params: 2,703,824\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 208.84\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 5.35\n",
       "Params size (MB): 10.82\n",
       "Estimated Total Size (MB): 16.20\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = qz(128,10,10,256,256,256,256)\n",
    "enc(torch.zeros((1,3,25,100)), torch.zeros((1,200)))\n",
    "summary(enc, [(1,3,25,100),(1,200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Normal_diag(x, mean, std, average=False, dim=None):\n",
    "    log_var = 2*torch.log(std)\n",
    "    log_normal = -0.5 * ( log_var + torch.pow( x - mean, 2 ) / torch.exp( log_var ) )\n",
    "    if average:\n",
    "        return torch.mean( log_normal, dim )\n",
    "    else:\n",
    "        return torch.sum( log_normal, dim )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn_gJdNSkH_V"
   },
   "source": [
    "## Full model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "BgR5BnQN1WWG"
   },
   "outputs": [],
   "source": [
    "class HVAE(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(HVAE, self).__init__()\n",
    "        self.z1_dim = args.z1_dim\n",
    "        self.z2_dim = args.z2_dim\n",
    "        self.d_dim = args.d_dim\n",
    "        self.x_dim = args.x_dim\n",
    "        self.y_dim = args.y_dim\n",
    "        self.h_dim = args.h_dim\n",
    "        self.h2_dim = args.h2_dim\n",
    "        self.number_components = args.number_components\n",
    "        \n",
    "        #d_dim, x_dim, y_dim, z1_dim ,z2_dim, h_dim, h2_dim\n",
    "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z1_dim, self.z2_dim, \n",
    "                     self.h_dim, self.h2_dim)\n",
    "        \n",
    "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z1_dim, self.z2_dim, \n",
    "                     self.h_dim, self.h2_dim)\n",
    "        \n",
    "\n",
    "        self.beta = args.beta\n",
    "        \n",
    "        self.rec_alpha = args.rec_alpha\n",
    "        self.rec_beta = args.rec_beta\n",
    "        self.rec_gamma = args.rec_gamma\n",
    "\n",
    "        self.warmup = args.warmup\n",
    "        self.prewarmup = args.prewarmup\n",
    "        \n",
    "        self.add_pseudoinputs()\n",
    "        \n",
    "        self.lqz1 = []\n",
    "        self.lqz2 = []\n",
    "        self.lpz1 = []\n",
    "        self.lpz2 = []\n",
    "        \n",
    "        self.bar = []\n",
    "        self.len = []\n",
    "        self.col = []\n",
    "        \n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, d, x, y, m):\n",
    "        # Encode\n",
    "        z1, z2, mz2, z1_m, z1_s, z2_m, z2_s = self.qz(x, m)\n",
    "        # Decode\n",
    "        x_len, x_len_scale, x_bar, x_bar_scale, x_col, pz1_m, pz1_s = self.px(z1, mz2)\n",
    "        \n",
    "        return x_len, x_len_scale, x_bar, x_bar_scale, x_col, z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s\n",
    "    \n",
    "    \n",
    "    def log_p_z2(self, z2):\n",
    "        C = self.number_components\n",
    "        \n",
    "        X = self.means(self.idle_input).view(-1,3,25,100)\n",
    "        \n",
    "        pz2_m, pz2_s = self.qz.q_z2(X)\n",
    "        \n",
    "        z_expand = z2.unsqueeze(1)\n",
    "        means = pz2_m.unsqueeze(0)\n",
    "        stds = pz2_s.unsqueeze(0)\n",
    "        \n",
    "        a = log_Normal_diag(z_expand, means, stds, dim=2) - math.log(C)\n",
    "        a_max, _ = torch.max(a,1)\n",
    "        \n",
    "        log_prior = (a_max + torch.log(torch.sum(torch.exp(a-a_max.unsqueeze(1)),1)))\n",
    "        \n",
    "        return log_prior\n",
    "    \n",
    "    def loss_function(self, d, x, y, m, out_len, out_bar, out_col):\n",
    "        \n",
    "        x_len, x_len_scale, x_bar, x_bar_scale, x_col, z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s = self.forward(d, x, y, m)\n",
    "        \n",
    "        #print(out_len.shape)\n",
    "        \n",
    "        # Reconstruction Loss\n",
    "        mask = (1 - (F.one_hot(torch.round(out_len).to(torch.int64), 101).cumsum(dim=1)))[:,None,:-1].repeat(1,25,1)\n",
    "        mask1 = (1 - (F.one_hot(torch.round(out_len).to(torch.int64), 101).cumsum(dim=1)))[:,None,:-1].repeat(1,2,1)\n",
    "\n",
    "        x_col = mask*x_col\n",
    "        \n",
    "    \n",
    "        dist_len = dist.Normal(x_len, x_len_scale+1e-7)\n",
    "        log_len = dist_len.log_prob(out_len[:,None]).mean()\n",
    "        \n",
    "        \n",
    "        mse_bar = F.mse_loss(x_bar*mask1, out_bar)\n",
    "        #((((x_bar - out_bar)**2)*mask1).sum(dim=(1,2))/(mask1.sum(dim=(1,2)))).sum()#.detach().item()\n",
    "        \n",
    "        max_bar = torch.argmax(x_col, dim=1)\n",
    "        sort_bar = torch.argsort(out_col, dim=1)\n",
    "        acc_bar = 0#(((max_bar==sort_bar[:,0,:,:])*mask1).sum((1,2))/mask1.sum((1,2))).sum()\n",
    "        acc_bar2 = 1#(((max_bar==sort_bar[:,1,:,:])*mask1).sum((1,2))/mask1.sum((1,2))).sum() + acc_bar\n",
    "        acc_bar3 = 1#(((max_bar==sort_bar[:,2,:,:])*mask1).sum((1,2))/mask1.sum((1,2))).sum() + acc_bar2\n",
    "        acc_bar4 = 1#(((max_bar==sort_bar[:,3,:,:])*mask1).sum((1,2))/mask1.sum((1,2))).sum() + acc_bar3\n",
    "        acc_bar5 = 1#(((max_bar==sort_bar[:,4,:,:])*mask1).sum((1,2))/mask1.sum((1,2))).sum() + acc_bar4\n",
    "       \n",
    "        RE_len = -log_len\n",
    "        RE_bar = mse_bar#-log_bar\n",
    "        RE_col = F.cross_entropy(x_col, out_col, reduction='sum')\n",
    "          \n",
    "            \n",
    "        # KL loss\n",
    "        KL_p_z1 = log_Normal_diag(z1, pz1_m, pz1_s, dim=1).sum()\n",
    "        KL_q_z1 = log_Normal_diag(z1, z1_m, z1_s, dim=1).sum()\n",
    "        KL_p_z2 = self.log_p_z2(z2).sum()\n",
    "        KL_q_z2 = log_Normal_diag(z2, z2_m, z2_s, dim=1).sum()\n",
    "        KL = -(KL_p_z1 + KL_p_z2 - KL_q_z1 - KL_q_z2)\n",
    "        \n",
    "        \n",
    "        return self.rec_alpha * RE_len \\\n",
    "                  + self.rec_beta * RE_bar \\\n",
    "                  + self.rec_gamma * RE_col/x_col.shape[0] \\\n",
    "                  + self.beta * KL, \\\n",
    "                  RE_bar, RE_len, RE_col, mse_bar, acc_bar, acc_bar2, acc_bar3, acc_bar4, acc_bar5\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_pseudoinputs(self):\n",
    "        # TODO: rework pseudo generation based on reconstruction\n",
    "        nonlinearity = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
    "        self.means = nn.Sequential(nn.Linear(self.number_components, 3*25*100, bias=False), nonlinearity)\n",
    "        self.idle_input = Variable(torch.eye(self.number_components, self.number_components), requires_grad=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-50.9189)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dist.Normal(0,1)\n",
    "a.log_prob(torch.tensor(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "HVAE                                     --                        --\n",
       "├─px: 1-1                                --                        (recursive)\n",
       "│    └─Sequential: 2-1                   --                        (recursive)\n",
       "│    │    └─Linear: 3-1                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-2                    --                        --\n",
       "│    │    └─Linear: 3-3                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-4                    --                        --\n",
       "│    └─Sequential: 2-2                   --                        (recursive)\n",
       "│    │    └─Linear: 3-5                  --                        (recursive)\n",
       "│    └─Sequential: 2-3                   --                        (recursive)\n",
       "│    │    └─Linear: 3-6                  --                        (recursive)\n",
       "│    │    └─Softplus: 3-7                --                        --\n",
       "│    └─Sequential: 2-4                   --                        (recursive)\n",
       "│    │    └─Linear: 3-8                  --                        (recursive)\n",
       "│    │    └─ReLU: 3-9                    --                        --\n",
       "│    └─Sequential: 2-5                   --                        (recursive)\n",
       "│    │    └─Linear: 3-10                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-11                   --                        --\n",
       "│    └─Sequential: 2-6                   --                        (recursive)\n",
       "│    │    └─Linear: 3-12                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-13                   --                        --\n",
       "│    └─Sequential: 2-7                   --                        (recursive)\n",
       "│    │    └─Linear: 3-14                 --                        (recursive)\n",
       "│    └─Sequential: 2-8                   --                        (recursive)\n",
       "│    │    └─Linear: 3-15                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-16                   --                        --\n",
       "│    │    └─Linear: 3-17                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-18                   --                        --\n",
       "│    │    └─Dropout: 3-19                --                        --\n",
       "│    └─Sequential: 2-9                   --                        (recursive)\n",
       "│    │    └─Linear: 3-20                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-21                   --                        --\n",
       "│    │    └─Linear: 3-22                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-23                   --                        --\n",
       "│    │    └─Dropout: 3-24                --                        --\n",
       "│    └─Sequential: 2-10                  --                        (recursive)\n",
       "│    │    └─Linear: 3-25                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-26               --                        --\n",
       "│    └─Sequential: 2-11                  --                        (recursive)\n",
       "│    │    └─Linear: 3-27                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-28               --                        --\n",
       "│    └─Sequential: 2-12                  --                        (recursive)\n",
       "│    │    └─Linear: 3-29                 --                        (recursive)\n",
       "│    │    └─ReLU: 3-30                   --                        --\n",
       "│    │    └─Linear: 3-31                 --                        (recursive)\n",
       "│    │    └─Softplus: 3-32               --                        --\n",
       "├─qz: 1-2                                [1, 256]                  --\n",
       "│    └─Sequential: 2-13                  [1, 72, 3, 12]            --\n",
       "│    │    └─Conv2d: 3-33                 [1, 48, 25, 100]          1,344\n",
       "│    │    └─ReLU: 3-34                   [1, 48, 25, 100]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 48, 25, 100]          20,784\n",
       "│    │    └─ReLU: 3-36                   [1, 48, 25, 100]          --\n",
       "│    │    └─MaxPool2d: 3-37              [1, 48, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-38                 [1, 60, 12, 50]           25,980\n",
       "│    │    └─ReLU: 3-39                   [1, 60, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-40                 [1, 60, 12, 50]           32,460\n",
       "│    │    └─ReLU: 3-41                   [1, 60, 12, 50]           --\n",
       "│    │    └─MaxPool2d: 3-42              [1, 60, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-43                 [1, 72, 6, 25]            38,952\n",
       "│    │    └─ReLU: 3-44                   [1, 72, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-45                 [1, 72, 6, 25]            46,728\n",
       "│    │    └─ReLU: 3-46                   [1, 72, 6, 25]            --\n",
       "│    │    └─MaxPool2d: 3-47              [1, 72, 3, 12]            --\n",
       "│    └─Sequential: 2-14                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-48                 [1, 256]                  663,808\n",
       "│    └─Sequential: 2-15                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-49                 [1, 256]                  663,808\n",
       "│    │    └─Softplus: 3-50               [1, 256]                  --\n",
       "│    └─Sequential: 2-16                  [1, 72, 3, 12]            --\n",
       "│    │    └─Conv2d: 3-51                 [1, 48, 25, 100]          1,344\n",
       "│    │    └─ReLU: 3-52                   [1, 48, 25, 100]          --\n",
       "│    │    └─Conv2d: 3-53                 [1, 48, 25, 100]          20,784\n",
       "│    │    └─ReLU: 3-54                   [1, 48, 25, 100]          --\n",
       "│    │    └─MaxPool2d: 3-55              [1, 48, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-56                 [1, 60, 12, 50]           25,980\n",
       "│    │    └─ReLU: 3-57                   [1, 60, 12, 50]           --\n",
       "│    │    └─Conv2d: 3-58                 [1, 60, 12, 50]           32,460\n",
       "│    │    └─ReLU: 3-59                   [1, 60, 12, 50]           --\n",
       "│    │    └─MaxPool2d: 3-60              [1, 60, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-61                 [1, 72, 6, 25]            38,952\n",
       "│    │    └─ReLU: 3-62                   [1, 72, 6, 25]            --\n",
       "│    │    └─Conv2d: 3-63                 [1, 72, 6, 25]            46,728\n",
       "│    │    └─ReLU: 3-64                   [1, 72, 6, 25]            --\n",
       "│    │    └─MaxPool2d: 3-65              [1, 72, 3, 12]            --\n",
       "│    └─Sequential: 2-17                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-66                 [1, 256]                  663,808\n",
       "│    │    └─ReLU: 3-67                   [1, 256]                  --\n",
       "│    └─Sequential: 2-18                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-68                 [1, 256]                  116,992\n",
       "│    │    └─ReLU: 3-69                   [1, 256]                  --\n",
       "│    └─Sequential: 2-19                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-70                 [1, 256]                  131,328\n",
       "│    │    └─ReLU: 3-71                   [1, 256]                  --\n",
       "│    └─Sequential: 2-20                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-72                 [1, 256]                  65,792\n",
       "│    └─Sequential: 2-21                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-73                 [1, 256]                  65,792\n",
       "│    │    └─Softplus: 3-74               [1, 256]                  --\n",
       "├─px: 1-3                                [1, 1]                    --\n",
       "│    └─Sequential: 2-22                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-75                 [1, 256]                  116,992\n",
       "│    │    └─ReLU: 3-76                   [1, 256]                  --\n",
       "│    │    └─Linear: 3-77                 [1, 256]                  65,792\n",
       "│    │    └─ReLU: 3-78                   [1, 256]                  --\n",
       "│    └─Sequential: 2-23                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-79                 [1, 256]                  65,792\n",
       "│    └─Sequential: 2-24                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-80                 [1, 256]                  65,792\n",
       "│    │    └─Softplus: 3-81               [1, 256]                  --\n",
       "│    └─Sequential: 2-25                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-82                 [1, 256]                  65,792\n",
       "│    │    └─ReLU: 3-83                   [1, 256]                  --\n",
       "│    └─Sequential: 2-26                  [1, 256]                  --\n",
       "│    │    └─Linear: 3-84                 [1, 256]                  116,992\n",
       "│    │    └─ReLU: 3-85                   [1, 256]                  --\n",
       "│    └─Sequential: 2-27                  [1, 64]                   --\n",
       "│    │    └─Linear: 3-86                 [1, 128]                  65,664\n",
       "│    │    └─ReLU: 3-87                   [1, 128]                  --\n",
       "│    │    └─Linear: 3-88                 [1, 64]                   8,256\n",
       "│    │    └─ReLU: 3-89                   [1, 64]                   --\n",
       "│    │    └─Dropout: 3-90                [1, 64]                   --\n",
       "│    └─Sequential: 2-28                  [1, 1]                    --\n",
       "│    │    └─Linear: 3-91                 [1, 400]                  26,000\n",
       "│    │    └─ReLU: 3-92                   [1, 400]                  --\n",
       "│    │    └─Linear: 3-93                 [1, 1]                    401\n",
       "│    │    └─Softplus: 3-94               [1, 1]                    --\n",
       "│    └─Sequential: 2-29                  [1, 64]                   --\n",
       "│    │    └─Linear: 3-95                 [1, 128]                  65,664\n",
       "│    │    └─ReLU: 3-96                   [1, 128]                  --\n",
       "│    │    └─Linear: 3-97                 [1, 64]                   8,256\n",
       "│    │    └─ReLU: 3-98                   [1, 64]                   --\n",
       "│    │    └─Dropout: 3-99                [1, 64]                   --\n",
       "│    └─Sequential: 2-30                  [1, 100]                  --\n",
       "│    │    └─Linear: 3-100                [1, 100]                  6,500\n",
       "│    │    └─Softplus: 3-101              [1, 100]                  --\n",
       "│    └─Sequential: 2-31                  [1, 100]                  --\n",
       "│    │    └─Linear: 3-102                [1, 100]                  6,500\n",
       "│    │    └─Softplus: 3-103              [1, 100]                  --\n",
       "│    └─Sequential: 2-32                  [1, 600]                  --\n",
       "│    │    └─Linear: 3-104                [1, 600]                  307,800\n",
       "│    │    └─ReLU: 3-105                  [1, 600]                  --\n",
       "│    └─Sequential: 2-33                  [1, 2500]                 --\n",
       "│    │    └─Linear: 3-106                [1, 2500]                 1,502,500\n",
       "==========================================================================================\n",
       "Total params: 5,198,517\n",
       "Trainable params: 5,198,517\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 211.34\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 5.40\n",
       "Params size (MB): 20.79\n",
       "Estimated Total Size (MB): 26.22\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_args = diva_args()\n",
    "enc = HVAE(default_args)\n",
    "summary(enc,[ (1,1),(1,3,25,100),(1,1),(1,200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOsLfYJjBBe"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH1E5J-ps3GD"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16152,
     "status": "ok",
     "timestamp": 1647023309618,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "myflmDPxjV40",
    "outputId": "0befed1a-e175-47eb-e1c0-f9f28da53d7c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset = MicroRNADataset(create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ut2P5RSaMoDR",
    "outputId": "eafab284-1376-4f62-c8c9-bb8e87351bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset_test = MicroRNADataset('test', create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215d520b348>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(RNA_dataset.x_col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215d524a808>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(RNA_dataset.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = torch.tensor(RNA_dataset.x_len[0]).reshape(1,1)\n",
    "ln_var = torch.tensor([1])\n",
    "br = torch.tensor(RNA_dataset.x_bar[0][np.newaxis])\n",
    "col = torch.tensor(RNA_dataset.x_col[0][np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diva' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-27d281780cf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruct_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mln\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mln_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mln_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'diva' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(diva.px.reconstruct_image(ln, ln_var, br , ln_var, col)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215d52b3b08>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB1CAYAAABXo7o4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAIq0lEQVR4nO3dW4xdVR3H8e/PQqlAEIqkKW21NVZMYxRMAxiMIVwiXmJ9MAhRQwymLxjBYKDy5oMJRuPlwZg0gPaBgKSQQAyRQIWoiWkAIeFSsQ2KFFtabkI0EdG/D2eTGSbM9HQu58zq/n5e5uy1z8xes2bNL+usvfbeqSokSe15x7grIEmaHQNckhplgEtSowxwSWqUAS5JjTLAJalRcwrwJBcleSrJniRb5qtSkqRDy2zXgSdZAvwZuBDYCzwIXFpVT85f9SRJ0zlqDt97JrCnqp4GSHIrsAmYNsCX5phaxnFzOKQk9c9rvPxCVZ0ytXwuAb4KeHbS9l7grJm+YRnHcVbOn8MhJal/7qvtz7xd+VwCfChJNgObAZZx7EIfTpJ6Yy4B/hywZtL26q7sLapqK7AV4IQsH/uNV+75+6Nv2f7kqaePpR6SNFdzWYXyILA+ybokS4FLgLvmp1qSpEOZ9Qi8qt5I8nXgHmAJcFNVPTFvNZMkzWhOc+BVdTdw9zzVRZJ0GBb8JOZi45y3pCOFl9JLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjmrsSc/LdBGe6qnLY97WsD7+jpOk5ApekRhngktSoWT/UeDZOyPLykWqSdHjuq+0PV9XGqeWOwCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYdMsCT3JTkQJLHJ5UtT3Jvkt3d15MWtpqSpKmGGYH/ArhoStkWYEdVrQd2dNuSpBE65AMdquq3SdZOKd4EnNu93gY8AFw7nxXrs9k8qGGhH+7gwyOkxWe2T+RZUVX7utf7gRXTvTHJZmAzwDKOneXhJElTzfkkZg1uKD7tTcWramtVbayqjUdzzFwPJ0nqzHYE/nySlVW1L8lK4MB8VqrvZjNFsdDTGk6bSIvPbEfgdwGXda8vA+6cn+pIkoY1zDLCW4A/AKcl2ZvkcuB64MIku4ELum1J0ggNswrl0ml2+XBLSRojr8SUpEYZ4JLUKANckho122WERwyvMJTUKkfgktQoA1ySGtX7KRSnTSS1yhG4JDXKAJekRo1tCmXy6g/o91TGTG3hKhlJ03EELkmNMsAlqVEGuCQ1KoMH6ozGCVleZ8WbGErS4bivtj9cVRunljsCl6RGGeCS1KjeX4k5mUsb55dLIKWF5QhckhplgEtSo5xCmWTqx3ynAObGNpMWliNwSWqUAS5JjTLAJalRzoHPwDlcSYvZIUfgSdYkuT/Jk0meSHJlV748yb1JdndfT1r46kqS3jTMFMobwNVVtQE4G7giyQZgC7CjqtYDO7ptSdKIHHIKpar2Afu6168l2QWsAjYB53Zv2wY8AFw708/6wIf/xT33PArMvGRvJtNNayz0VZTD1m82hq3rsL/jQtR1uodMzPQ+SQvrsE5iJlkLnAHsBFZ04Q6wH1gxv1WTJM1k6ABPcjxwO3BVVb06eV8N7kn7tvelTbI5yUNJHjr44n/nVFlJ0oShAjzJ0QzC++aquqMrfj7Jym7/SuDA231vVW2tqo1VtfGUk5fMR50lSQzxQIckYTDH/VJVXTWp/PvAi1V1fZItwPKqumamn+UDHSTp8E33QIdh1oGfA3wFeCzJo13ZdcD1wG1JLgeeAS6ep7pKkoYwzCqU3wOZZrfDaUkak6avxPRugYuPfxNpdLwXiiQ1ygCXpEY1PYXiR/TFx7+JNDqOwCWpUQa4JDXKAJekRjU9Bz4sl7ZJOhI5ApekRhngktSoQ97Mal4PlhwE/gm8MLKDLm7vxrZ4k20xwbaYYFsMvLeqTplaONIAB0jy0NvdVauPbIsJtsUE22KCbTEzp1AkqVEGuCQ1ahwBvnUMx1ysbIsJtsUE22KCbTGDkc+BS5Lmh1MoktSokQZ4kouSPJVkT/cczd5IsibJ/UmeTPJEkiu78uVJ7k2yu/t60rjrOipJliR5JMmvuu11SXZ2/eOXSZaOu46jkOTEJNuT/CnJriQf62u/SPLN7v/j8SS3JFnW134xjJEFeJIlwE+BTwEbgEuTbBjV8ReBN4Crq2oDcDZwRff7bwF2VNV6YEe33RdXArsmbX8P+FFVvR94Gbh8LLUavZ8Av66qDwIfYdAmvesXSVYB3wA2VtWHgCXAJfS3XxzSKEfgZwJ7qurpqnoduBXYNMLjj1VV7auqP3avX2PwT7qKQRts6962Dfj8WCo4YklWA58Bbui2A5wHbO/e0ou2SPIu4BPAjQBV9XpVvUJP+wWD+zO9M8lRwLHAPnrYL4Y1ygBfBTw7aXtvV9Y7SdYCZwA7gRVVta/btR9YMa56jdiPgWuA/3XbJwOvVNUb3XZf+sc64CDw82466YYkx9HDflFVzwE/AP7GILj/ATxMP/vFUDyJOWJJjgduB66qqlcn76vBkqAjfllQks8CB6rq4XHXZRE4Cvgo8LOqOoPBrSbeMl3So35xEoNPHuuAU4HjgIvGWqlFbpQB/hywZtL26q6sN5IczSC8b66qO7ri55Os7PavBA6Mq34jdA7wuSR/ZTCVdh6DeeATu4/O0J/+sRfYW1U7u+3tDAK9j/3iAuAvVXWwqv4D3MGgr/SxXwxllAH+ILC+O6O8lMHJibtGePyx6uZ4bwR2VdUPJ+26C7ise30ZcOeo6zZqVfXtqlpdVWsZ9IPfVNWXgPuBL3Rv60tb7AeeTXJaV3Q+8CQ97BcMpk7OTnJs9//yZlv0rl8Ma9R3I/w0g7nPJcBNVfXdkR18zJJ8HPgd8BgT877XMZgHvw14D/AMcHFVvTSWSo5BknOBb1XVZ5O8j8GIfDnwCPDlqvr3GKs3EklOZ3AydynwNPBVBoOr3vWLJN8Bvshg1dYjwNcYzHn3rl8MwysxJalRnsSUpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNer/WDyHCF0/q/0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(RNA_dataset.x_col[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215e2988bc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(RNA_dataset.x_col[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = torch.tensor(RNA_dataset.x_col[2]).unsqueeze(0).float()[:,:,:60]\n",
    "col2 = torch.tensor(RNA_dataset.x_col[1]).unsqueeze(0).float()[:,:,:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = torch.tensor(RNA_dataset.x_len.reshape(-1,).astype('float64'))\n",
    "mask = (1 - (F.one_hot(torch.round(ln).to(torch.int64), 101).cumsum(dim=1)))[:,None,:-1].repeat(1,25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(121.2856)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.tensor(RNA_dataset.x_col).float(), torch.tensor(RNA_dataset.x_col).float()*mask, reduction='sum')/RNA_dataset.x_col.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(172.2336)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.tensor(RNA_dataset.x_col).float(), torch.tensor(1/25).repeat(RNA_dataset.x_col.shape[0], 25,100)*mask, reduction='sum')/RNA_dataset.x_col.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_dataset.x_len.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34721, 25, 100])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape\n",
    "#F.one_hot(torch.round(ln).to(torch.int64)-1, 100).cumsum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215e49b4fc8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask[0]*RNA_dataset.x_col[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1150)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34721, 2, 100), (34721, 25, 100))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_dataset.x_bar.shape, RNA_dataset.x_col.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "eVGq463Y2m20"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "    no_batches = 0\n",
    "    train_corr = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0\n",
    "    acc_bar2 = 0\n",
    "    acc_bar3 = 0\n",
    "    acc_bar4 = 0\n",
    "    acc_bar5 = 0\n",
    "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
    "                                     desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (x, y, d, x_len, x_col, x_bar, m) in pbar:\n",
    "        # To device\n",
    "        x, y, d , x_len, x_bar, x_col, m= x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE), m.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, bar_loss, len_loss, col_loss, mse, acc, acc2, acc3, acc4, acc5 = model.loss_function(d.float(), x.float(), y.float(), m.float(), x_len.float(), x_bar.float(), x_col.float())\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item()/x.shape[0])\n",
    "        train_loss += loss\n",
    "        epoch_bar_loss += bar_loss\n",
    "        epoch_col_loss += col_loss\n",
    "        epoch_len_loss += len_loss\n",
    "        mse_bar += mse\n",
    "        acc_bar += acc\n",
    "        acc_bar2 += acc2\n",
    "        acc_bar3 += acc3\n",
    "        acc_bar4 += acc4\n",
    "        acc_bar5 += acc5\n",
    "        no_batches += 1\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    epoch_bar_loss /= len(train_loader.dataset)\n",
    "    epoch_len_loss /= len(train_loader.dataset)\n",
    "    epoch_col_loss /= len(train_loader.dataset)\n",
    "    acc_bar /= len(train_loader.dataset)\n",
    "    acc_bar2 /= len(train_loader.dataset)\n",
    "    acc_bar3 /= len(train_loader.dataset)\n",
    "    acc_bar4 /= len(train_loader.dataset)\n",
    "    acc_bar5 /= len(train_loader.dataset)\n",
    "    mse_bar /= len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss, mse_bar, acc_bar, acc_bar2, acc_bar3, acc_bar4, acc_bar5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dT7E0C3nM3qh"
   },
   "outputs": [],
   "source": [
    "def test_single_epoch(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    epoch_len_loss = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0   \n",
    "    acc_bar2 = 0\n",
    "    acc_bar3 = 0\n",
    "    acc_bar4 = 0\n",
    "    acc_bar5 = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x,y,d,x_len,x_col,x_bar, m) in enumerate(test_loader):\n",
    "            x, y, d, x_len, x_bar, x_col, m = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE), m.to(DEVICE)\n",
    "            loss, bar_loss, len_loss, col_loss, mse, acc, acc2, acc3, acc4, acc5  = model.loss_function(d.float(), x.float(), y.float(),m.float(),x_len.float(),x_bar.float(),x_col.float())\n",
    "            test_loss += loss\n",
    "            epoch_bar_loss += bar_loss\n",
    "            epoch_col_loss += col_loss\n",
    "            epoch_len_loss += len_loss\n",
    "            mse_bar += mse\n",
    "            acc_bar += acc\n",
    "            acc_bar2 += acc2\n",
    "            acc_bar3 += acc3\n",
    "            acc_bar4 += acc4\n",
    "            acc_bar5 += acc5\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    epoch_bar_loss /= len(test_loader.dataset)\n",
    "    epoch_len_loss /= len(test_loader.dataset)\n",
    "    epoch_col_loss /= len(test_loader.dataset)\n",
    "    acc_bar /= len(test_loader.dataset)\n",
    "    acc_bar2 /= len(test_loader.dataset)\n",
    "    acc_bar3 /= len(test_loader.dataset)\n",
    "    acc_bar4 /= len(test_loader.dataset)\n",
    "    acc_bar5 /= len(test_loader.dataset)\n",
    "    mse_bar /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, epoch_bar_loss, epoch_len_loss, epoch_col_loss, mse_bar, acc_bar, acc_bar2, acc_bar3, acc_bar4, acc_bar5 \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "npLjVGs0jHYn"
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch=0, save_folder='sd_1.0.0',save_interval=5):\n",
    "    \n",
    "    epoch_loss_sup = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(start_epoch+1, end_epoch+1):\n",
    "        diva.beta = min([args.beta, args.beta * (epoch - args.prewarmup * 1.) / (args.warmup)])\n",
    "        if epoch< args.prewarmup:\n",
    "            diva.beta = args.beta/args.prewarmup\n",
    "        train_loss, avg_loss_bar, avg_loss_len, avg_loss_col, mtr, atr, atr2, atr3, atr4, atr5  = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
    "        str_loss_sup = train_loss\n",
    "        epoch_loss_sup.append(train_loss)\n",
    "        str_print = \"epoch {}: avg train loss {:.2f}\".format(epoch, str_loss_sup)\n",
    "        str_print += \", bar train loss {:.3f}\".format(avg_loss_bar)\n",
    "        str_print += \", len train loss {:.3f}\".format(avg_loss_len)\n",
    "        str_print += \", col train loss {:.3f}\".format(avg_loss_col)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_train = diva.rec_alpha * avg_loss_len + diva.rec_beta * avg_loss_bar + diva.rec_gamma * avg_loss_col\n",
    "        dis_loss_train = train_loss - rec_loss_train\n",
    "\n",
    "        test_lss, avg_loss_bar_test, avg_loss_len_test, avg_loss_col_test, mte, ate, ate2, ate3, ate4, ate5  = test_single_epoch(test_loader, diva, epoch)\n",
    "        test_loss.append(test_lss)\n",
    "       \n",
    "        str_print = \"epoch {}: avg test  loss {:.2f}\".format(epoch, test_lss)\n",
    "        str_print += \", bar  test loss {:.3f}\".format(avg_loss_bar_test)\n",
    "        str_print += \", len  test loss {:.3f}\".format(avg_loss_len_test)\n",
    "        str_print += \", col  test loss {:.3f}\".format(avg_loss_col_test)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_test = diva.rec_alpha * avg_loss_len_test + diva.rec_beta * avg_loss_bar_test + diva.rec_gamma * avg_loss_col_test\n",
    "        dis_loss_test = test_lss - rec_loss_test\n",
    "\n",
    "        if writer is not None:\n",
    "            \n",
    "            writer.add_scalars(\"Total_Loss\", {'train': train_loss, 'test': test_lss} ,epoch)\n",
    "            writer.add_scalars(\"Reconstruction_vs_Disentanglement\",{'rec':rec_loss_train, 'dis':dis_loss_train}, epoch)\n",
    "            writer.add_scalars(\"bar_mse\",{'train': mtr, 'test':mte}, epoch)\n",
    "            writer.add_scalars(\"coll loss\", {'train':avg_loss_col, 'test':avg_loss_col_test}, epoch)\n",
    "#             writer.add_scalars(\"bar_acc\",{'train-top1': atr, 'test-top1':ate,\n",
    "#                                           'train-top2': atr2, 'test-top2':ate2,\n",
    "#                                           'train-top3': atr3, 'test-top3':ate3,\n",
    "#                                           'train-top4': atr4, 'test-top4':ate4,\n",
    "#                                           'train-top5': atr4, 'test-top5':ate4\n",
    "#                                          }, epoch)\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            save_reconstructions(epoch, test_loader, diva, name=save_folder)\n",
    "            save_reconstructions(epoch, train_loader, diva, name=save_folder, estr='tr')\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(diva.state_dict(), f'{link}/saved_models/{save_folder}/checkpoints/{epoch}.pth')\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.flush()\n",
    "\n",
    "    epoch_loss_sup = [i.detach().cpu().numpy() for i in epoch_loss_sup]\n",
    "    test_loss = [i.detach().cpu().numpy() for i in test_loss]\n",
    "    return epoch_loss_sup, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "XxN8U8YK0Qi1"
   },
   "outputs": [],
   "source": [
    "def save_reconstructions(epoch, test_loader, diva, name='diva', estr=''):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:10].to(DEVICE).float()\n",
    "        x = a[1][0][:10].to(DEVICE).float()\n",
    "        y = a[1][1][:10].to(DEVICE).float()\n",
    "        m = a[1][-1][:10].to(DEVICE).float()\n",
    "        x_1, x_1var, x_2, x_2var, x_3 ,z1, z2, z1_m, z1_s, z2_m, z2_s, pz1_m, pz1_s = diva(d,x,y,m)\n",
    "        out = diva.px.reconstruct_image(x_1, x_1var, x_2, x_2var, x_3)\n",
    "\n",
    "    plt.figure(figsize=(80,20))\n",
    "    fig, ax = plt.subplots(nrows=10, ncols=2)\n",
    "\n",
    "    ax[0,0].set_title(\"Original\")\n",
    "    ax[0,1].set_title(\"Reconstructed\")\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i, 1].imshow(out[i])\n",
    "        ax[i, 0].imshow(x[i].cpu().permute(1,2,0))\n",
    "        ax[i, 0].xaxis.set_visible(False)\n",
    "        ax[i, 0].yaxis.set_visible(False)\n",
    "        ax[i, 1].xaxis.set_visible(False)\n",
    "        ax[i, 1].yaxis.set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig(f'{link}/saved_models/{name}/reconstructions/e{epoch}{estr}.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "YVAD-Mjwh7yq",
    "outputId": "f330c11c-e358-41af-9ef4-bc36c146f907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI4-NzHxjmci"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023317083,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "sJE0HTJE1ayP"
   },
   "outputs": [],
   "source": [
    "default_args = diva_args(prewarmup=0, number_components=50, z1_dim=256, z2_dim=256, rec_gamma=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "kxIMSeUD1949",
    "outputId": "45991358-df3b-4e61-9d8a-c48b71b9fa49"
   },
   "outputs": [],
   "source": [
    "diva = HVAE(default_args).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318259,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "PUHyoMi7iwJC"
   },
   "outputs": [],
   "source": [
    "#diva.load_state_dict(torch.load(f'{link}/saved_models/new/DOUBLEHVAE/checkpoints/250.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318260,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "48B39rFl79Yh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(RNA_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(RNA_dataset_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "J6y2Ek2677z1"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(diva.parameters(), lr=0.00001, momentum=0.1, nesterov=True)\n",
    "optimizer = optim.Adam(diva.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_dataset.x_len.min(), RNA_dataset.x_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diva.rec_gamma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "vQGakzXN6V-Y",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14644), started 1 day, 7:54:47 ago. (Use '!kill 14644' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-50ffea19a8dc9d17\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-50ffea19a8dc9d17\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard  --logdir=\"D:/users/Marko/downloads/mirna/saved_models/new/DOUBLEHVAE/tensorboard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "0m47XoL87oLs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 272batch [00:35,  7.63batch/s, loss=5.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg train loss 130850.41, bar train loss 0.065, len train loss 1.057, col train loss 166.882\n",
      "epoch 1: avg test  loss 129940.96, bar  test loss 0.049, len  test loss 0.784, col  test loss 165.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 272batch [00:32,  8.30batch/s, loss=5.14e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg train loss 128845.40, bar train loss 0.047, len train loss 0.279, col train loss 164.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 1batch [00:00,  8.20batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg test  loss 128731.72, bar  test loss 0.041, len  test loss 2.071, col  test loss 163.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 272batch [00:32,  8.29batch/s, loss=4.9e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg train loss 127576.30, bar train loss 0.042, len train loss 0.219, col train loss 162.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 1batch [00:00,  8.26batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg test  loss 127701.71, bar  test loss 0.037, len  test loss 1.983, col  test loss 162.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 272batch [00:32,  8.26batch/s, loss=4.83e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg train loss 126818.80, bar train loss 0.039, len train loss 0.179, col train loss 161.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 1batch [00:00,  8.20batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg test  loss 127079.40, bar  test loss 0.034, len  test loss 1.665, col  test loss 161.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 272batch [00:32,  8.27batch/s, loss=4.62e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg train loss 126256.54, bar train loss 0.038, len train loss 0.166, col train loss 161.037\n",
      "epoch 5: avg test  loss 126784.54, bar  test loss 0.034, len  test loss 1.878, col  test loss 160.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 272batch [00:32,  8.25batch/s, loss=4.79e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg train loss 125839.98, bar train loss 0.037, len train loss 0.148, col train loss 160.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 1batch [00:00,  8.20batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg test  loss 126399.14, bar  test loss 0.032, len  test loss 1.945, col  test loss 160.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 272batch [00:32,  8.27batch/s, loss=4.85e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg train loss 125565.36, bar train loss 0.036, len train loss 0.145, col train loss 160.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 1batch [00:00,  8.26batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg test  loss 126133.45, bar  test loss 0.032, len  test loss 1.817, col  test loss 160.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 272batch [00:32,  8.27batch/s, loss=4.89e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg train loss 125234.45, bar train loss 0.035, len train loss 0.133, col train loss 159.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 1batch [00:00,  8.26batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg test  loss 125899.36, bar  test loss 0.031, len  test loss 1.971, col  test loss 159.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 272batch [00:32,  8.26batch/s, loss=4.75e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg train loss 124993.74, bar train loss 0.035, len train loss 0.127, col train loss 159.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 1batch [00:00,  8.00batch/s, loss=1.31e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg test  loss 125696.84, bar  test loss 0.030, len  test loss 1.975, col  test loss 159.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 272batch [00:32,  8.25batch/s, loss=4.77e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg train loss 124772.95, bar train loss 0.034, len train loss 0.120, col train loss 159.066\n",
      "epoch 10: avg test  loss 125476.03, bar  test loss 0.029, len  test loss 1.871, col  test loss 159.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 272batch [00:32,  8.26batch/s, loss=5.04e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg train loss 124608.19, bar train loss 0.033, len train loss 0.115, col train loss 158.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 1batch [00:00,  8.20batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg test  loss 125354.72, bar  test loss 0.029, len  test loss 1.666, col  test loss 159.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 272batch [00:32,  8.25batch/s, loss=5.18e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg train loss 124442.56, bar train loss 0.033, len train loss 0.109, col train loss 158.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 1batch [00:00,  8.13batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg test  loss 125281.38, bar  test loss 0.029, len  test loss 1.855, col  test loss 158.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 272batch [00:33,  8.23batch/s, loss=4.73e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg train loss 124248.05, bar train loss 0.033, len train loss 0.112, col train loss 158.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 1batch [00:00,  8.26batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg test  loss 125190.88, bar  test loss 0.028, len  test loss 2.209, col  test loss 158.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 272batch [00:33,  8.23batch/s, loss=5.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg train loss 124130.25, bar train loss 0.032, len train loss 0.105, col train loss 158.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 1batch [00:00,  8.13batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg test  loss 125103.52, bar  test loss 0.028, len  test loss 1.997, col  test loss 158.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 272batch [00:33,  8.24batch/s, loss=5.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg train loss 123998.70, bar train loss 0.032, len train loss 0.103, col train loss 158.020\n",
      "epoch 15: avg test  loss 125023.63, bar  test loss 0.028, len  test loss 1.939, col  test loss 158.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 272batch [00:33,  8.24batch/s, loss=4.8e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg train loss 123884.92, bar train loss 0.032, len train loss 0.104, col train loss 157.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 1batch [00:00,  8.06batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg test  loss 124861.83, bar  test loss 0.028, len  test loss 1.776, col  test loss 158.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 272batch [00:33,  8.24batch/s, loss=4.54e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg train loss 123749.12, bar train loss 0.031, len train loss 0.098, col train loss 157.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 1batch [00:00,  8.00batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg test  loss 124796.30, bar  test loss 0.028, len  test loss 1.881, col  test loss 158.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 272batch [00:33,  8.24batch/s, loss=5.14e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg train loss 123695.77, bar train loss 0.031, len train loss 0.098, col train loss 157.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 1batch [00:00,  8.20batch/s, loss=1.27e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg test  loss 124715.29, bar  test loss 0.027, len  test loss 1.454, col  test loss 158.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 272batch [00:33,  8.23batch/s, loss=4.88e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg train loss 123580.94, bar train loss 0.031, len train loss 0.094, col train loss 157.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 1batch [00:00,  8.00batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg test  loss 124647.37, bar  test loss 0.027, len  test loss 1.710, col  test loss 158.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 272batch [00:33,  8.23batch/s, loss=4.49e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg train loss 123454.39, bar train loss 0.031, len train loss 0.091, col train loss 157.346\n",
      "epoch 20: avg test  loss 124574.99, bar  test loss 0.027, len  test loss 1.588, col  test loss 158.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 272batch [00:33,  8.23batch/s, loss=4.26e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg train loss 123356.74, bar train loss 0.031, len train loss 0.086, col train loss 157.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 1batch [00:00,  8.20batch/s, loss=1.27e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg test  loss 124522.31, bar  test loss 0.027, len  test loss 1.700, col  test loss 158.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 272batch [00:33,  8.22batch/s, loss=5.17e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg train loss 123330.72, bar train loss 0.031, len train loss 0.088, col train loss 157.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 1batch [00:00,  8.20batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg test  loss 124461.26, bar  test loss 0.027, len  test loss 1.453, col  test loss 157.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 272batch [00:33,  8.22batch/s, loss=4.7e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg train loss 123226.77, bar train loss 0.030, len train loss 0.085, col train loss 157.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 1batch [00:00,  8.20batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg test  loss 124462.20, bar  test loss 0.027, len  test loss 1.371, col  test loss 157.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 272batch [00:33,  8.21batch/s, loss=4.62e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg train loss 123152.85, bar train loss 0.030, len train loss 0.084, col train loss 156.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 1batch [00:00,  8.20batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg test  loss 124316.47, bar  test loss 0.027, len  test loss 1.235, col  test loss 157.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 272batch [00:33,  8.21batch/s, loss=4.87e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: avg train loss 123069.49, bar train loss 0.030, len train loss 0.081, col train loss 156.799\n",
      "epoch 25: avg test  loss 124329.72, bar  test loss 0.027, len  test loss 1.072, col  test loss 157.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 272batch [00:33,  8.21batch/s, loss=4.51e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg train loss 123002.70, bar train loss 0.030, len train loss 0.084, col train loss 156.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 1batch [00:00,  8.20batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg test  loss 124299.49, bar  test loss 0.027, len  test loss 1.418, col  test loss 157.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 272batch [00:33,  8.21batch/s, loss=4.65e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg train loss 122962.59, bar train loss 0.030, len train loss 0.080, col train loss 156.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 1batch [00:00,  7.81batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg test  loss 124199.80, bar  test loss 0.027, len  test loss 1.188, col  test loss 157.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 272batch [00:33,  8.20batch/s, loss=4.63e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg train loss 122889.74, bar train loss 0.030, len train loss 0.080, col train loss 156.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 1batch [00:00,  8.13batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg test  loss 124150.21, bar  test loss 0.026, len  test loss 1.049, col  test loss 157.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 272batch [00:33,  8.19batch/s, loss=4.49e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg train loss 122816.19, bar train loss 0.030, len train loss 0.081, col train loss 156.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 1batch [00:00,  8.13batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg test  loss 124121.96, bar  test loss 0.026, len  test loss 1.172, col  test loss 157.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 272batch [00:33,  8.17batch/s, loss=4.98e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg train loss 122821.11, bar train loss 0.030, len train loss 0.077, col train loss 156.459\n",
      "epoch 30: avg test  loss 124131.48, bar  test loss 0.026, len  test loss 1.092, col  test loss 157.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 272batch [00:33,  8.17batch/s, loss=4.93e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg train loss 122754.02, bar train loss 0.030, len train loss 0.077, col train loss 156.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 1batch [00:00,  8.06batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg test  loss 124039.46, bar  test loss 0.026, len  test loss 1.030, col  test loss 157.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 272batch [00:33,  8.16batch/s, loss=4.92e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg train loss 122688.09, bar train loss 0.029, len train loss 0.075, col train loss 156.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 1batch [00:00,  8.00batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg test  loss 124009.36, bar  test loss 0.026, len  test loss 1.008, col  test loss 157.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 272batch [00:33,  8.13batch/s, loss=4.9e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg train loss 122675.45, bar train loss 0.029, len train loss 0.077, col train loss 156.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 1batch [00:00,  8.13batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg test  loss 124016.84, bar  test loss 0.026, len  test loss 1.159, col  test loss 157.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 272batch [00:33,  8.12batch/s, loss=4.38e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg train loss 122579.12, bar train loss 0.029, len train loss 0.075, col train loss 156.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 1batch [00:00,  8.13batch/s, loss=1.19e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg test  loss 124017.38, bar  test loss 0.026, len  test loss 0.991, col  test loss 157.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 272batch [00:33,  8.12batch/s, loss=4.41e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg train loss 122548.10, bar train loss 0.029, len train loss 0.075, col train loss 156.149\n",
      "epoch 35: avg test  loss 123956.52, bar  test loss 0.026, len  test loss 0.959, col  test loss 157.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 272batch [00:33,  8.10batch/s, loss=4.61e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg train loss 122521.87, bar train loss 0.029, len train loss 0.074, col train loss 156.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 1batch [00:00,  7.94batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg test  loss 123986.90, bar  test loss 0.026, len  test loss 1.087, col  test loss 157.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 272batch [00:33,  8.10batch/s, loss=4.76e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg train loss 122513.44, bar train loss 0.029, len train loss 0.075, col train loss 156.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 1batch [00:00,  8.00batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg test  loss 123884.66, bar  test loss 0.026, len  test loss 0.850, col  test loss 157.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 272batch [00:33,  8.11batch/s, loss=5.1e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg train loss 122514.20, bar train loss 0.029, len train loss 0.074, col train loss 156.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 1batch [00:00,  8.13batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg test  loss 123882.83, bar  test loss 0.026, len  test loss 0.877, col  test loss 157.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 272batch [00:33,  8.11batch/s, loss=4.73e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg train loss 122453.65, bar train loss 0.029, len train loss 0.071, col train loss 155.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 1batch [00:00,  8.06batch/s, loss=1.17e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg test  loss 123933.55, bar  test loss 0.026, len  test loss 0.949, col  test loss 157.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 272batch [00:33,  8.08batch/s, loss=4.2e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: avg train loss 122377.63, bar train loss 0.029, len train loss 0.074, col train loss 155.942\n",
      "epoch 40: avg test  loss 123820.16, bar  test loss 0.026, len  test loss 0.907, col  test loss 157.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 272batch [00:33,  8.08batch/s, loss=4.61e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg train loss 122363.13, bar train loss 0.029, len train loss 0.072, col train loss 155.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 1batch [00:00,  8.00batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg test  loss 123810.70, bar  test loss 0.026, len  test loss 0.982, col  test loss 157.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 272batch [00:33,  8.08batch/s, loss=4.84e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg train loss 122340.50, bar train loss 0.029, len train loss 0.069, col train loss 155.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 1batch [00:00,  8.00batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg test  loss 123744.85, bar  test loss 0.026, len  test loss 0.767, col  test loss 157.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 272batch [00:33,  8.08batch/s, loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg train loss 122302.07, bar train loss 0.029, len train loss 0.073, col train loss 155.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 1batch [00:00,  8.06batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg test  loss 123780.96, bar  test loss 0.026, len  test loss 0.915, col  test loss 157.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 272batch [00:33,  8.07batch/s, loss=4.94e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg train loss 122265.13, bar train loss 0.029, len train loss 0.070, col train loss 155.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 1batch [00:00,  7.87batch/s, loss=1.31e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg test  loss 123806.16, bar  test loss 0.026, len  test loss 0.974, col  test loss 157.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 272batch [00:33,  8.05batch/s, loss=4.57e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45: avg train loss 122229.48, bar train loss 0.029, len train loss 0.071, col train loss 155.711\n",
      "epoch 45: avg test  loss 123699.27, bar  test loss 0.025, len  test loss 0.869, col  test loss 157.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 272batch [00:33,  8.04batch/s, loss=4.47e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg train loss 122205.98, bar train loss 0.029, len train loss 0.068, col train loss 155.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 1batch [00:00,  7.94batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg test  loss 123752.91, bar  test loss 0.026, len  test loss 0.958, col  test loss 157.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 272batch [00:33,  8.04batch/s, loss=4.66e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg train loss 122201.09, bar train loss 0.028, len train loss 0.067, col train loss 155.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 1batch [00:00,  7.87batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg test  loss 123772.69, bar  test loss 0.025, len  test loss 0.933, col  test loss 157.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 272batch [00:33,  8.02batch/s, loss=5.14e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg train loss 122234.02, bar train loss 0.029, len train loss 0.067, col train loss 155.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 1batch [00:00,  8.06batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg test  loss 123717.18, bar  test loss 0.026, len  test loss 0.888, col  test loss 157.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 272batch [00:33,  8.01batch/s, loss=4.5e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg train loss 122189.41, bar train loss 0.028, len train loss 0.070, col train loss 155.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 1batch [00:00,  7.94batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg test  loss 123678.48, bar  test loss 0.025, len  test loss 0.786, col  test loss 156.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 272batch [00:33,  8.01batch/s, loss=5.22e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: avg train loss 122199.55, bar train loss 0.028, len train loss 0.066, col train loss 155.609\n",
      "epoch 50: avg test  loss 123733.06, bar  test loss 0.025, len  test loss 0.856, col  test loss 157.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 272batch [00:33,  8.01batch/s, loss=4.5e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg train loss 122135.37, bar train loss 0.028, len train loss 0.066, col train loss 155.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 1batch [00:00,  7.94batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg test  loss 123691.70, bar  test loss 0.026, len  test loss 0.782, col  test loss 156.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 272batch [00:34,  7.99batch/s, loss=4.35e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg train loss 122097.29, bar train loss 0.028, len train loss 0.067, col train loss 155.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 1batch [00:00,  8.00batch/s, loss=1.18e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: avg test  loss 123655.49, bar  test loss 0.025, len  test loss 0.916, col  test loss 156.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 272batch [00:34,  7.99batch/s, loss=4.88e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg train loss 122097.62, bar train loss 0.028, len train loss 0.067, col train loss 155.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 1batch [00:00,  8.00batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: avg test  loss 123606.10, bar  test loss 0.026, len  test loss 0.801, col  test loss 156.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 272batch [00:34,  7.98batch/s, loss=4.9e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg train loss 122117.11, bar train loss 0.028, len train loss 0.068, col train loss 155.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 1batch [00:00,  7.69batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: avg test  loss 123633.47, bar  test loss 0.026, len  test loss 0.854, col  test loss 156.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 272batch [00:34,  7.97batch/s, loss=4.71e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55: avg train loss 122095.60, bar train loss 0.028, len train loss 0.067, col train loss 155.517\n",
      "epoch 55: avg test  loss 123619.23, bar  test loss 0.026, len  test loss 0.708, col  test loss 156.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 272batch [00:34,  7.97batch/s, loss=4.47e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg train loss 122054.45, bar train loss 0.028, len train loss 0.066, col train loss 155.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 1batch [00:00,  7.87batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: avg test  loss 123638.78, bar  test loss 0.026, len  test loss 0.860, col  test loss 156.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 272batch [00:34,  7.94batch/s, loss=4.63e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg train loss 122087.08, bar train loss 0.028, len train loss 0.067, col train loss 155.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 1batch [00:00,  8.00batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: avg test  loss 123567.87, bar  test loss 0.026, len  test loss 0.757, col  test loss 156.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 272batch [00:34,  7.95batch/s, loss=4.58e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg train loss 122067.92, bar train loss 0.028, len train loss 0.066, col train loss 155.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 1batch [00:00,  7.87batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: avg test  loss 123549.79, bar  test loss 0.026, len  test loss 0.680, col  test loss 156.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 272batch [00:34,  7.95batch/s, loss=4.88e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg train loss 122080.80, bar train loss 0.028, len train loss 0.066, col train loss 155.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 1batch [00:00,  7.58batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: avg test  loss 123581.11, bar  test loss 0.025, len  test loss 0.696, col  test loss 156.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 272batch [00:34,  7.95batch/s, loss=4.45e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60: avg train loss 122079.80, bar train loss 0.028, len train loss 0.067, col train loss 155.503\n",
      "epoch 60: avg test  loss 123574.63, bar  test loss 0.026, len  test loss 0.766, col  test loss 156.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 272batch [00:34,  7.93batch/s, loss=4.82e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg train loss 122089.14, bar train loss 0.028, len train loss 0.067, col train loss 155.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 1batch [00:00,  7.87batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: avg test  loss 123637.14, bar  test loss 0.026, len  test loss 0.765, col  test loss 156.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 272batch [00:34,  7.93batch/s, loss=4.88e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg train loss 122101.50, bar train loss 0.028, len train loss 0.065, col train loss 155.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 1batch [00:00,  7.87batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: avg test  loss 123528.43, bar  test loss 0.026, len  test loss 0.761, col  test loss 156.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 272batch [00:34,  7.92batch/s, loss=4.96e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg train loss 122102.69, bar train loss 0.028, len train loss 0.066, col train loss 155.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 1batch [00:00,  7.69batch/s, loss=1.17e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: avg test  loss 123572.12, bar  test loss 0.025, len  test loss 0.777, col  test loss 156.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 272batch [00:34,  7.90batch/s, loss=4.28e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg train loss 122016.16, bar train loss 0.028, len train loss 0.066, col train loss 155.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 1batch [00:00,  7.94batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg test  loss 123587.24, bar  test loss 0.026, len  test loss 0.757, col  test loss 156.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 272batch [00:34,  7.90batch/s, loss=4.67e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: avg train loss 122048.02, bar train loss 0.028, len train loss 0.064, col train loss 155.447\n",
      "epoch 65: avg test  loss 123526.02, bar  test loss 0.026, len  test loss 0.708, col  test loss 156.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 272batch [00:34,  7.90batch/s, loss=4.57e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg train loss 122015.23, bar train loss 0.028, len train loss 0.064, col train loss 155.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 1batch [00:00,  7.69batch/s, loss=1.14e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg test  loss 123542.30, bar  test loss 0.025, len  test loss 0.745, col  test loss 156.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 272batch [00:34,  7.89batch/s, loss=4.58e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg train loss 121996.07, bar train loss 0.028, len train loss 0.066, col train loss 155.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 1batch [00:00,  7.69batch/s, loss=1.16e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg test  loss 123511.24, bar  test loss 0.026, len  test loss 0.791, col  test loss 156.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 272batch [00:34,  7.87batch/s, loss=4.8e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg train loss 122028.72, bar train loss 0.028, len train loss 0.066, col train loss 155.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 1batch [00:00,  7.81batch/s, loss=1.17e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg test  loss 123553.49, bar  test loss 0.026, len  test loss 0.637, col  test loss 156.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 272batch [00:34,  7.86batch/s, loss=5.29e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg train loss 122100.53, bar train loss 0.028, len train loss 0.068, col train loss 155.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 1batch [00:00,  7.75batch/s, loss=1.18e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg test  loss 123519.73, bar  test loss 0.026, len  test loss 0.564, col  test loss 156.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 272batch [00:34,  7.85batch/s, loss=4.64e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70: avg train loss 122025.73, bar train loss 0.028, len train loss 0.067, col train loss 155.422\n",
      "epoch 70: avg test  loss 123561.41, bar  test loss 0.026, len  test loss 0.642, col  test loss 156.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 272batch [00:34,  7.86batch/s, loss=4.65e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg train loss 122026.23, bar train loss 0.028, len train loss 0.066, col train loss 155.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 1batch [00:00,  7.75batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg test  loss 123481.22, bar  test loss 0.026, len  test loss 0.671, col  test loss 156.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 272batch [00:34,  7.84batch/s, loss=4.7e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg train loss 122013.40, bar train loss 0.028, len train loss 0.066, col train loss 155.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 1batch [00:00,  7.75batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg test  loss 123462.43, bar  test loss 0.025, len  test loss 0.657, col  test loss 156.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 272batch [00:34,  7.82batch/s, loss=4.73e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: avg train loss 122007.98, bar train loss 0.028, len train loss 0.068, col train loss 155.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 1batch [00:00,  7.87batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: avg test  loss 123494.81, bar  test loss 0.025, len  test loss 0.763, col  test loss 156.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 272batch [00:34,  7.81batch/s, loss=4.83e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74: avg train loss 122070.75, bar train loss 0.028, len train loss 0.067, col train loss 155.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 1batch [00:00,  7.81batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74: avg test  loss 123521.23, bar  test loss 0.026, len  test loss 0.686, col  test loss 156.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 272batch [00:34,  7.78batch/s, loss=5.1e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75: avg train loss 122055.20, bar train loss 0.028, len train loss 0.065, col train loss 155.405\n",
      "epoch 75: avg test  loss 123493.25, bar  test loss 0.026, len  test loss 0.638, col  test loss 156.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 272batch [00:34,  7.78batch/s, loss=5.01e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76: avg train loss 122065.97, bar train loss 0.028, len train loss 0.065, col train loss 155.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 1batch [00:00,  7.75batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76: avg test  loss 123461.58, bar  test loss 0.026, len  test loss 0.661, col  test loss 156.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 272batch [00:34,  7.77batch/s, loss=4.48e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: avg train loss 122036.21, bar train loss 0.028, len train loss 0.066, col train loss 155.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 1batch [00:00,  7.58batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: avg test  loss 123503.09, bar  test loss 0.025, len  test loss 0.652, col  test loss 156.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 272batch [00:35,  7.75batch/s, loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: avg train loss 121977.97, bar train loss 0.028, len train loss 0.063, col train loss 155.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 1batch [00:00,  7.69batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: avg test  loss 123463.02, bar  test loss 0.025, len  test loss 0.624, col  test loss 156.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 272batch [00:35,  7.75batch/s, loss=4.72e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79: avg train loss 122069.91, bar train loss 0.028, len train loss 0.064, col train loss 155.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 1batch [00:00,  7.63batch/s, loss=1.19e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79: avg test  loss 123526.70, bar  test loss 0.026, len  test loss 0.530, col  test loss 156.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 272batch [00:35,  7.70batch/s, loss=4.77e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80: avg train loss 122027.91, bar train loss 0.028, len train loss 0.065, col train loss 155.400\n",
      "epoch 80: avg test  loss 123464.48, bar  test loss 0.026, len  test loss 0.625, col  test loss 156.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 272batch [00:35,  7.71batch/s, loss=5.08e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81: avg train loss 122068.84, bar train loss 0.028, len train loss 0.067, col train loss 155.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 1batch [00:00,  7.63batch/s, loss=1.19e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81: avg test  loss 123525.66, bar  test loss 0.026, len  test loss 0.689, col  test loss 156.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 272batch [00:35,  7.69batch/s, loss=4.86e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: avg train loss 122046.52, bar train loss 0.028, len train loss 0.066, col train loss 155.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 1batch [00:00,  7.69batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: avg test  loss 123489.70, bar  test loss 0.026, len  test loss 0.586, col  test loss 156.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 272batch [00:35,  7.68batch/s, loss=5.09e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83: avg train loss 122090.38, bar train loss 0.028, len train loss 0.065, col train loss 155.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 1batch [00:00,  7.81batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83: avg test  loss 123444.37, bar  test loss 0.026, len  test loss 0.673, col  test loss 156.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 272batch [00:35,  7.68batch/s, loss=4.98e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: avg train loss 122069.17, bar train loss 0.028, len train loss 0.066, col train loss 155.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 1batch [00:00,  7.58batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: avg test  loss 123452.75, bar  test loss 0.026, len  test loss 0.638, col  test loss 156.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 272batch [00:35,  7.64batch/s, loss=5.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85: avg train loss 122065.48, bar train loss 0.028, len train loss 0.064, col train loss 155.426\n",
      "epoch 85: avg test  loss 123507.88, bar  test loss 0.026, len  test loss 0.621, col  test loss 156.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 272batch [00:35,  7.63batch/s, loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86: avg train loss 122027.70, bar train loss 0.028, len train loss 0.063, col train loss 155.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 1batch [00:00,  7.69batch/s, loss=1.18e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86: avg test  loss 123438.36, bar  test loss 0.025, len  test loss 0.619, col  test loss 156.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 272batch [00:35,  7.62batch/s, loss=4.84e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: avg train loss 122059.78, bar train loss 0.028, len train loss 0.063, col train loss 155.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 1batch [00:00,  7.09batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: avg test  loss 123460.05, bar  test loss 0.026, len  test loss 0.468, col  test loss 156.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 272batch [00:35,  7.59batch/s, loss=5.21e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: avg train loss 122100.90, bar train loss 0.028, len train loss 0.062, col train loss 155.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 1batch [00:00,  7.41batch/s, loss=1.28e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: avg test  loss 123459.54, bar  test loss 0.026, len  test loss 0.636, col  test loss 156.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 272batch [00:35,  7.57batch/s, loss=4.95e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89: avg train loss 122070.33, bar train loss 0.028, len train loss 0.062, col train loss 155.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 1batch [00:00,  7.63batch/s, loss=1.17e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89: avg test  loss 123466.39, bar  test loss 0.026, len  test loss 0.594, col  test loss 156.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 272batch [00:36,  7.55batch/s, loss=4.52e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90: avg train loss 122054.45, bar train loss 0.028, len train loss 0.062, col train loss 155.452\n",
      "epoch 90: avg test  loss 123453.74, bar  test loss 0.026, len  test loss 0.533, col  test loss 156.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 272batch [00:36,  7.55batch/s, loss=4.61e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91: avg train loss 122079.73, bar train loss 0.028, len train loss 0.064, col train loss 155.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 1batch [00:00,  7.75batch/s, loss=1.25e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91: avg test  loss 123498.38, bar  test loss 0.026, len  test loss 0.627, col  test loss 156.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 272batch [00:36,  7.54batch/s, loss=4.65e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: avg train loss 122076.05, bar train loss 0.028, len train loss 0.062, col train loss 155.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 1batch [00:00,  7.63batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: avg test  loss 123451.29, bar  test loss 0.026, len  test loss 0.547, col  test loss 156.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 272batch [00:36,  7.53batch/s, loss=4.82e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93: avg train loss 122109.14, bar train loss 0.028, len train loss 0.063, col train loss 155.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 1batch [00:00,  7.52batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93: avg test  loss 123568.34, bar  test loss 0.026, len  test loss 0.661, col  test loss 156.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 272batch [00:36,  7.54batch/s, loss=5.02e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94: avg train loss 122141.80, bar train loss 0.028, len train loss 0.062, col train loss 155.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 1batch [00:00,  7.35batch/s, loss=1.15e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94: avg test  loss 123548.62, bar  test loss 0.026, len  test loss 0.593, col  test loss 156.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 272batch [00:36,  7.50batch/s, loss=4.8e+5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95: avg train loss 122179.59, bar train loss 0.028, len train loss 0.064, col train loss 155.577\n",
      "epoch 95: avg test  loss 123519.54, bar  test loss 0.026, len  test loss 0.509, col  test loss 156.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 272batch [00:36,  7.48batch/s, loss=4.67e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96: avg train loss 122135.80, bar train loss 0.028, len train loss 0.063, col train loss 155.540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 1batch [00:00,  7.41batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96: avg test  loss 123468.34, bar  test loss 0.026, len  test loss 0.590, col  test loss 156.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 272batch [00:36,  7.40batch/s, loss=4.69e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: avg train loss 122098.98, bar train loss 0.028, len train loss 0.062, col train loss 155.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 1batch [00:00,  7.35batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: avg test  loss 123437.77, bar  test loss 0.026, len  test loss 0.553, col  test loss 156.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 272batch [00:36,  7.52batch/s, loss=4.45e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98: avg train loss 122074.02, bar train loss 0.028, len train loss 0.063, col train loss 155.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 1batch [00:00,  7.52batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98: avg test  loss 123443.51, bar  test loss 0.026, len  test loss 0.585, col  test loss 156.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 272batch [00:36,  7.44batch/s, loss=4.59e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: avg train loss 122177.11, bar train loss 0.028, len train loss 0.065, col train loss 155.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 1batch [00:00,  7.41batch/s, loss=1.26e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: avg test  loss 123402.69, bar  test loss 0.026, len  test loss 0.543, col  test loss 156.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 272batch [00:36,  7.42batch/s, loss=4.72e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: avg train loss 122152.39, bar train loss 0.028, len train loss 0.061, col train loss 155.565\n",
      "epoch 100: avg test  loss 123493.98, bar  test loss 0.026, len  test loss 0.540, col  test loss 156.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 272batch [00:36,  7.42batch/s, loss=4.92e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: avg train loss 122190.09, bar train loss 0.028, len train loss 0.063, col train loss 155.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 1batch [00:00,  7.41batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: avg test  loss 123526.28, bar  test loss 0.026, len  test loss 0.605, col  test loss 156.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 272batch [00:36,  7.40batch/s, loss=4.63e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: avg train loss 122201.74, bar train loss 0.028, len train loss 0.063, col train loss 155.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 1batch [00:00,  7.25batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: avg test  loss 123540.45, bar  test loss 0.026, len  test loss 0.520, col  test loss 156.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 272batch [00:36,  7.37batch/s, loss=4.56e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103: avg train loss 122192.40, bar train loss 0.028, len train loss 0.067, col train loss 155.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 1batch [00:00,  7.14batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103: avg test  loss 123536.20, bar  test loss 0.026, len  test loss 0.561, col  test loss 156.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 272batch [00:36,  7.36batch/s, loss=4.55e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: avg train loss 122203.92, bar train loss 0.028, len train loss 0.066, col train loss 155.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 1batch [00:00,  7.35batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: avg test  loss 123549.66, bar  test loss 0.026, len  test loss 0.521, col  test loss 156.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 272batch [00:37,  7.32batch/s, loss=4.34e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105: avg train loss 122172.61, bar train loss 0.028, len train loss 0.067, col train loss 155.606\n",
      "epoch 105: avg test  loss 123553.12, bar  test loss 0.026, len  test loss 0.557, col  test loss 156.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106: 272batch [00:37,  7.33batch/s, loss=4.65e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: avg train loss 122213.94, bar train loss 0.028, len train loss 0.065, col train loss 155.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 1batch [00:00,  7.35batch/s, loss=1.21e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: avg test  loss 123495.29, bar  test loss 0.026, len  test loss 0.467, col  test loss 156.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 272batch [00:37,  7.32batch/s, loss=4.84e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: avg train loss 122244.80, bar train loss 0.028, len train loss 0.066, col train loss 155.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 1batch [00:00,  7.25batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: avg test  loss 123619.60, bar  test loss 0.026, len  test loss 0.635, col  test loss 156.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 272batch [00:37,  7.31batch/s, loss=4.75e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: avg train loss 122293.44, bar train loss 0.029, len train loss 0.066, col train loss 155.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 1batch [00:00,  7.14batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: avg test  loss 123569.27, bar  test loss 0.026, len  test loss 0.499, col  test loss 156.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 272batch [00:37,  7.24batch/s, loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109: avg train loss 122289.01, bar train loss 0.029, len train loss 0.066, col train loss 155.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 1batch [00:00,  7.19batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109: avg test  loss 123575.68, bar  test loss 0.026, len  test loss 0.500, col  test loss 156.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 272batch [00:37,  7.23batch/s, loss=5.05e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110: avg train loss 122390.70, bar train loss 0.029, len train loss 0.066, col train loss 155.820\n",
      "epoch 110: avg test  loss 123598.91, bar  test loss 0.026, len  test loss 0.560, col  test loss 156.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111: 272batch [00:37,  7.16batch/s, loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111: avg train loss 122362.92, bar train loss 0.029, len train loss 0.066, col train loss 155.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 1batch [00:00,  7.19batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111: avg test  loss 123581.45, bar  test loss 0.026, len  test loss 0.503, col  test loss 156.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 272batch [00:39,  6.94batch/s, loss=4.48e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112: avg train loss 122308.70, bar train loss 0.029, len train loss 0.065, col train loss 155.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 1batch [00:00,  6.58batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112: avg test  loss 123580.93, bar  test loss 0.026, len  test loss 0.611, col  test loss 156.840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 272batch [00:40,  6.69batch/s, loss=4.49e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113: avg train loss 122344.77, bar train loss 0.029, len train loss 0.066, col train loss 155.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114: 1batch [00:00,  7.04batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113: avg test  loss 123586.47, bar  test loss 0.026, len  test loss 0.552, col  test loss 156.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114: 272batch [00:38,  6.98batch/s, loss=4.58e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114: avg train loss 122364.80, bar train loss 0.029, len train loss 0.064, col train loss 155.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115: 1batch [00:00,  7.14batch/s, loss=1.23e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114: avg test  loss 123567.96, bar  test loss 0.026, len  test loss 0.552, col  test loss 156.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115: 272batch [00:39,  6.94batch/s, loss=4.41e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115: avg train loss 122346.40, bar train loss 0.029, len train loss 0.068, col train loss 155.810\n",
      "epoch 115: avg test  loss 123593.55, bar  test loss 0.026, len  test loss 0.675, col  test loss 156.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116: 272batch [00:39,  6.87batch/s, loss=4.65e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116: avg train loss 122382.57, bar train loss 0.029, len train loss 0.068, col train loss 155.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117: 1batch [00:00,  7.14batch/s, loss=1.2e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116: avg test  loss 123603.66, bar  test loss 0.026, len  test loss 0.542, col  test loss 156.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117: 272batch [00:39,  6.81batch/s, loss=4.66e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117: avg train loss 122471.32, bar train loss 0.029, len train loss 0.066, col train loss 155.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118: 1batch [00:00,  7.25batch/s, loss=1.14e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117: avg test  loss 123662.95, bar  test loss 0.026, len  test loss 0.488, col  test loss 156.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118: 272batch [00:40,  6.77batch/s, loss=4.87e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118: avg train loss 122396.02, bar train loss 0.029, len train loss 0.068, col train loss 155.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119: 1batch [00:00,  6.62batch/s, loss=1.22e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118: avg test  loss 123630.18, bar  test loss 0.026, len  test loss 0.515, col  test loss 156.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119: 272batch [00:40,  6.73batch/s, loss=4.66e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119: avg train loss 122440.45, bar train loss 0.029, len train loss 0.068, col train loss 155.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120: 1batch [00:00,  7.14batch/s, loss=1.24e+5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119: avg test  loss 123643.70, bar  test loss 0.027, len  test loss 0.476, col  test loss 156.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120: 272batch [00:40,  6.68batch/s, loss=4.72e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120: avg train loss 122449.09, bar train loss 0.029, len train loss 0.068, col train loss 155.922\n",
      "epoch 120: avg test  loss 123686.91, bar  test loss 0.027, len  test loss 0.466, col  test loss 156.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 242batch [00:36,  6.65batch/s, loss=1.2e+5] "
     ]
    }
   ],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1000, 0, save_folder=\"new/DOUBLEHVAE\",save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1000,273,save_folder=\"new/DOUBLEHVAE\",save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4182003,
     "status": "ok",
     "timestamp": 1647010362327,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "NprX9l7G73MJ",
    "outputId": "e970b2ef-1d7d-4702-dd1f-3bb4b59c0326"
   },
   "outputs": [],
   "source": [
    "lss2, lss_t2 = train(default_args, train_loader, test_loader, diva, optimizer, 1000, 500, save_folder=\"VAEFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 1600, 1000, save_folder=\"VAEFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4r_UyPUGXqT"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(lss, lss_t):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(lss, label=\"train loss\")\n",
    "    ax.plot(lss_t, label = \"test loss\")\n",
    "    #ax1 = ax.twinx()\n",
    "    #ax1.plot(yacc, label = \"train accuracy\", ls='--')\n",
    "    #ax1.plot(yacc_t, label = \"test accuracy\", ls='--')\n",
    "\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    #lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(lines, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1645822416415,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "fTFZZmoguwtU",
    "outputId": "540c8c1f-99d7-4931-c102-7c96747243aa"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss, lss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1645623855467,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "mq2FG26TznE1",
    "outputId": "152eddd3-a440-4b25-c437-498efb0a7ffe"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss3, lss_t3, yacc3, yacc_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FyP02qPdgso"
   },
   "outputs": [],
   "source": [
    "def plot_change_latent_var(diva, lat_space=\"y\", var_idx=[0,1,2,3,4,5,6,7], step = 5):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:len(var_idx)].to(DEVICE).float()\n",
    "        x = a[1][0][:len(var_idx)].to(DEVICE).float()\n",
    "        y = a[1][1][:len(var_idx)].to(DEVICE).float()\n",
    "\n",
    "        zx, zx_sc = diva.qzx(x)\n",
    "        zy, zy_sc = diva.qzy(x)\n",
    "        zd, zd_sc =  diva.qzd(x)\n",
    "\n",
    "        print(torch.max(zy), torch.min(zy), \"sdmax:\", torch.max(zy_sc))\n",
    "\n",
    "        out = change(zx, zy, zd, var_idx, lat_space, diva, step)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=out.shape[0],nrows=len(var_idx),figsize=(10*4*out.shape[0],10*len(var_idx)))\n",
    "    for i in range(out.shape[0]):\n",
    "      for j in range(len(var_idx)):\n",
    "        ax[j,i].imshow(out[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6kJu1APenFe"
   },
   "outputs": [],
   "source": [
    "def change(zx, zy, zd, idx, lat = \"y\", model=diva, step = 2):\n",
    "    \n",
    "    dif = np.arange(-30,15,step)\n",
    "    print(torch.max(zy), torch.min(zy))\n",
    "    out = np.zeros((dif.shape[0], len(idx), 25, 100 ,3))  \n",
    "    #print(zy.shape, dif.shape[0])\n",
    "    for i in range(dif.shape[0]):\n",
    "      for j in range(len(idx)):\n",
    "        if lat == \"y\":\n",
    "            zy[j,idx] = dif[i]\n",
    "        elif lat == \"x\":\n",
    "            zx[j,idx] = dif[i]\n",
    "        elif lat == \"d\":\n",
    "            zd[j,idx] = dif[i]\n",
    "        len_, bar, col = model.px(zd[j],zx[j],zy[j])\n",
    "        out[i,j] = model.px.reconstruct_image(len_[None,:], bar, col)\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 33513,
     "status": "ok",
     "timestamp": 1645623900042,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "4U1JHmTKh0cE",
    "outputId": "b0a1850e-9f0d-4163-813b-8686f4bb05fc"
   },
   "outputs": [],
   "source": [
    "plot_change_latent_var(diva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpZoRZMGHcui"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss2], label=\"train loss\")\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss_t2], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(50,120), yacc2, label = \"train\")\n",
    "ax1.plot(np.arange(50,120), yacc_t2, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1645563980004,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OQMW85JXM6oO",
    "outputId": "dd28a6c2-0024-498e-d571-c705ee67fbd6"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss3], label=\"train loss\")\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss_t3], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(120,180), yacc3, label = \"train\",c='green')\n",
    "ax1.plot(np.arange(120,180), yacc_t3, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whsgNltzXDhK"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfcwhSNIjqIE"
   },
   "source": [
    "## Sampling from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NWGV4Xd7bn8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z5XA4QI1Mb1"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(lat_space=\"y\"):\n",
    "    '''\n",
    "    lat_space: y, d, x\n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1645556291755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "USZ7nIDugT1S",
    "outputId": "174d53bb-845f-458b-ca85-9d749c9c0865"
   },
   "outputs": [],
   "source": [
    "plot(x, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1645550689935,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OE3qVVFFLaPm",
    "outputId": "93953e16-3bda-464b-b765-3aedb9fbe428"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i in range(9):\n",
    "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
    "  \n",
    "plt.savefig('divastamporg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQU05xQEx28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StampVAE (Beta)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "UuXEtFCubCjx"
   },
   "outputs": [],
   "source": [
    "link = 'D:/users/Marko/downloads/mirna/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgMR4QspjvRl"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023261840,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "aXljY6Cp4zU-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31000,
     "status": "ok",
     "timestamp": 1647023292835,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "VgKU5wNzDK4F",
    "outputId": "2edd95bf-9577-4772-eeca-95c5d32cf026"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0,'/content/drive/MyDrive/Marko/master')\n",
    "sys.path.insert(0, link)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"{link}/saved_models/new/IVAE1/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "HuLsYxyh6_ZM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFkNf0cjx2V"
   },
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647023292836,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ae7NZhZGj7Zi"
   },
   "outputs": [],
   "source": [
    "class diva_args:\n",
    "\n",
    "    def __init__(self, z_dim=128, d_dim=45, x_dim=7500, y_dim=2,\n",
    "                 beta=10, rec_alpha = 1, rec_beta = 1, \n",
    "                 rec_gamma = 1, warmup = 1, prewarmup = 1):\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.d_dim = d_dim\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        \n",
    "        self.beta = beta\n",
    "        self.rec_alpha = rec_alpha\n",
    "        self.rec_beta = rec_beta\n",
    "        self.rec_gamma = rec_gamma\n",
    "        self.warmup = warmup\n",
    "        self.prewarmup = prewarmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb1vH-a1j7Rf"
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1647023293159,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "D6ouvuZX3WPs"
   },
   "outputs": [],
   "source": [
    "class MicroRNADataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds='train', create_encodings=False, use_subset=False):\n",
    "        \n",
    "        # loading images\n",
    "        self.images = np.load(f'{link}/data/modmirbase_{ds}_images.npz')['arr_0']/255\n",
    "        \n",
    "        \n",
    "        # loading labels\n",
    "        print('Loading Labels! (~10s)')     \n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        labels = np.load(f'{link}/data/modmirbase_{ds}_labels.npz')['arr_0']\n",
    "        self.labels = ohe.fit_transform(labels)\n",
    "        \n",
    "        # loading encoded images\n",
    "        print(\"loading encodings\")\n",
    "        if create_encodings:\n",
    "            x_len, x_bar, x_col = self.get_encoded_values(self.images, ds)\n",
    "        else:\n",
    "            x_len = np.load(f'{link}/data/modmirbase_{ds}_images_len_new.npz')\n",
    "            x_bar = np.load(f'{link}/data/modmirbase_{ds}_images_bar_new.npz')\n",
    "            x_col = np.load(f'{link}/data/modmirbase_{ds}_images_col_new.npz')\n",
    "        \n",
    "        self.x_len = x_len\n",
    "        self.x_bar = x_bar\n",
    "        self.x_col = x_col\n",
    "        \n",
    "        \n",
    "        self.mountain = np.load(f'{link}/data/modmirbase_{ds}_mountain.npy')\n",
    "        \n",
    "        \n",
    "        # loading names\n",
    "        print('Loading Names! (~5s)')\n",
    "        names =  np.load(f'{link}/data/modmirbase_{ds}_names.npz')['arr_0']\n",
    "        names = [i.decode('utf-8') for i in names]\n",
    "        self.species = ['mmu', 'prd', 'hsa', 'ptr', 'efu', 'cbn', 'gma', 'pma',\n",
    "                        'cel', 'gga', 'ipu', 'ptc', 'mdo', 'cgr', 'bta', 'cin', \n",
    "                        'ppy', 'ssc', 'ath', 'cfa', 'osa', 'mtr', 'gra', 'mml',\n",
    "                        'stu', 'bdi', 'rno', 'oan', 'dre', 'aca', 'eca', 'chi',\n",
    "                        'bmo', 'ggo', 'aly', 'dps', 'mdm', 'ame', 'ppc', 'ssa',\n",
    "                        'ppt', 'tca', 'dme', 'sbi']\n",
    "        # assigning a species label to each observation from species\n",
    "        # with more than 200 observations from past research\n",
    "        self.names = []\n",
    "        for i in names:\n",
    "            append = False\n",
    "            for j in self.species:\n",
    "                if j in i.lower():\n",
    "                    self.names.append(j)\n",
    "                    append = True\n",
    "                    break\n",
    "            if not append:\n",
    "                if 'random' in i.lower() or i.isdigit():\n",
    "                    self.names.append('hsa')\n",
    "                else:\n",
    "                    self.names.append('notfound')\n",
    "        \n",
    "        # performing one hot encoding\n",
    "        ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.names_ohe = ohe.fit_transform(np.array(self.names).reshape(-1,1))\n",
    "          \n",
    "        if use_subset:    \n",
    "            idxes = [i == 'hsa' and np.random.choice([True, False]) for i in self.names]\n",
    "            self.names_ohe = self.names_ohe[idxes]\n",
    "            self.labels = self.labels[idxes]\n",
    "            self.images = self.images[idxes]\n",
    "            self.x_len = self.x_len[idxes]\n",
    "            self.x_col = self.x_col[idxes]\n",
    "            self.x_bar = self.x_bar[idxes]\n",
    "            self.mountain = self.mountain[idxes]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.names_ohe[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = self.images[idx]\n",
    "        x = np.transpose(x, (2,0,1))\n",
    "        x_len = self.x_len[idx]\n",
    "        x_col = self.x_col[idx]\n",
    "        x_bar = self.x_bar[idx]\n",
    "        mount = self.mountain[idx]                        \n",
    "        return (x, y, d, x_len, x_col, x_bar, mount)\n",
    "\n",
    "\n",
    "    def get_encoded_values(self, x, ds):\n",
    "        \"\"\"\n",
    "        given an image or batch of images\n",
    "        returns length of strand, length of bars and colors of bars\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        x = np.transpose(x, (0,3,1,2))\n",
    "        out_len = np.zeros((n), dtype=np.uint8)\n",
    "        out_col = np.zeros((n,26,100), dtype=np.uint8)\n",
    "        out_bar = np.zeros((n,2,100), dtype=np.uint8)\n",
    "\n",
    "        for i in range(n):\n",
    "            if i % 100 == 0:\n",
    "                print(f'at {i} out of {n}')\n",
    "            rna_len = 0\n",
    "            broke = False\n",
    "            for j in range(100):\n",
    "                if (x[i,:,12,j] == np.array([1,1,1])).all():\n",
    "                    out_len[i] = rna_len\n",
    "                    broke = True\n",
    "                    out_col[i,25,j] = 1\n",
    "                else:\n",
    "                    rna_len += 1\n",
    "                    # check color of bars\n",
    "                    out_col[i, self.get_color(x,i,j),j] = 1 \n",
    "                    #out_col[i, self.get_color(x[i,:,13,j]), 1, j] = 1\n",
    "                    # check length of bars\n",
    "                    len1 = 0\n",
    "                    # loop until white pixel\n",
    "                    while not (x[i,:,12-len1,j] == np.array([1.,1.,1.])).all():\n",
    "                        len1 += 1\n",
    "                        if 13-len1 == 0:\n",
    "                            break\n",
    "                    out_bar[i, 0, j] = len1\n",
    "\n",
    "                    len2 = 0\n",
    "                    while not (x[i,:,13+len2,j] == np.array([1.,1.,1.])).all():\n",
    "                        len2 += 1\n",
    "                        if 13+len2 == 25:\n",
    "                            break\n",
    "                    out_bar[i, 1, j] = len2\n",
    "            if not broke:\n",
    "                out_len[i] = rna_len\n",
    "\n",
    "\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_len_new.npz', 'wb') as f:\n",
    "            np.save(f, out_len)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_col_new.npz', 'wb') as f:\n",
    "            np.save(f, out_col)\n",
    "        with open(f'{link}/data/modmirbase_{ds}_images_bar_new.npz', 'wb') as f:\n",
    "            np.save(f, out_bar)\n",
    "        \n",
    "\n",
    "        return out_len, out_bar, out_col\n",
    "\n",
    "    def get_color(self, x, i, j):\n",
    "        \n",
    "        col = self._get_color(x[i,:,12,j])+self._get_color(x[i,:,13,j])\n",
    "        if col == '00':\n",
    "            return 0\n",
    "        if col == '01':\n",
    "            return 1\n",
    "        if col == '02':\n",
    "            return 2\n",
    "        if col == '03':\n",
    "            return 3\n",
    "        if col == '04':\n",
    "            return 4\n",
    "        if col == '10':\n",
    "            return 5\n",
    "        if col == '11':\n",
    "            return 6\n",
    "        if col == '12':\n",
    "            return 7\n",
    "        if col == '13':\n",
    "            return 8\n",
    "        if col == '14':\n",
    "            return 9\n",
    "        if col == '20':\n",
    "            return 10\n",
    "        if col == '21':\n",
    "            return 11\n",
    "        if col == '22':\n",
    "            return 12\n",
    "        if col == '23':\n",
    "            return 13\n",
    "        if col == '24':\n",
    "            return 14\n",
    "        if col == '30':\n",
    "            return 15\n",
    "        if col == '31':\n",
    "            return 16\n",
    "        if col == '32':\n",
    "            return 17\n",
    "        if col == '33':\n",
    "            return 18\n",
    "        if col == '34':\n",
    "            return 19\n",
    "        if col == '40':\n",
    "            return 20\n",
    "        if col == '41':\n",
    "            return 21\n",
    "        if col == '42':\n",
    "            return 22\n",
    "        if col == '43':\n",
    "            return 23\n",
    "        if col == '44':\n",
    "            return 24\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _get_color(self, pixel):\n",
    "        \"\"\"\n",
    "        returns the encoded value for a pixel\n",
    "        \"\"\"\n",
    "        if (pixel == np.array([0,0,0])).all():  \n",
    "            return \"0\" # black\n",
    "        elif (pixel == np.array([1,0,0])).all():  \n",
    "            return \"1\" # red\n",
    "        elif (pixel == np.array([0,0,1])).all():  \n",
    "            return \"2\" # blue\n",
    "        elif (pixel == np.array([0,1,0])).all():  \n",
    "            return \"3\" # green\n",
    "        elif (pixel == np.array([1,1,0])).all():  \n",
    "            return \"4\" # yellow\n",
    "        else:\n",
    "            print(\"Something wrong!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xxj-WGXMj-Ne"
   },
   "source": [
    "## Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "RKizJuchX9uG"
   },
   "outputs": [],
   "source": [
    "# Decoders\n",
    "class px(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim, dim1=256, dim2=512):\n",
    "        super(px, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(z_dim, dim1, bias=False),  \n",
    "                                 nn.ReLU(),\n",
    "                                nn.Linear(dim1, dim2),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        # Predicting length and color of each bar\n",
    "        \n",
    "        self.color = nn.Sequential(nn.Linear(dim2, 2600))\n",
    "        \n",
    "        \n",
    "        self.length_bar = nn.Sequential(nn.Linear(dim2,200), nn.Softplus())\n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        \n",
    "        h = self.fc(z)\n",
    "        \n",
    "        \n",
    "        \n",
    "        len_bar = self.length_bar(h).reshape(-1,2,100)\n",
    "        len_bar_sc = nn.Parameter(torch.tensor([1.])).to(DEVICE)\n",
    "        \n",
    "        \n",
    "        col = self.color(h).reshape(-1,26,100)\n",
    "        col_bar = nn.Softmax(dim=1)(col)\n",
    "        \n",
    "        return len_bar, len_bar_sc, col_bar\n",
    "\n",
    "    def reconstruct_image(self, len_bar, var_bar ,col_bar, sample=False):\n",
    "        \"\"\"\n",
    "        reconstructs RNA image given output from decoder\n",
    "        even indexes of len_bar and col_bar   -> top\n",
    "        uneven indexes of len_bar and col_bar -> bottom\n",
    "        function does not support sampling yet\n",
    "        color reconstructions: 0: black\n",
    "                               1: red\n",
    "                               2: blue\n",
    "                               3: green\n",
    "                               4: yellow\n",
    "        \"\"\"\n",
    "        color_dict = {\n",
    "                  0: np.array([0,0,0]), # black\n",
    "                  1: np.array([1,0,0]), # red\n",
    "                  3: np.array([0,1,0]), # green\n",
    "                  2: np.array([0,0,1]), # blue\n",
    "                  4: np.array([1,1,0]),  # yellow\n",
    "                  5: np.array([1,1,1])  # white\n",
    "                  }\n",
    "    \n",
    "        _color_dict =  {0: (0,0),\n",
    "                        1: (0,1),\n",
    "                        2: (0,2),\n",
    "                        3: (0,3),\n",
    "                        4: (0,4),\n",
    "                        5: (1,0),\n",
    "                        6: (1,1),\n",
    "                        7: (1,2),\n",
    "                        8: (1,3),\n",
    "                        9: (1,4),\n",
    "                        10: (1,0),\n",
    "                        11: (2,1),\n",
    "                        12: (2,2),\n",
    "                        13: (2,3),\n",
    "                        14: (2,4),\n",
    "                        15: (2,0),\n",
    "                        16: (3,1),\n",
    "                        17: (3,2),\n",
    "                        18: (3,3),\n",
    "                        19: (3,4),\n",
    "                        20: (3,0),\n",
    "                        21: (4,1),\n",
    "                        22: (4,2),\n",
    "                        23: (4,3),\n",
    "                        24: (4,4),\n",
    "                        25: (5,5)\n",
    "                        }       \n",
    "        len_bar = len_bar.cpu().numpy()\n",
    "        var_bar = var_bar.cpu().numpy()\n",
    "        col_bar = col_bar.cpu().numpy()\n",
    "        n = len_bar.shape[0]\n",
    "        output = np.ones((n,25,100,3))\n",
    "\n",
    "        for i in range(n):\n",
    "            limit = 100\n",
    "            for j in range(limit):\n",
    "                if sample:\n",
    "                    _len_bar_1 = int(np.round(np.random.normal(loc=len_bar[i,0,j], scale=var_bar[i,0,j])))\n",
    "                    _len_bar_2 = int(np.round(np.random.normal(loc=len_bar[i,1,j], scale=var_bar[i,1,j])))\n",
    "                    _col_bar_1 = np.random.choice(np.arange(5), p = col_bar[i, :, 2*j])\n",
    "                    _col_bar_2 = np.random.choice(np.arange(5), p = col_bar[i,:, 2*j+1])\n",
    "                else:\n",
    "                    _len_bar_1 = int(np.round(len_bar[i,0,j])) \n",
    "                    _len_bar_2 = int(np.round(len_bar[i,1,j]))\n",
    "                    _col_bar_1, _col_bar_2 = _color_dict[np.argmax(col_bar[i,:,j])]\n",
    "                    \n",
    "                h1 = max(0,13-_len_bar_1)\n",
    "                # paint upper bar\n",
    "                output[i, h1:13, j] = color_dict[_col_bar_1]\n",
    "                h2 = min(25,13+_len_bar_2)\n",
    "                # paint lower bar\n",
    "                output[i, 13:h2, j] = color_dict[_col_bar_2]\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.round(3.7, 0))\n",
    "int(3.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023293160,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "1y8G2S1zxzTH"
   },
   "outputs": [],
   "source": [
    "# pzy_ = pzy(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, (1,2))\n",
    "# pzy_ = px(45, 7500, 2, 32,32,32)\n",
    "# summary(pzy_, [(1,32),(1,32),(1,32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmNnZWXvkCDP"
   },
   "source": [
    "## Endcoder Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647013220008,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "tt82wvITwg4j"
   },
   "outputs": [],
   "source": [
    "#pzy_.reconstruct_image(torch.zeros((1,100)), torch.zeros((1,13,200)), torch.zeros(1,5,200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_color(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(inception_color, self).__init__()\n",
    "        \n",
    "        self.filters = filters\n",
    "        \n",
    "        self.color_tower = nn.Sequential(\n",
    "            nn.Conv2d(3, 1, kernel_size=1, stride=1, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((13,1),stride=(13,1), ceil_mode=True)\n",
    "            \n",
    "        )\n",
    "        self.shape_tower = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ZeroPad2d((0,0,0,1)), # shape -1,26,100,12\n",
    "            nn.Conv2d(12, self.filters, kernel_size=(13,5), stride=(13,1)),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        col = self.color_tower(x)\n",
    "        col = col.view(-1,200)\n",
    "        shp = self.shape_tower(x)\n",
    "        shp = shp.view(-1, 2*96*self.filters)\n",
    "\n",
    "        out = torch.cat([col,shp],1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_A(nn.Module):\n",
    "    def __init__(self, in_channels=3, hidden_channels=16, out_channels=32):\n",
    "        super(inception_A, self).__init__()\n",
    "        \n",
    "        self.tower_1 = nn.Sequential(\n",
    "            nn.AvgPool2d((3,3), stride=1, padding=1, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.tower_3a = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(7,3), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3b = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(3,7), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=(1,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(3,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(7,3), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t1 = self.tower_1(x)\n",
    "        t2 = self.tower_2(x)\n",
    "        t3 = self.tower_3(x)\n",
    "        ta = self.tower_3a(t3)\n",
    "        tb = self.tower_3b(t3)\n",
    "        t4 = self.tower_4(x)\n",
    "        cat = torch.cat([t1,t2,ta,tb,t4],1)\n",
    "        out = self.out(cat)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class inception_B(nn.Module):\n",
    "    def __init__(self, in_channels=128, hidden_channels=64, out_channels=128):\n",
    "        super(inception_B, self).__init__()\n",
    "        \n",
    "        self.tower_1 = nn.Sequential(\n",
    "            nn.AvgPool2d((3,3), stride=1, padding=1, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(1,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(1,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.tower_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=(1,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=(1,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(7,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(1,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(7,1), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t1 = self.tower_1(x)\n",
    "        t2 = self.tower_2(x)\n",
    "        t3 = self.tower_3(x)\n",
    "        t4 = self.tower_4(x)\n",
    "        cat = torch.cat([t1,t2,t3,t4],1)\n",
    "        out = self.out(cat)\n",
    "        return out\n",
    "    \n",
    "class inception_C(nn.Module):\n",
    "    def __init__(self, in_channels=128, hidden_channels=64, out_channels=128):\n",
    "        super(inception_C, self).__init__()\n",
    "        \n",
    "        self.tower_1 = nn.Sequential(\n",
    "            nn.AvgPool2d((3,3), stride=1, padding=1, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.tower_3a = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(5,1), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3b = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(1,5), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.tower_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=(1,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=(1,3), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=(3,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.tower_4a = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(3,1), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_4b = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(1,3), padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t1 = self.tower_1(x)\n",
    "        t2 = self.tower_2(x)\n",
    "        t3 = self.tower_3(x)\n",
    "        t3a = self.tower_3a(t3)\n",
    "        t3b = self.tower_3b(t3)\n",
    "        t4 = self.tower_4(x)\n",
    "        t4a = self.tower_4a(t4)\n",
    "        t4b = self.tower_4b(t4)\n",
    "        cat = torch.cat([t1,t2,t3a,t3b,t4a,t4b],1)\n",
    "        out = self.out(cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reduction_A(nn.Module):\n",
    "    def __init__(self, in_channels=128, hidden_channels=128, out_channels=128):\n",
    "        super(reduction_A, self).__init__()\n",
    "        \n",
    "        self.tower_1 = nn.Sequential(\n",
    "            nn.MaxPool2d((3,7), stride=(2,3)),\n",
    "        )\n",
    "        \n",
    "        self.tower_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=(3,7), stride=(2,3), padding='valid'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(3,7), stride=(2,3), padding='valid'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t1 = self.tower_1(x)\n",
    "        t2 = self.tower_2(x)\n",
    "        t3 = self.tower_3(x)\n",
    "        cat = torch.cat([t1,t2,t3],1)\n",
    "        out = self.out(cat)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class reduction_B(nn.Module):\n",
    "    def __init__(self, in_channels=384, hidden_channels=64, out_channels=128):\n",
    "        super(reduction_B, self).__init__()\n",
    "        \n",
    "        self.tower_1 = nn.Sequential(\n",
    "            nn.MaxPool2d((3,7), stride=(2,3)),\n",
    "        )\n",
    "        \n",
    "        self.tower_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=(3,7), stride=(2,3), padding='valid'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.tower_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=(1,7), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=(7,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(3,7), stride=(2,3), padding='valid'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t1 = self.tower_1(x)\n",
    "        t2 = self.tower_2(x)\n",
    "        t3 = self.tower_3(x)\n",
    "        cat = torch.cat([t1,t2,t3],1)\n",
    "        out = self.out(cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "inception_color                          --                        --\n",
       "├─Sequential: 1-1                        [1, 1, 2, 100]            --\n",
       "│    └─Conv2d: 2-1                       [1, 1, 25, 100]           4\n",
       "│    └─ReLU: 2-2                         [1, 1, 25, 100]           --\n",
       "│    └─MaxPool2d: 2-3                    [1, 1, 2, 100]            --\n",
       "├─Sequential: 1-2                        [1, 4, 2, 96]             --\n",
       "│    └─Conv2d: 2-4                       [1, 12, 25, 100]          48\n",
       "│    └─ReLU: 2-5                         [1, 12, 25, 100]          --\n",
       "│    └─ZeroPad2d: 2-6                    [1, 12, 26, 100]          --\n",
       "│    └─Conv2d: 2-7                       [1, 4, 2, 96]             3,124\n",
       "│    └─ReLU: 2-8                         [1, 4, 2, 96]             --\n",
       "==========================================================================================\n",
       "Total params: 3,176\n",
       "Trainable params: 3,176\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.27\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc = inception_color(4)\n",
    "summary(inc, (1,3,25,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = inc.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 968])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc(torch.zeros((1,3,25,100)).to(DEVICE)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1647023293469,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "78ZFH8gYl_-z"
   },
   "outputs": [],
   "source": [
    "class qz(nn.Module):\n",
    "    def __init__(self, d_dim, x_dim, y_dim, z_dim):\n",
    "        super(qz, self).__init__()\n",
    "\n",
    "        self.inc_A = nn.Sequential( \n",
    "            inception_A(3, 8, 8),\n",
    "            inception_A(40,16,16),\n",
    "        )\n",
    "        \n",
    "        self.top = nn.Sequential(\n",
    "            nn.Conv2d(80, 96, kernel_size=(3,3), stride=2, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=2, padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "#         self.red_A = nn.Sequential(\n",
    "#             reduction_A(80,16,16)\n",
    "#         )\n",
    "#         self.inc_B = nn.Sequential(\n",
    "#             inception_B(112,16,16)\n",
    "#         )\n",
    "#         self.red_B = nn.Sequential(\n",
    "#             reduction_B(64,16,16)\n",
    "#         )\n",
    "#         self.inc_C = nn.Sequential(\n",
    "#             inception_C(96,64,96),\n",
    "#             #inception_C(512,32,64),\n",
    "#             nn.MaxPool2d(2,2)\n",
    "#         )\n",
    "        \n",
    "        self.inc_COL = inception_color(4)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(2304, 512), nn.ReLU())\n",
    "        \n",
    "        self.z_mu = nn.Sequential(nn.Linear(512+968, z_dim))\n",
    "        self.z_si = nn.Sequential(nn.Linear(512+968, z_dim), nn.Softplus())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.inc_A(x)\n",
    "        h = self.top(h)\n",
    "        h = h.view(-1,2304)\n",
    "        h = self.fc(h)\n",
    "        \n",
    "        c = self.inc_COL(x)\n",
    "        ch = torch.cat([c,h],1)\n",
    "        z_loc = self.z_mu(ch)\n",
    "        z_scale = self.z_si(ch) + 1e-7\n",
    "\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "qz                                       --                        --\n",
       "├─Sequential: 1-1                        [1, 80, 25, 100]          --\n",
       "│    └─inception_A: 2-1                  [1, 40, 25, 100]          --\n",
       "│    │    └─Sequential: 3-1              [1, 8, 25, 100]           32\n",
       "│    │    └─Sequential: 3-2              [1, 8, 25, 100]           32\n",
       "│    │    └─Sequential: 3-3              [1, 8, 25, 100]           32\n",
       "│    │    └─Sequential: 3-4              [1, 8, 25, 100]           1,352\n",
       "│    │    └─Sequential: 3-5              [1, 8, 25, 100]           1,352\n",
       "│    │    └─Sequential: 3-6              [1, 8, 25, 100]           2,736\n",
       "│    │    └─ReLU: 3-7                    [1, 40, 25, 100]          --\n",
       "│    └─inception_A: 2-2                  [1, 80, 25, 100]          --\n",
       "│    │    └─Sequential: 3-8              [1, 16, 25, 100]          656\n",
       "│    │    └─Sequential: 3-9              [1, 16, 25, 100]          656\n",
       "│    │    └─Sequential: 3-10             [1, 16, 25, 100]          656\n",
       "│    │    └─Sequential: 3-11             [1, 16, 25, 100]          5,392\n",
       "│    │    └─Sequential: 3-12             [1, 16, 25, 100]          5,392\n",
       "│    │    └─Sequential: 3-13             [1, 16, 25, 100]          11,440\n",
       "│    │    └─ReLU: 3-14                   [1, 80, 25, 100]          --\n",
       "├─Sequential: 1-2                        [1, 96, 2, 12]            --\n",
       "│    └─Conv2d: 2-3                       [1, 96, 12, 49]           69,216\n",
       "│    └─ReLU: 2-4                         [1, 96, 12, 49]           --\n",
       "│    └─Conv2d: 2-5                       [1, 96, 5, 24]            83,040\n",
       "│    └─ReLU: 2-6                         [1, 96, 5, 24]            --\n",
       "│    └─MaxPool2d: 2-7                    [1, 96, 2, 12]            --\n",
       "├─Sequential: 1-3                        [1, 512]                  --\n",
       "│    └─Linear: 2-8                       [1, 512]                  1,180,160\n",
       "│    └─ReLU: 2-9                         [1, 512]                  --\n",
       "├─inception_color: 1-4                   [1, 968]                  --\n",
       "│    └─Sequential: 2-10                  [1, 1, 2, 100]            --\n",
       "│    │    └─Conv2d: 3-15                 [1, 1, 25, 100]           4\n",
       "│    │    └─ReLU: 3-16                   [1, 1, 25, 100]           --\n",
       "│    │    └─MaxPool2d: 3-17              [1, 1, 2, 100]            --\n",
       "│    └─Sequential: 2-11                  [1, 4, 2, 96]             --\n",
       "│    │    └─Conv2d: 3-18                 [1, 12, 25, 100]          48\n",
       "│    │    └─ReLU: 3-19                   [1, 12, 25, 100]          --\n",
       "│    │    └─ZeroPad2d: 3-20              [1, 12, 26, 100]          --\n",
       "│    │    └─Conv2d: 3-21                 [1, 4, 2, 96]             3,124\n",
       "│    │    └─ReLU: 3-22                   [1, 4, 2, 96]             --\n",
       "├─Sequential: 1-5                        [1, 1024]                 --\n",
       "│    └─Linear: 2-12                      [1, 1024]                 1,516,544\n",
       "├─Sequential: 1-6                        [1, 1024]                 --\n",
       "│    └─Linear: 2-13                      [1, 1024]                 1,516,544\n",
       "│    └─Softplus: 2-14                    [1, 1024]                 --\n",
       "==========================================================================================\n",
       "Total params: 4,398,408\n",
       "Trainable params: 4,398,408\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 129.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 4.67\n",
       "Params size (MB): 17.59\n",
       "Estimated Total Size (MB): 22.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = qz(128,10,10,1024)\n",
    "summary(enc, (1,3,25,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn_gJdNSkH_V"
   },
   "source": [
    "## Full model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1647023293470,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "BgR5BnQN1WWG"
   },
   "outputs": [],
   "source": [
    "class StampDIVA(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StampDIVA, self).__init__()\n",
    "        self.z_dim = args.z_dim\n",
    "        self.d_dim = args.d_dim\n",
    "        self.x_dim = args.x_dim\n",
    "        self.y_dim = args.y_dim\n",
    "\n",
    "        self.px = px(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "        self.qz = qz(self.d_dim, self.x_dim, self.y_dim, self.z_dim)\n",
    "        \n",
    "\n",
    "        self.beta = args.beta\n",
    "        \n",
    "        self.rec_alpha = args.rec_alpha\n",
    "        self.rec_beta = args.rec_beta\n",
    "        self.rec_gamma = args.rec_gamma\n",
    "\n",
    "        self.warmup = args.warmup\n",
    "        self.prewarmup = args.prewarmup\n",
    "\n",
    "        self.cuda()\n",
    "\n",
    "    def forward(self, d, x, y):\n",
    "        # Encode\n",
    "        zd_q_loc, zd_q_scale = self.qz(x)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        qz = dist.Normal(zd_q_loc, zd_q_scale)\n",
    "        z_q = qz.rsample()\n",
    "        \n",
    "        \n",
    "        # Decode\n",
    "        x_bar, x_bar_scale, x_col = self.px(z_q)\n",
    "        z_p_loc, z_p_scale = torch.zeros(z_q.size()[0], self.z_dim).cuda(),\\\n",
    "                        torch.ones(z_q.size()[0], self.z_dim).cuda()\n",
    "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        pz = dist.Normal(z_p_loc, z_p_scale)\n",
    "        \n",
    "        return x_bar, x_bar_scale, x_col, qz, pz, z_q\n",
    "\n",
    "    def loss_function(self, d, x, y, out_len, out_bar, out_col):\n",
    "        \n",
    "        x_bar, x_bar_scale, x_col, qz, pz, z_q = self.forward(d, x, y)\n",
    "       \n",
    "        mse_bar = (((x_bar - out_bar)**2)).mean(dim=(1,2)).sum()\n",
    "        \n",
    "        max_bar = torch.argmax(x_col, dim=1)\n",
    "        acc_bar = (max_bar==torch.argmax(out_col, dim=1)).float().mean((1)).sum().float()\n",
    "        \n",
    "        CE_bar = mse_bar#-log_bar\n",
    "        CE_col = F.cross_entropy(x_col, out_col, reduction='sum')\n",
    "\n",
    "        KL_z = torch.sum(pz.log_prob(z_q) - qz.log_prob(z_q))\n",
    "          \n",
    "        return self.rec_beta * CE_bar \\\n",
    "                  + self.rec_gamma * CE_col \\\n",
    "                  - self.beta * KL_z, \\\n",
    "                  CE_bar, CE_col, mse_bar, acc_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOsLfYJjBBe"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH1E5J-ps3GD"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16152,
     "status": "ok",
     "timestamp": 1647023309618,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "myflmDPxjV40",
    "outputId": "0befed1a-e175-47eb-e1c0-f9f28da53d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset = MicroRNADataset(create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7139,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "ut2P5RSaMoDR",
    "outputId": "eafab284-1376-4f62-c8c9-bb8e87351bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels! (~10s)\n",
      "loading encodings\n",
      "Loading Names! (~5s)\n"
     ]
    }
   ],
   "source": [
    "RNA_dataset_test = MicroRNADataset('test', create_encodings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34721"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RNA_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316754,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "eVGq463Y2m20"
   },
   "outputs": [],
   "source": [
    "def train_single_epoch(train_loader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    no_batches = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0\n",
    "    pbar = tqdm(enumerate(train_loader), unit=\"batch\", \n",
    "                                     desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (x, y, d, x_len, x_col, x_bar,_) in pbar:\n",
    "        # To device\n",
    "        x, y, d , x_len, x_bar, x_col = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, bar_loss, col_loss, mse, acc = model.loss_function(d.float(), x.float(), y.float(), x_len.float(), x_bar.float(), x_col.float())\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=loss.item()/x.shape[0])\n",
    "        train_loss += loss\n",
    "        epoch_bar_loss += bar_loss\n",
    "        epoch_col_loss += col_loss\n",
    "        mse_bar += mse\n",
    "        acc_bar += acc\n",
    "        no_batches += 1\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    epoch_bar_loss /= len(train_loader.dataset)\n",
    "    epoch_col_loss /= len(train_loader.dataset)\n",
    "    acc_bar /= len(train_loader.dataset)\n",
    "    mse_bar /= len(train_loader.dataset)\n",
    "    \n",
    "    return train_loss, epoch_bar_loss, epoch_col_loss, mse_bar, acc_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "dT7E0C3nM3qh"
   },
   "outputs": [],
   "source": [
    "def test_single_epoch(test_loader, model, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    epoch_bar_loss = 0\n",
    "    epoch_col_loss = 0\n",
    "    mse_bar = 0\n",
    "    acc_bar = 0        \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x,y,d,x_len,x_col,x_bar,_) in enumerate(test_loader):\n",
    "            x, y, d, x_len, x_bar, x_col = x.to(DEVICE), y.to(DEVICE), d.to(DEVICE), x_len.to(DEVICE), x_bar.to(DEVICE), x_col.to(DEVICE)\n",
    "            loss, bar_loss, col_loss, mse, acc = model.loss_function(d.float(), x.float(), y.float(),x_len.float(),x_bar.float(),x_col.float())\n",
    "            test_loss += loss\n",
    "            epoch_bar_loss += bar_loss\n",
    "            epoch_col_loss += col_loss\n",
    "            mse_bar += mse\n",
    "            acc_bar += acc\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    epoch_bar_loss /= len(test_loader.dataset)\n",
    "    epoch_col_loss /= len(test_loader.dataset)\n",
    "    acc_bar /= len(test_loader.dataset)\n",
    "    mse_bar /= len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, epoch_bar_loss, epoch_col_loss, mse_bar, acc_bar\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1647023316755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "npLjVGs0jHYn"
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch=0, save_folder='sd_1.0.0',save_interval=5):\n",
    "    \n",
    "    epoch_loss_sup = []\n",
    "    test_loss = []\n",
    "    \n",
    "    for epoch in range(start_epoch+1, end_epoch+1):\n",
    "        diva.beta = min([args.beta, args.beta * (epoch - args.prewarmup * 1.) / (args.warmup)])\n",
    "        if epoch< args.prewarmup:\n",
    "            diva.beta = args.beta/args.prewarmup\n",
    "        train_loss, avg_loss_bar, avg_loss_col, mtr, atr = train_single_epoch(train_loader, diva, optimizer, epoch)\n",
    "        str_loss_sup = train_loss\n",
    "        epoch_loss_sup.append(train_loss)\n",
    "        str_print = \"epoch {}: avg train loss {:.2f}\".format(epoch, str_loss_sup)\n",
    "        str_print += \", bar train loss {:.3f}\".format(avg_loss_bar)\n",
    "        str_print += \", col train loss {:.3f}\".format(avg_loss_col)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_train = diva.rec_beta * avg_loss_bar + diva.rec_gamma * avg_loss_col\n",
    "        dis_loss_train = train_loss - rec_loss_train\n",
    "\n",
    "        test_lss, avg_loss_bar_test, avg_loss_col_test, mte, ate = test_single_epoch(test_loader, diva, epoch)\n",
    "        test_loss.append(test_lss)\n",
    "       \n",
    "        str_print = \"epoch {}: avg test  loss {:.2f}\".format(epoch, test_lss)\n",
    "        str_print += \", bar  test loss {:.3f}\".format(avg_loss_bar_test)\n",
    "        str_print += \", col  test loss {:.3f}\".format(avg_loss_col_test)\n",
    "        print(str_print)\n",
    "\n",
    "        rec_loss_test = diva.rec_beta * avg_loss_bar_test + diva.rec_gamma * avg_loss_col_test\n",
    "        dis_loss_test = test_lss - rec_loss_test\n",
    "\n",
    "        if writer is not None:\n",
    "            \n",
    "            writer.add_scalars(\"Total_Loss\", {'train': train_loss, 'test': test_lss} ,epoch)\n",
    "            writer.add_scalars(\"Reconstruction_vs_Disentanglement\",{'rec':rec_loss_train, 'dis':dis_loss_train}, epoch)\n",
    "            writer.add_scalars(\"bar_mse\",{'train': mtr, 'test':mte}, epoch)\n",
    "            writer.add_scalars(\"bar_acc\",{'train': atr, 'test':ate}, epoch)\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            save_reconstructions(epoch, test_loader, diva, name=save_folder)\n",
    "            save_reconstructions(epoch, train_loader, diva, name=save_folder, estr='tr')\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            torch.save(diva.state_dict(), f'{link}/saved_models/{save_folder}/checkpoints/{epoch}.pth')\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.flush()\n",
    "\n",
    "    epoch_loss_sup = [i.detach().cpu().numpy() for i in epoch_loss_sup]\n",
    "    test_loss = [i.detach().cpu().numpy() for i in test_loss]\n",
    "    return epoch_loss_sup, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "XxN8U8YK0Qi1"
   },
   "outputs": [],
   "source": [
    "def save_reconstructions(epoch, test_loader, diva, name='diva', estr=''):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:10].to(DEVICE).float()\n",
    "        x = a[1][0][:10].to(DEVICE).float()\n",
    "        y = a[1][1][:10].to(DEVICE).float()\n",
    "        m = a[1][-1][:10].to(DEVICE).float()\n",
    "        x_2, x_2var, x_3 ,qz, pz, z_q = diva(d,x,y)\n",
    "        out = diva.px.reconstruct_image(x_2, x_2var, x_3)\n",
    "\n",
    "    plt.figure(figsize=(80,20))\n",
    "    fig, ax = plt.subplots(nrows=10, ncols=2)\n",
    "\n",
    "    ax[0,0].set_title(\"Original\")\n",
    "    ax[0,1].set_title(\"Reconstructed\")\n",
    "\n",
    "    for i in range(10):\n",
    "        ax[i, 1].imshow(out[i])\n",
    "        ax[i, 0].imshow(x[i].cpu().permute(1,2,0))\n",
    "        ax[i, 0].xaxis.set_visible(False)\n",
    "        ax[i, 0].yaxis.set_visible(False)\n",
    "        ax[i, 1].xaxis.set_visible(False)\n",
    "        ax[i, 1].yaxis.set_visible(False)\n",
    "    fig.tight_layout(pad=0.1)\n",
    "    plt.savefig(f'{link}/saved_models/{name}/reconstructions/e{epoch}{estr}.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647023317082,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "YVAD-Mjwh7yq",
    "outputId": "f330c11c-e358-41af-9ef4-bc36c146f907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI4-NzHxjmci"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647023317083,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "sJE0HTJE1ayP"
   },
   "outputs": [],
   "source": [
    "default_args = diva_args(z_dim=1024, rec_alpha = 20, rec_beta = 10, rec_gamma = 10, \n",
    "                         beta=1, warmup=1, prewarmup=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "kxIMSeUD1949",
    "outputId": "45991358-df3b-4e61-9d8a-c48b71b9fa49"
   },
   "outputs": [],
   "source": [
    "diva = StampDIVA(default_args).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318259,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "PUHyoMi7iwJC"
   },
   "outputs": [],
   "source": [
    "#diva.load_state_dict(torch.load(f'{link}/saved_models/VAE10/checkpoints/905.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1647023318260,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "48B39rFl79Yh"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(RNA_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(RNA_dataset_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "J6y2Ek2677z1"
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(diva.parameters(), lr=0.00001, momentum=0.1, nesterov=True)\n",
    "#optimizer = optim.Adam(diva.parameters(), lr=0.005)\n",
    "optimizer = optim.RMSprop(diva.parameters(), lr=0.001, eps=0.1, momentum=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_dataset.x_len.min(), RNA_dataset.x_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1647023318261,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "vQGakzXN6V-Y",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3615d768df2c21e8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3615d768df2c21e8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"D:/users/Marko/downloads/mirna/saved_models/new/IVAE1/tensorboard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1647023318262,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "0m47XoL87oLs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0batch [00:00, ?batch/s]D:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
      "Epoch 1: 272batch [00:45,  6.04batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: avg train loss 2922.62, bar train loss 9.990, col train loss 281.673\n",
      "epoch 1: avg test  loss 2890.41, bar  test loss 7.907, col  test loss 281.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 272batch [00:44,  6.07batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg train loss 2891.20, bar train loss 7.924, col train loss 281.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 1batch [00:00,  5.95batch/s, loss=2.88e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: avg test  loss 2890.98, bar  test loss 7.923, col  test loss 281.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 272batch [00:44,  6.06batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg train loss 2889.37, bar train loss 7.709, col train loss 281.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 1batch [00:00,  6.02batch/s, loss=2.88e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: avg test  loss 2882.04, bar  test loss 7.083, col  test loss 280.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 272batch [00:45,  6.02batch/s, loss=2.88e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg train loss 2880.16, bar train loss 6.835, col train loss 280.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 1batch [00:00,  5.99batch/s, loss=2.87e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: avg test  loss 2876.03, bar  test loss 6.468, col  test loss 280.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 272batch [00:45,  6.03batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: avg train loss 2874.42, bar train loss 6.322, col train loss 280.606\n",
      "epoch 5: avg test  loss 2870.95, bar  test loss 6.165, col  test loss 280.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 272batch [00:45,  6.00batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg train loss 2869.84, bar train loss 6.036, col train loss 280.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 1batch [00:00,  5.99batch/s, loss=2.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: avg test  loss 2867.56, bar  test loss 5.928, col  test loss 280.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 272batch [00:45,  6.00batch/s, loss=2.89e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg train loss 2867.16, bar train loss 5.902, col train loss 280.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 1batch [00:00,  6.14batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: avg test  loss 2865.10, bar  test loss 5.733, col  test loss 280.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 272batch [00:45,  6.02batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg train loss 2864.73, bar train loss 5.744, col train loss 279.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 1batch [00:00,  6.02batch/s, loss=2.89e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: avg test  loss 2864.26, bar  test loss 5.901, col  test loss 279.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 272batch [00:45,  6.01batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg train loss 2861.69, bar train loss 5.630, col train loss 279.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 1batch [00:00,  5.95batch/s, loss=2.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: avg test  loss 2859.84, bar  test loss 5.566, col  test loss 279.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 272batch [00:45,  6.00batch/s, loss=2.88e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: avg train loss 2859.72, bar train loss 5.524, col train loss 279.587\n",
      "epoch 10: avg test  loss 2858.70, bar  test loss 5.444, col  test loss 279.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 272batch [00:45,  6.01batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg train loss 2857.34, bar train loss 5.345, col train loss 279.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 1batch [00:00,  6.06batch/s, loss=2.88e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: avg test  loss 2855.81, bar  test loss 5.219, col  test loss 279.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 272batch [00:45,  5.98batch/s, loss=2.93e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg train loss 2855.65, bar train loss 5.189, col train loss 279.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 1batch [00:00,  6.02batch/s, loss=2.85e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: avg test  loss 2854.89, bar  test loss 5.140, col  test loss 279.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 272batch [00:45,  5.98batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg train loss 2854.32, bar train loss 5.075, col train loss 279.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 14: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: avg test  loss 2853.32, bar  test loss 4.958, col  test loss 279.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 272batch [00:44,  6.05batch/s, loss=2.9e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg train loss 2853.37, bar train loss 5.009, col train loss 279.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 15: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: avg test  loss 2853.53, bar  test loss 5.093, col  test loss 279.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 272batch [00:45,  6.00batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: avg train loss 2851.63, bar train loss 4.958, col train loss 279.110\n",
      "epoch 15: avg test  loss 2850.54, bar  test loss 4.948, col  test loss 279.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 272batch [00:45,  6.04batch/s, loss=2.89e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg train loss 2850.62, bar train loss 4.935, col train loss 278.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 1batch [00:00,  6.13batch/s, loss=2.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: avg test  loss 2850.25, bar  test loss 5.044, col  test loss 278.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 272batch [00:45,  6.04batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg train loss 2848.87, bar train loss 4.879, col train loss 278.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 1batch [00:00,  6.06batch/s, loss=2.85e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: avg test  loss 2847.63, bar  test loss 4.753, col  test loss 278.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 272batch [00:45,  5.97batch/s, loss=2.89e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg train loss 2847.17, bar train loss 4.804, col train loss 278.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 1batch [00:00,  5.95batch/s, loss=2.89e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: avg test  loss 2846.58, bar  test loss 4.759, col  test loss 278.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 272batch [00:45,  6.03batch/s, loss=2.78e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg train loss 2846.14, bar train loss 4.756, col train loss 278.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 20: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: avg test  loss 2845.45, bar  test loss 4.603, col  test loss 278.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 272batch [00:45,  6.03batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: avg train loss 2845.28, bar train loss 4.705, col train loss 278.529\n",
      "epoch 20: avg test  loss 2844.72, bar  test loss 4.643, col  test loss 278.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 272batch [00:45,  5.98batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg train loss 2844.23, bar train loss 4.692, col train loss 278.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 22: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: avg test  loss 2843.90, bar  test loss 4.652, col  test loss 278.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 272batch [00:45,  6.02batch/s, loss=2.87e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg train loss 2843.39, bar train loss 4.670, col train loss 278.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 1batch [00:00,  6.06batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: avg test  loss 2843.25, bar  test loss 4.630, col  test loss 278.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 272batch [00:45,  5.99batch/s, loss=2.89e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg train loss 2842.47, bar train loss 4.651, col train loss 278.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 1batch [00:00,  6.13batch/s, loss=2.85e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: avg test  loss 2842.24, bar  test loss 4.567, col  test loss 278.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 272batch [00:45,  6.01batch/s, loss=2.87e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg train loss 2841.96, bar train loss 4.639, col train loss 278.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 1batch [00:00,  6.10batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: avg test  loss 2842.25, bar  test loss 4.525, col  test loss 278.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 272batch [00:45,  6.03batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: avg train loss 2841.36, bar train loss 4.612, col train loss 278.093\n",
      "epoch 25: avg test  loss 2841.85, bar  test loss 4.730, col  test loss 278.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 272batch [00:45,  5.97batch/s, loss=2.76e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg train loss 2840.62, bar train loss 4.592, col train loss 278.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 1batch [00:00,  6.06batch/s, loss=2.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: avg test  loss 2841.04, bar  test loss 4.466, col  test loss 278.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 272batch [00:45,  5.98batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg train loss 2839.93, bar train loss 4.553, col train loss 277.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 1batch [00:00,  6.06batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: avg test  loss 2839.95, bar  test loss 4.508, col  test loss 277.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 272batch [00:45,  6.00batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg train loss 2839.26, bar train loss 4.529, col train loss 277.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 1batch [00:00,  6.06batch/s, loss=2.85e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: avg test  loss 2840.07, bar  test loss 4.528, col  test loss 277.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 272batch [00:45,  5.99batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg train loss 2838.55, bar train loss 4.500, col train loss 277.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 1batch [00:00,  6.21batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: avg test  loss 2839.22, bar  test loss 4.644, col  test loss 277.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 272batch [00:45,  6.04batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: avg train loss 2837.92, bar train loss 4.473, col train loss 277.793\n",
      "epoch 30: avg test  loss 2837.99, bar  test loss 4.491, col  test loss 277.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 272batch [00:45,  6.01batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg train loss 2837.31, bar train loss 4.458, col train loss 277.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 1batch [00:00,  5.78batch/s, loss=2.83e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: avg test  loss 2838.04, bar  test loss 4.433, col  test loss 277.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 272batch [00:45,  6.01batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg train loss 2836.58, bar train loss 4.428, col train loss 277.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 1batch [00:00,  6.29batch/s, loss=2.83e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: avg test  loss 2836.51, bar  test loss 4.415, col  test loss 277.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 272batch [00:45,  6.03batch/s, loss=2.87e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg train loss 2835.50, bar train loss 4.402, col train loss 277.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 1batch [00:00,  6.06batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: avg test  loss 2835.46, bar  test loss 4.352, col  test loss 277.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 272batch [00:45,  6.00batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg train loss 2834.64, bar train loss 4.367, col train loss 277.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 1batch [00:00,  6.17batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: avg test  loss 2835.34, bar  test loss 4.364, col  test loss 277.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 272batch [00:45,  6.01batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: avg train loss 2834.17, bar train loss 4.343, col train loss 277.438\n",
      "epoch 35: avg test  loss 2834.55, bar  test loss 4.321, col  test loss 277.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 272batch [00:45,  5.98batch/s, loss=2.89e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg train loss 2833.62, bar train loss 4.317, col train loss 277.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 1batch [00:00,  6.06batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: avg test  loss 2833.85, bar  test loss 4.374, col  test loss 277.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 272batch [00:45,  6.00batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg train loss 2832.94, bar train loss 4.292, col train loss 277.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 1batch [00:00,  6.10batch/s, loss=2.83e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: avg test  loss 2833.34, bar  test loss 4.310, col  test loss 277.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 272batch [00:42,  6.41batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg train loss 2832.24, bar train loss 4.271, col train loss 277.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 39: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: avg test  loss 2832.38, bar  test loss 4.223, col  test loss 277.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 272batch [00:46,  5.81batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg train loss 2831.91, bar train loss 4.257, col train loss 277.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 0batch [00:00, ?batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: avg test  loss 2832.29, bar  test loss 4.251, col  test loss 277.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 272batch [00:46,  5.82batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: avg train loss 2831.32, bar train loss 4.234, col train loss 277.167\n",
      "epoch 40: avg test  loss 2832.06, bar  test loss 4.236, col  test loss 277.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 272batch [00:46,  5.83batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg train loss 2830.29, bar train loss 4.199, col train loss 277.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 42: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: avg test  loss 2830.79, bar  test loss 4.281, col  test loss 277.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 272batch [00:46,  5.81batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg train loss 2830.08, bar train loss 4.191, col train loss 277.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 1batch [00:00,  5.92batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: avg test  loss 2830.54, bar  test loss 4.154, col  test loss 277.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 272batch [00:46,  5.83batch/s, loss=2.77e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg train loss 2829.64, bar train loss 4.168, col train loss 276.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 1batch [00:00,  5.88batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: avg test  loss 2830.03, bar  test loss 4.154, col  test loss 277.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 272batch [00:46,  5.82batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg train loss 2828.95, bar train loss 4.142, col train loss 276.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 1batch [00:00,  5.88batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: avg test  loss 2829.74, bar  test loss 4.262, col  test loss 277.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 272batch [00:46,  5.80batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45: avg train loss 2828.60, bar train loss 4.129, col train loss 276.908\n",
      "epoch 45: avg test  loss 2829.45, bar  test loss 4.149, col  test loss 277.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 272batch [00:46,  5.79batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg train loss 2828.34, bar train loss 4.120, col train loss 276.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 1batch [00:00,  5.68batch/s, loss=2.86e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: avg test  loss 2828.47, bar  test loss 4.126, col  test loss 276.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 272batch [00:46,  5.80batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg train loss 2827.94, bar train loss 4.101, col train loss 276.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 1batch [00:00,  5.78batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: avg test  loss 2828.39, bar  test loss 4.079, col  test loss 276.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 272batch [00:47,  5.73batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg train loss 2827.30, bar train loss 4.079, col train loss 276.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 1batch [00:00,  5.62batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: avg test  loss 2827.62, bar  test loss 4.047, col  test loss 276.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 272batch [00:47,  5.71batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg train loss 2826.61, bar train loss 4.060, col train loss 276.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 0batch [00:00, ?batch/s, loss=2.8e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: avg test  loss 2827.56, bar  test loss 4.080, col  test loss 276.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 272batch [00:47,  5.73batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: avg train loss 2826.25, bar train loss 4.045, col train loss 276.701\n",
      "epoch 50: avg test  loss 2826.80, bar  test loss 4.086, col  test loss 276.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 272batch [00:47,  5.76batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg train loss 2825.81, bar train loss 4.031, col train loss 276.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 1batch [00:00,  5.75batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: avg test  loss 2825.92, bar  test loss 3.969, col  test loss 276.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 169batch [00:29,  5.68batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-569c2d094958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlss_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"new/IVAE1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-866f38b905e2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch, save_folder, save_interval)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m<\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprewarmup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mdiva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprewarmup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_single_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mstr_loss_sup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mepoch_loss_sup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-3a263e4205da>\u001b[0m in \u001b[0;36mtrain_single_epoch\u001b[1;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbar_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-0fe204dce6fc>\u001b[0m in \u001b[0;36mloss_function\u001b[1;34m(self, d, x, y, out_len, out_bar, out_col)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mx_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bar_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mmse_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bar\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mout_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-0fe204dce6fc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, d, x, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Reparameterization trick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mqz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzd_q_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzd_q_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mz_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\distributions\\normal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     raise ValueError(\n\u001b[0;32m     56\u001b[0m                         \u001b[1;34mf\"Expected parameter {param} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lss, lss_t = train(default_args, train_loader, test_loader, diva, optimizer, 500, 0, save_folder=\"new/IVAE1\",save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(diva.parameters(), lr=0.001, eps=0.1, momentum=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diva.load_state_dict(torch.load(f'{link}/saved_models/new/IVAE1/checkpoints/50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 272batch [00:46,  5.83batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg train loss 2828.26, bar train loss 4.152, col train loss 276.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 1batch [00:00,  5.99batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: avg test  loss 2826.25, bar  test loss 4.014, col  test loss 276.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 272batch [00:46,  5.80batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: avg train loss 2825.43, bar train loss 4.010, col train loss 276.615\n",
      "epoch 65: avg test  loss 2826.56, bar  test loss 4.085, col  test loss 276.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 272batch [00:46,  5.80batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg train loss 2824.57, bar train loss 3.983, col train loss 276.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 1batch [00:00,  5.81batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: avg test  loss 2825.07, bar  test loss 3.991, col  test loss 276.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 272batch [00:47,  5.77batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg train loss 2823.83, bar train loss 3.959, col train loss 276.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 68: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: avg test  loss 2824.46, bar  test loss 3.903, col  test loss 276.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 272batch [00:47,  5.77batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg train loss 2823.18, bar train loss 3.948, col train loss 276.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 1batch [00:00,  5.65batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: avg test  loss 2824.96, bar  test loss 4.092, col  test loss 276.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 272batch [00:47,  5.70batch/s, loss=2.88e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg train loss 2822.59, bar train loss 3.925, col train loss 276.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 1batch [00:00,  5.85batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: avg test  loss 2823.75, bar  test loss 3.926, col  test loss 276.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 272batch [00:47,  5.74batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70: avg train loss 2822.15, bar train loss 3.914, col train loss 276.347\n",
      "epoch 70: avg test  loss 2822.92, bar  test loss 3.944, col  test loss 276.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 272batch [00:47,  5.76batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg train loss 2821.34, bar train loss 3.892, col train loss 276.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 72: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: avg test  loss 2822.43, bar  test loss 3.937, col  test loss 276.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 272batch [00:47,  5.78batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg train loss 2820.63, bar train loss 3.874, col train loss 276.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 1batch [00:00,  5.81batch/s, loss=2.8e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: avg test  loss 2821.43, bar  test loss 3.873, col  test loss 276.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 272batch [00:46,  5.85batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: avg train loss 2819.67, bar train loss 3.846, col train loss 276.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 1batch [00:00,  5.78batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: avg test  loss 2820.55, bar  test loss 3.827, col  test loss 276.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 272batch [00:46,  5.82batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74: avg train loss 2819.35, bar train loss 3.844, col train loss 276.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 1batch [00:00,  5.81batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74: avg test  loss 2820.02, bar  test loss 3.767, col  test loss 276.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 272batch [00:47,  5.76batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75: avg train loss 2818.85, bar train loss 3.829, col train loss 276.093\n",
      "epoch 75: avg test  loss 2819.65, bar  test loss 3.778, col  test loss 276.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 272batch [00:47,  5.75batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76: avg train loss 2818.06, bar train loss 3.811, col train loss 276.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 77: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76: avg test  loss 2818.88, bar  test loss 3.816, col  test loss 276.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 272batch [00:47,  5.77batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: avg train loss 2817.24, bar train loss 3.790, col train loss 275.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 78: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: avg test  loss 2817.79, bar  test loss 3.746, col  test loss 276.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 272batch [00:46,  5.84batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: avg train loss 2816.61, bar train loss 3.773, col train loss 275.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 1batch [00:00,  5.78batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: avg test  loss 2818.07, bar  test loss 3.782, col  test loss 276.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 272batch [00:46,  5.83batch/s, loss=2.75e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79: avg train loss 2816.11, bar train loss 3.763, col train loss 275.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 80: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79: avg test  loss 2817.84, bar  test loss 3.806, col  test loss 276.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 272batch [00:46,  5.80batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80: avg train loss 2815.59, bar train loss 3.745, col train loss 275.838\n",
      "epoch 80: avg test  loss 2816.76, bar  test loss 3.706, col  test loss 275.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 272batch [00:47,  5.78batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81: avg train loss 2815.27, bar train loss 3.722, col train loss 275.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 1batch [00:00,  5.99batch/s, loss=2.8e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81: avg test  loss 2816.23, bar  test loss 3.731, col  test loss 275.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 272batch [00:47,  5.72batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: avg train loss 2814.80, bar train loss 3.708, col train loss 275.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 83: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: avg test  loss 2815.55, bar  test loss 3.687, col  test loss 275.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 272batch [00:47,  5.77batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83: avg train loss 2814.06, bar train loss 3.689, col train loss 275.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 1batch [00:00,  5.59batch/s, loss=2.84e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83: avg test  loss 2814.88, bar  test loss 3.669, col  test loss 275.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 272batch [00:47,  5.77batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: avg train loss 2813.79, bar train loss 3.683, col train loss 275.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 85: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: avg test  loss 2814.97, bar  test loss 3.673, col  test loss 275.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 272batch [00:46,  5.82batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85: avg train loss 2813.35, bar train loss 3.674, col train loss 275.665\n",
      "epoch 85: avg test  loss 2813.65, bar  test loss 3.628, col  test loss 275.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 272batch [00:47,  5.78batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86: avg train loss 2812.81, bar train loss 3.651, col train loss 275.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 87: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86: avg test  loss 2813.90, bar  test loss 3.555, col  test loss 275.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 272batch [00:46,  5.80batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: avg train loss 2812.66, bar train loss 3.641, col train loss 275.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 1batch [00:00,  5.88batch/s, loss=2.83e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: avg test  loss 2813.51, bar  test loss 3.656, col  test loss 275.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 272batch [00:47,  5.78batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: avg train loss 2812.29, bar train loss 3.625, col train loss 275.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 1batch [00:00,  5.81batch/s, loss=2.79e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: avg test  loss 2814.12, bar  test loss 3.601, col  test loss 275.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 272batch [00:47,  5.75batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89: avg train loss 2812.03, bar train loss 3.619, col train loss 275.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 1batch [00:00,  5.85batch/s, loss=2.8e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89: avg test  loss 2813.26, bar  test loss 3.617, col  test loss 275.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 272batch [00:47,  5.73batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90: avg train loss 2811.82, bar train loss 3.610, col train loss 275.574\n",
      "epoch 90: avg test  loss 2813.06, bar  test loss 3.607, col  test loss 275.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 272batch [00:47,  5.75batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91: avg train loss 2811.44, bar train loss 3.603, col train loss 275.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 1batch [00:00,  5.81batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91: avg test  loss 2812.93, bar  test loss 3.567, col  test loss 275.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 272batch [00:47,  5.71batch/s, loss=2.84e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: avg train loss 2811.39, bar train loss 3.582, col train loss 275.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 93: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: avg test  loss 2812.69, bar  test loss 3.595, col  test loss 275.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 272batch [00:47,  5.75batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93: avg train loss 2811.16, bar train loss 3.583, col train loss 275.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 1batch [00:00,  5.71batch/s, loss=2.85e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93: avg test  loss 2812.46, bar  test loss 3.547, col  test loss 275.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 272batch [00:47,  5.70batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94: avg train loss 2810.70, bar train loss 3.566, col train loss 275.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 95: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94: avg test  loss 2811.83, bar  test loss 3.541, col  test loss 275.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 272batch [00:47,  5.74batch/s, loss=2.78e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95: avg train loss 2810.42, bar train loss 3.563, col train loss 275.462\n",
      "epoch 95: avg test  loss 2811.98, bar  test loss 3.625, col  test loss 275.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 272batch [00:47,  5.75batch/s, loss=2.76e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96: avg train loss 2810.38, bar train loss 3.552, col train loss 275.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 0batch [00:00, ?batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96: avg test  loss 2811.57, bar  test loss 3.505, col  test loss 275.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 272batch [00:47,  5.76batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: avg train loss 2810.14, bar train loss 3.543, col train loss 275.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 98: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: avg test  loss 2811.56, bar  test loss 3.589, col  test loss 275.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 272batch [00:47,  5.78batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98: avg train loss 2809.84, bar train loss 3.537, col train loss 275.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 99: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98: avg test  loss 2811.49, bar  test loss 3.543, col  test loss 275.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 272batch [00:47,  5.75batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: avg train loss 2809.56, bar train loss 3.518, col train loss 275.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 1batch [00:00,  5.88batch/s, loss=2.82e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: avg test  loss 2810.79, bar  test loss 3.493, col  test loss 275.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 272batch [00:47,  5.77batch/s, loss=2.85e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: avg train loss 2809.42, bar train loss 3.516, col train loss 275.373\n",
      "epoch 100: avg test  loss 2810.52, bar  test loss 3.542, col  test loss 275.530\n"
     ]
    }
   ],
   "source": [
    " lss2, lss_t2 = train(default_args, train_loader, test_loader, diva, optimizer, 100, 63, save_folder=\"new/IVAE1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 272batch [00:46,  5.81batch/s, loss=2.79e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: avg train loss 2812.91, bar train loss 3.693, col train loss 275.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 1batch [00:00,  5.85batch/s, loss=2.79e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101: avg test  loss 2811.46, bar  test loss 3.589, col  test loss 275.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 272batch [00:46,  5.82batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: avg train loss 2810.02, bar train loss 3.544, col train loss 275.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 1batch [00:00,  5.85batch/s, loss=2.81e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102: avg test  loss 2810.96, bar  test loss 3.529, col  test loss 275.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 272batch [00:46,  5.81batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103: avg train loss 2809.42, bar train loss 3.519, col train loss 275.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 104: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103: avg test  loss 2810.96, bar  test loss 3.464, col  test loss 275.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 272batch [00:46,  5.83batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: avg train loss 2809.05, bar train loss 3.514, col train loss 275.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 105: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104: avg test  loss 2809.91, bar  test loss 3.537, col  test loss 275.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 272batch [00:46,  5.81batch/s, loss=2.82e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105: avg train loss 2808.28, bar train loss 3.496, col train loss 275.262\n",
      "epoch 105: avg test  loss 2809.57, bar  test loss 3.484, col  test loss 275.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106: 272batch [00:46,  5.82batch/s, loss=2.8e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: avg train loss 2807.87, bar train loss 3.492, col train loss 275.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 1batch [00:00,  5.99batch/s, loss=2.79e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106: avg test  loss 2808.87, bar  test loss 3.449, col  test loss 275.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 272batch [00:46,  5.82batch/s, loss=2.76e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: avg train loss 2807.65, bar train loss 3.478, col train loss 275.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 1batch [00:00,  5.99batch/s, loss=2.8e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107: avg test  loss 2809.81, bar  test loss 3.628, col  test loss 275.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 272batch [00:46,  5.83batch/s, loss=2.86e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: avg train loss 2807.41, bar train loss 3.493, col train loss 275.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 109: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108: avg test  loss 2808.82, bar  test loss 3.455, col  test loss 275.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 272batch [00:46,  5.80batch/s, loss=2.78e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109: avg train loss 2807.34, bar train loss 3.479, col train loss 275.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 110: 0batch [00:00, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109: avg test  loss 2808.57, bar  test loss 3.498, col  test loss 275.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 272batch [00:47,  5.69batch/s, loss=2.83e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110: avg train loss 2807.21, bar train loss 3.475, col train loss 275.152\n",
      "epoch 110: avg test  loss 2808.37, bar  test loss 3.482, col  test loss 275.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111: 272batch [00:46,  5.81batch/s, loss=2.76e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111: avg train loss 2807.02, bar train loss 3.465, col train loss 275.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 1batch [00:00,  5.85batch/s, loss=2.78e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111: avg test  loss 2808.15, bar  test loss 3.466, col  test loss 275.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 56batch [00:09,  5.76batch/s, loss=2.81e+3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-25c1978842c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlss3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlss_t3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"new/IVAE1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-866f38b905e2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, train_loader, test_loader, diva, optimizer, end_epoch, start_epoch, save_folder, save_interval)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m<\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprewarmup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mdiva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprewarmup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_single_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mstr_loss_sup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mepoch_loss_sup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-3a263e4205da>\u001b[0m in \u001b[0;36mtrain_single_epoch\u001b[1;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbar_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-0fe204dce6fc>\u001b[0m in \u001b[0;36mloss_function\u001b[1;34m(self, d, x, y, out_len, out_bar, out_col)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mx_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bar_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mmse_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bar\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mout_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-0fe204dce6fc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, d, x, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Reparameterization trick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mqz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzd_q_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzd_q_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mz_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\distributions\\normal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Marko\\Anaconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     raise ValueError(\n\u001b[0;32m     56\u001b[0m                         \u001b[1;34mf\"Expected parameter {param} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lss3, lss_t3 = train(default_args, train_loader, test_loader, diva, optimizer, 500, 100, save_folder=\"new/IVAE1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4r_UyPUGXqT"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(lss, lss_t):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(lss, label=\"train loss\")\n",
    "    ax.plot(lss_t, label = \"test loss\")\n",
    "    #ax1 = ax.twinx()\n",
    "    #ax1.plot(yacc, label = \"train accuracy\", ls='--')\n",
    "    #ax1.plot(yacc_t, label = \"test accuracy\", ls='--')\n",
    "\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    #lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "\n",
    "    ax.legend(lines, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1645822416415,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "fTFZZmoguwtU",
    "outputId": "540c8c1f-99d7-4931-c102-7c96747243aa"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss, lss_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1645623855467,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "mq2FG26TznE1",
    "outputId": "152eddd3-a440-4b25-c437-498efb0a7ffe"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(lss3, lss_t3, yacc3, yacc_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FyP02qPdgso"
   },
   "outputs": [],
   "source": [
    "def plot_change_latent_var(diva, lat_space=\"y\", var_idx=[0,1,2,3,4,5,6,7], step = 5):\n",
    "    a = next(enumerate(test_loader))\n",
    "    with torch.no_grad():\n",
    "        diva.eval()\n",
    "        d = a[1][2][:len(var_idx)].to(DEVICE).float()\n",
    "        x = a[1][0][:len(var_idx)].to(DEVICE).float()\n",
    "        y = a[1][1][:len(var_idx)].to(DEVICE).float()\n",
    "\n",
    "        zx, zx_sc = diva.qzx(x)\n",
    "        zy, zy_sc = diva.qzy(x)\n",
    "        zd, zd_sc =  diva.qzd(x)\n",
    "\n",
    "        print(torch.max(zy), torch.min(zy), \"sdmax:\", torch.max(zy_sc))\n",
    "\n",
    "        out = change(zx, zy, zd, var_idx, lat_space, diva, step)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=out.shape[0],nrows=len(var_idx),figsize=(10*4*out.shape[0],10*len(var_idx)))\n",
    "    for i in range(out.shape[0]):\n",
    "      for j in range(len(var_idx)):\n",
    "        ax[j,i].imshow(out[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6kJu1APenFe"
   },
   "outputs": [],
   "source": [
    "def change(zx, zy, zd, idx, lat = \"y\", model=diva, step = 2):\n",
    "    \n",
    "    dif = np.arange(-30,15,step)\n",
    "    print(torch.max(zy), torch.min(zy))\n",
    "    out = np.zeros((dif.shape[0], len(idx), 25, 100 ,3))  \n",
    "    #print(zy.shape, dif.shape[0])\n",
    "    for i in range(dif.shape[0]):\n",
    "      for j in range(len(idx)):\n",
    "        if lat == \"y\":\n",
    "            zy[j,idx] = dif[i]\n",
    "        elif lat == \"x\":\n",
    "            zx[j,idx] = dif[i]\n",
    "        elif lat == \"d\":\n",
    "            zd[j,idx] = dif[i]\n",
    "        len_, bar, col = model.px(zd[j],zx[j],zy[j])\n",
    "        out[i,j] = model.px.reconstruct_image(len_[None,:], bar, col)\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 33513,
     "status": "ok",
     "timestamp": 1645623900042,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04006351469182865246"
     },
     "user_tz": -60
    },
    "id": "4U1JHmTKh0cE",
    "outputId": "b0a1850e-9f0d-4163-813b-8686f4bb05fc"
   },
   "outputs": [],
   "source": [
    "plot_change_latent_var(diva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpZoRZMGHcui"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss2], label=\"train loss\")\n",
    "ax.plot(np.arange(50,120), [i.cpu().detach().numpy() for i in lss_t2], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(50,120), yacc2, label = \"train\")\n",
    "ax1.plot(np.arange(50,120), yacc_t2, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1645563980004,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OQMW85JXM6oO",
    "outputId": "dd28a6c2-0024-498e-d571-c705ee67fbd6"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss3], label=\"train loss\")\n",
    "ax.plot(np.arange(120,180), [i.cpu().detach().numpy() for i in lss_t3], label = \"testloss\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(120,180), yacc3, label = \"train\",c='green')\n",
    "ax1.plot(np.arange(120,180), yacc_t3, label = \"test\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whsgNltzXDhK"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfcwhSNIjqIE"
   },
   "source": [
    "## Sampling from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NWGV4Xd7bn8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z5XA4QI1Mb1"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(lat_space=\"y\"):\n",
    "    '''\n",
    "    lat_space: y, d, x\n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1645556291755,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "USZ7nIDugT1S",
    "outputId": "174d53bb-845f-458b-ca85-9d749c9c0865"
   },
   "outputs": [],
   "source": [
    "plot(x, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1645550689935,
     "user": {
      "displayName": "Marko Petkovic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gijd0e9r3I1vRZVN6DEwl16XpJxxS1oSAKunOnfZQ=s64",
      "userId": "11987583535390684770"
     },
     "user_tz": -60
    },
    "id": "OE3qVVFFLaPm",
    "outputId": "93953e16-3bda-464b-b765-3aedb9fbe428"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i in range(9):\n",
    "  ax[i//3, i%3].imshow(x[i].cpu().permute(1,2,0))\n",
    "  \n",
    "plt.savefig('divastamporg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQU05xQEx28"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StampVAE (Beta)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
